--- a/apex/src/scripts/consolidate.py	(original)
--- b/apex/src/scripts/consolidate.py	(refactored)
@@ -1,6 +1,6 @@
 #!/usr/bin/python
 
-from __future__ import print_function
+
 import os.path
 import sys
 import glob
@@ -70,7 +70,7 @@
                     rowdata[period] = {}
                 total = 0
                 for c in colnames:
-                    if c not in line.keys():
+                    if c not in list(line.keys()):
                         rowdata[period][c] = 0
                         continue
                     if c not in rowdata[period]:
--- a/apex/src/scripts/task_scatterplot.py	(original)
--- b/apex/src/scripts/task_scatterplot.py	(refactored)
@@ -33,13 +33,13 @@
             try:
                 mytup = (float(row[0]),float(row[1]))
             except ValueError as e:
-                print(index, " Bad row: ", row)
+                print((index, " Bad row: ", row))
                 continue
             if row[2] not in dictionary:
                 dictionary[row[2]] = [mytup]
             else:
                 dictionary[row[2]].append(mytup)
-    print "Parsed", index, "samples"
+    print("Parsed", index, "samples")
 
 #resize the figure
 # Get current size
@@ -56,7 +56,7 @@
 numplots = min(len(dictionary), 10)
 for key in sorted(dictionary, key=lambda key: len(dictionary[key]), reverse=True):
     index = index + 1
-    print "Plotting", key
+    print("Plotting", key)
     axes = pl.subplot(((numplots+1)/2), 2, index)
     timestamps = np.array([x[0] for x in dictionary[key]])
     values = np.array([x[1] for x in dictionary[key]])
@@ -72,7 +72,7 @@
     pl.xlabel("seconds from program start")
     if index >= numplots:
         break
-print "Rendering..."
+print("Rendering...")
 pl.tight_layout()
 #pl.show()
 pl.savefig("image.png")
--- a/etc/TAU-CSV-To-HeatMap.py	(original)
--- b/etc/TAU-CSV-To-HeatMap.py	(refactored)
@@ -18,7 +18,7 @@
 csvSource = GetActiveSource()
 
 if(('FileName' in dir(csvSource) and csvSource.FileName[0].lower().endswith(".csv")) is False):
-	raise TypeError, "This macro requires a .csv file to be selected in the pipeline browser."
+	raise TypeError("This macro requires a .csv file to be selected in the pipeline browser.")
 
 data = servermanager.Fetch(csvSource,0)
 col0 = data.GetColumn(0)
--- a/examples/test.py	(original)
--- b/examples/test.py	(refactored)
@@ -6,11 +6,11 @@
 def shell_command(command,errorMessage):
 #command initiated where this script is ran
   try:
-    print command
+    print(command)
     subprocess.check_call(command, stderr=subprocess.STDOUT, shell=True)
     errorStatus=0
   except :
-    print errorMessage
+    print(errorMessage)
     pass
     errorStatus=1
   return errorStatus
@@ -29,20 +29,20 @@
 
 def dumpclean(obj):
     if type(obj) == dict:
-        for k, v in obj.items():
+        for k, v in list(obj.items()):
             if hasattr(v, '__iter__'):
-                print k
+                print(k)
                 dumpclean(v)
             else:
-                print '%s : %s' % (k, v)
+                print('%s : %s' % (k, v))
     elif type(obj) == list:
         for v in obj:
             if hasattr(v, '__iter__'):
                 dumpclean(v)
             else:
-                print v
+                print(v)
     else:
-        print obj
+        print(obj)
 
 def resultMeaning(result):
     if result == 0 :
@@ -69,12 +69,12 @@
     parentDir=os.getcwd()
 
 
-    directories = filter(os.path.isdir, os.listdir(os.getcwd()))
+    directories = list(filter(os.path.isdir, os.listdir(os.getcwd())))
     makeResults=dict((dirs,{"make":0,"build.sh":0}) for dirs in directories)
       # 0,1 normal, -1 if doesn't exist
     for currentDir in directories:
         os.chdir(currentDir)
-        print "*** CD into ", currentDir
+        print("*** CD into ", currentDir)
         isBuild = os.path.isfile("build.sh")
         isMake = os.path.isfile("Makefile")
         if isMake :
@@ -100,10 +100,10 @@
     target.write("#dir,   make,    build.sh \n")
     target.write("\n")
 
-    for dir,resultDict in makeResults.iteritems():
+    for dir,resultDict in makeResults.items():
         result=[]
         result.append(dir + " , ")
-        for type,code in resultDict.iteritems():
+        for type,code in resultDict.items():
             result.append(resultMeaning(code)+ " , ")
             #print '%s: %s: %s' % (dir,type,resultMeaning(result))}
         result.append("\n")
--- a/examples/gpu/pycuda/matmult.py	(original)
--- b/examples/gpu/pycuda/matmult.py	(refactored)
@@ -107,7 +107,7 @@
 	cuda.memcpy_htod(d_a, a)
 	cuda.memcpy_htod(d_b, b)
 
-	print "threads:", number_of_threads, "blocks: ", number_of_blocks
+	print("threads:", number_of_threads, "blocks: ", number_of_blocks)
 
 	multiply_matrices = multiply_source.get_function("multiply_matrices")
 	multiply_matrices_shared_blocks = multiply_source.get_function("multiply_matrices_shared_blocks")
--- a/examples/mpi4py-c++-f90/samarc.py	(original)
--- b/examples/mpi4py-c++-f90/samarc.py	(refactored)
@@ -28,7 +28,7 @@
 	try:
 		import samint
 	except ImportError:
-		print "Import Error: have to run with MPI"
+		print("Import Error: have to run with MPI")
 
 
 class samarc:
@@ -37,7 +37,7 @@
 		self.inpfile=startfile
 
 		if not os.path.isfile(startfile):
-			print 'Error: Could not find file %s' % startfile
+			print('Error: Could not find file %s' % startfile)
 			return None
 
 		samint.samarcInit(self.inpfile)
--- a/examples/mpi4py-c++-f90/samarcrun.py	(original)
--- b/examples/mpi4py-c++-f90/samarcrun.py	(refactored)
@@ -50,8 +50,8 @@
 for n in range(nsteps):
    step = step + 1
 
-   print "---------------------------------------------------"
-   print "           step: ", step, "\ttime: ", simtime
+   print("---------------------------------------------------")
+   print("           step: ", step, "\ttime: ", simtime)
 
    # flow solve
    offBodySolver.runStep(simtime,dt)
--- a/examples/plugin/adios2_trace/mpi_reader.py	(original)
--- b/examples/plugin/adios2_trace/mpi_reader.py	(refactored)
@@ -11,22 +11,22 @@
 
 def process_file(filename):
    filename = filename.replace('.sst', '')
-   print ("Opening:", filename)
+   print(("Opening:", filename))
    with adios2.open(filename, "r", MPI.COMM_SELF, engine_type=engine) as fh:
       for fstep in fh:
          # inspect variables in current step
          step_vars = fstep.available_variables()
          # print variables information
-         for name, info in step_vars.items():
-             print(filename, "variable_name: " + name)
-             for key, value in info.items():
-                print(filename, "\t" + key + ": " + value)
+         for name, info in list(step_vars.items()):
+             print((filename, "variable_name: " + name))
+             for key, value in list(info.items()):
+                print((filename, "\t" + key + ": " + value))
              print("\n")
              # read the variable!
              dummy = fstep.read(name)
          # track current step
          step = fstep.current_step()
-         print(filename, "Step = ", step)
+         print((filename, "Step = ", step))
 
 if __name__ == '__main__':
    comm = MPI.COMM_WORLD
--- a/examples/plugin/adios2_trace/reader.py	(original)
--- b/examples/plugin/adios2_trace/reader.py	(refactored)
@@ -11,22 +11,22 @@
 
 def process_file(filename):
    filename = filename.replace('.sst', '')
-   print ("Opening:", filename)
+   print(("Opening:", filename))
    with adios2.open(filename, "r", MPI.COMM_SELF, engine_type=engine) as fh:
       for fstep in fh:
          # inspect variables in current step
          step_vars = fstep.available_variables()
          # print variables information
-         for name, info in step_vars.items():
-             print(filename, "variable_name: " + name)
-             for key, value in info.items():
-                print(filename, "\t" + key + ": " + value)
+         for name, info in list(step_vars.items()):
+             print((filename, "variable_name: " + name))
+             for key, value in list(info.items()):
+                print((filename, "\t" + key + ": " + value))
              print("\n")
              # read the variable!
              dummy = fstep.read(name)
          # track current step
          step = fstep.current_step()
-         print(filename, "Step = ", step)
+         print((filename, "Step = ", step))
 
 if __name__ == '__main__':
    #time.sleep(2)
--- a/examples/plugin/adios2_trace/reader_single.py	(original)
--- b/examples/plugin/adios2_trace/reader_single.py	(refactored)
@@ -11,22 +11,22 @@
 
 def process_file(filename):
    filename = filename.replace('.sst', '')
-   print ("Opening:", filename)
+   print(("Opening:", filename))
    with adios2.open(filename, "r", MPI.COMM_SELF, engine_type=engine) as fh:
       for fstep in fh:
          # inspect variables in current step
          step_vars = fstep.available_variables()
          # print variables information
-         for name, info in step_vars.items():
-             print(filename, "variable_name: " + name)
-             for key, value in info.items():
-                print(filename, "\t" + key + ": " + value)
+         for name, info in list(step_vars.items()):
+             print((filename, "variable_name: " + name))
+             for key, value in list(info.items()):
+                print((filename, "\t" + key + ": " + value))
              print("\n")
              # read the variable!
              dummy = fstep.read(name)
          # track current step
          step = fstep.current_step()
-         print(filename, "Step = ", step)
+         print((filename, "Step = ", step))
 
 if __name__ == '__main__':
    #time.sleep(2)
--- a/examples/plugin/sqlite3/nosql-parser.py	(original)
--- b/examples/plugin/sqlite3/nosql-parser.py	(refactored)
@@ -48,7 +48,7 @@
     rows = c.execute(sql)
     desc = c.description
     column_names = [col[0] for col in desc]
-    data = [dict(zip(column_names, row)) for row in c.fetchall()]
+    data = [dict(list(zip(column_names, row))) for row in c.fetchall()]
     return data
 
 def get_counters(conn):
@@ -76,7 +76,7 @@
     rows = c.execute(sql)
     desc = c.description
     column_names = [col[0] for col in desc]
-    data = [dict(zip(column_names, row)) for row in c.fetchall()]
+    data = [dict(list(zip(column_names, row))) for row in c.fetchall()]
     return data
 
 if __name__ == '__main__':
--- a/examples/plugin/sqlite3/parser.py	(original)
--- b/examples/plugin/sqlite3/parser.py	(refactored)
@@ -19,7 +19,7 @@
     rows = c.execute('SELECT id, name, created FROM trial')
     desc = c.description
     column_names = [col[0] for col in desc]
-    data = [dict(zip(column_names, row)) for row in c.fetchall()]
+    data = [dict(list(zip(column_names, row))) for row in c.fetchall()]
     return data
 
 def get_metadata(conn):
@@ -27,7 +27,7 @@
     rows = c.execute('SELECT trial, name, value FROM metadata')
     desc = c.description
     column_names = [col[0] for col in desc]
-    data = [dict(zip(column_names, row)) for row in c.fetchall()]
+    data = [dict(list(zip(column_names, row))) for row in c.fetchall()]
     return data
 
 def get_threads(conn):
@@ -35,7 +35,7 @@
     rows = c.execute('SELECT id, node_rank, thread_rank FROM thread')
     desc = c.description
     column_names = [col[0] for col in desc]
-    data = [dict(zip(column_names, row)) for row in c.fetchall()]
+    data = [dict(list(zip(column_names, row))) for row in c.fetchall()]
     return data
 
 def get_metrics(conn):
@@ -43,7 +43,7 @@
     rows = c.execute('SELECT trial, name FROM metric')
     desc = c.description
     column_names = [col[0] for col in desc]
-    data = [dict(zip(column_names, row)) for row in c.fetchall()]
+    data = [dict(list(zip(column_names, row))) for row in c.fetchall()]
     return data
 
 def get_timers(conn):
@@ -51,7 +51,7 @@
     rows = c.execute('SELECT id, trial, parent, short_name FROM timer')
     desc = c.description
     column_names = [col[0] for col in desc]
-    data = [dict(zip(column_names, row)) for row in c.fetchall()]
+    data = [dict(list(zip(column_names, row))) for row in c.fetchall()]
     return data
 
 def get_timer_values(conn):
@@ -59,7 +59,7 @@
     rows = c.execute('SELECT timer, metric, thread, value FROM timer_value')
     desc = c.description
     column_names = [col[0] for col in desc]
-    data = [dict(zip(column_names, row)) for row in c.fetchall()]
+    data = [dict(list(zip(column_names, row))) for row in c.fetchall()]
     return data
 
 def get_counters(conn):
@@ -67,7 +67,7 @@
     rows = c.execute('SELECT id, trial, name FROM counter')
     desc = c.description
     column_names = [col[0] for col in desc]
-    data = [dict(zip(column_names, row)) for row in c.fetchall()]
+    data = [dict(list(zip(column_names, row))) for row in c.fetchall()]
     return data
 
 def get_counter_values(conn):
@@ -75,7 +75,7 @@
     rows = c.execute('SELECT counter, timer, thread, sample_count, maximum_value, minimum_value, mean_value, sum_of_squares FROM counter_value')
     desc = c.description
     column_names = [col[0] for col in desc]
-    data = [dict(zip(column_names, row)) for row in c.fetchall()]
+    data = [dict(list(zip(column_names, row))) for row in c.fetchall()]
     return data
 
 def write_callgraph(timers):
@@ -87,7 +87,7 @@
                 dot.node(str(timer['id']), timer['short_name'])
             if timer['parent'] != None:
                 dot.edge(str(timer['id']), str(timer['parent']))
-    print(dot.source)
+    print((dot.source))
     #dot.render('callgraph.gv', view=True)
 
 if __name__ == '__main__':
--- a/examples/pyspark/als.py	(original)
--- b/examples/pyspark/als.py	(refactored)
@@ -21,7 +21,7 @@
 
 This example requires numpy (http://www.numpy.org/)
 """
-from __future__ import print_function
+
 
 import sys
 
@@ -87,7 +87,7 @@
     usb = sc.broadcast(us)
 
     for i in range(ITERATIONS):
-        ms = sc.parallelize(range(M), partitions) \
+        ms = sc.parallelize(list(range(M)), partitions) \
                .map(lambda x: update(x, usb.value, Rb.value)) \
                .collect()
         # collect() returns a list, so array ends up being
@@ -95,7 +95,7 @@
         ms = matrix(np.array(ms)[:, :, 0])
         msb = sc.broadcast(ms)
 
-        us = sc.parallelize(range(U), partitions) \
+        us = sc.parallelize(list(range(U)), partitions) \
                .map(lambda x: update(x, msb.value, Rb.value.T)) \
                .collect()
         us = matrix(np.array(us)[:, :, 0])
--- a/examples/python/cpi.py	(original)
--- b/examples/python/cpi.py	(refactored)
@@ -25,7 +25,7 @@
 
 def prn_pi(pi, PI):
     message = "pi is approximately %.16f, error is %.16f"
-    print  (message % (pi, abs(pi - PI)))
+    print((message % (pi, abs(pi - PI))))
 
 comm = MPI.COMM_WORLD
 nprocs = comm.Get_size()
--- a/examples/python/firstprime.py	(original)
--- b/examples/python/firstprime.py	(refactored)
@@ -15,7 +15,7 @@
 				# Found factor. not prime
 				break # move on to next number
 			elif potentialfactor >= sqrtno: 
-				print("The first prime number after {} is {}".format(x,current))
+				print(("The first prime number after {} is {}".format(x,current)))
 				return current
 		current += 1
 
--- a/examples/python/hello-mpi.py	(original)
--- b/examples/python/hello-mpi.py	(refactored)
@@ -5,6 +5,6 @@
 
 comm = MPI.COMM_WORLD
 
-print ("Hello! I'm rank %d from %d running in total..." % (comm.rank, comm.size))
+print(("Hello! I'm rank %d from %d running in total..." % (comm.rank, comm.size)))
 
 comm.Barrier()   # wait for everybody to synchronize _here_
--- a/examples/sos/pycoolrgui/pycoolr-plot/clr_utils.py	(original)
--- b/examples/sos/pycoolrgui/pycoolr-plot/clr_utils.py	(refactored)
@@ -26,7 +26,7 @@
     for jt in jtext:
         try:
             j = json.loads(jt)
-        except ValueError, e:
+        except ValueError as e:
             continue
         ret.append(j)
 
--- a/examples/sos/pycoolrgui/pycoolr-plot/coolr-back.py	(original)
--- b/examples/sos/pycoolrgui/pycoolr-plot/coolr-back.py	(refactored)
@@ -1,7 +1,7 @@
 #!/usr/bin/env python
 
 #import sys, os, re, _thread, signal
-import sys, os, re, thread, signal
+import sys, os, re, _thread, signal
 #from cStringIO import StringIO
 from io import StringIO
 import subprocess
@@ -146,10 +146,10 @@
     with open(cfgfn) as f:
         cfgtmp = json.load(f)
         # override if cfg defines any
-        for k in cfgtmp.keys():
+        for k in list(cfgtmp.keys()):
             cfg[k] = cfgtmp[k]
         # override if specifed as cmd option
-        for k in ocfg.keys():
+        for k in list(ocfg.keys()):
             cfg[k] = ocfg[k]
 
 
@@ -157,21 +157,21 @@
     targetnode = os.environ['PYCOOLR_NODE']
     #targetnode = cfg['masternode']
 if len(enclaves) == 0:
-    if cfg.has_key('enclaves'):
+    if 'enclaves' in cfg:
         enclaves = cfg['enclaves']
 
 #print 'masternode:', cfg['masternode']
-print('targetnode:', targetnode)
-print('enclaves:', enclaves)
+print(('targetnode:', targetnode))
+print(('enclaves:', enclaves))
 
 if len(appcfgfn) > 0:
     with open(appcfgfn) as f:
         appcfg = json.load(f)
-    for k in appcfg.keys():
+    for k in list(appcfg.keys()):
         cfg[k] = appcfg[k]
 
-    if not (cfg.has_key('appname') and cfg.has_key('appsamples')):
-        print("Please double check %s: appname or appsamples tags" % appcfgfn)
+    if not ('appname' in cfg and 'appsamples' in cfg):
+        print(("Please double check %s: appname or appsamples tags" % appcfgfn))
         sys.exit(1)
 
 
@@ -187,7 +187,7 @@
 try:
     logf = open(cfg["outputfn"], 'w', 0) # unbuffered write
 except:
-    print('unable to open', cfg["outputfn"])
+    print(('unable to open', cfg["outputfn"]))
 
 
 #if not fakemode:
@@ -210,11 +210,11 @@
 params['enclaves'] = enclaves
 
 if sys.version_info[0] < 3:
-    import Tkinter
+    import tkinter
     #from Tkinter import *
-    import tkFileDialog
-    import tkFont
-    from tkFont import Font
+    import tkinter.filedialog
+    import tkinter.font
+    from tkinter.font import Font
     #from Tkinter.FileDialog import askopenfilename
 else:
     import tkinter
@@ -227,7 +227,7 @@
   def __init__(self, master, row=2, col=3):
 
         # Create a container
-        self.frame = Tkinter.Frame(master,width=200,height=100)
+        self.frame = tkinter.Frame(master,width=200,height=100)
         # Create 2 buttons
         #self.button_left = Tkinter.Button(frame,text="< Decrease Slope",
         #                               command=self.decrease)
@@ -243,7 +243,7 @@
         self.nbsamples = params['cfg']['nbsamples']
         #self.nbcvars = params['cfg']['nbcvars']
         self.listmetrics = params['cfg']['metrics']
-        print("self.listmetrics",self.listmetrics)
+        print(("self.listmetrics",self.listmetrics))
         #self.listsamples = params['cfg']['appsamples']
         self.nbGraphs = params['cfg']['nbgraphs']
       
@@ -268,7 +268,7 @@
           self.btncvarsupdate = None
 
         self.metrics = params['cfg']['metrics']
-        print("self.metrics", self.metrics)
+        print(("self.metrics", self.metrics))
         #self.ranks = params['cfg']['ranks']
         self.ranks = [None] * self.nbsamples
         self.procs = [None] * self.nbsamples
@@ -318,14 +318,14 @@
         self.listFontFamily = ['serif', 'sans-serif', 'cursive', 'fantasy', 'monospace']
         self.listFontWeight = ['ultralight','light','normal','regular','book','medium','roman','semibold','demibold','demi','bold','heavy','extra bold','black']
 
-        self.list_fonts = list( tkFont.families() )
+        self.list_fonts = list( tkinter.font.families() )
 
         self.selectedFontPolicy = None
         self.selectedFontSize = None
         self.selectedFontWeight = None
        
         # create a custom font
-        self.customFont = tkFont.Font(family="Helvetica", size=12)
+        self.customFont = tkinter.font.Font(family="Helvetica", size=12)
  
         for idx in range(params['cfg']['nbgraphs']):
          self.listUsedGraphs.append(-1)
@@ -414,7 +414,7 @@
         try:       
           root.config(menu=menubar)
         except AttributeError as attErr:
-          print('menu Exception: ', type(attErr), attErr)
+          print(('menu Exception: ', type(attErr), attErr))
 
         #self.winPvars()
         #self.winCvars()
@@ -422,27 +422,27 @@
         self.subSpawn()
 
   def try_execute(self, c, statement, parameters=None):
-    print ("statement: ", statement)
-    print ("parameters: ", parameters)
+    print(("statement: ", statement))
+    print(("parameters: ", parameters))
     try:
         if parameters:
             c.execute(statement,parameters);
         else:
             c.execute(statement);
     except sqlite3.Error as e:
-        print("database error...", e.args[0])
+        print(("database error...", e.args[0]))
 
   def open_connection(self):
     global conn
     # check for file to exist
     #print ("Checking for file: ", sqlite_file)
-    print("Checking for file: ", self.sosdbfile)
+    print(("Checking for file: ", self.sosdbfile))
     while not os.path.exists(self.sosdbfile):
-        print("Waiting on file: ", self.sosdbfile)
+        print(("Waiting on file: ", self.sosdbfile))
         time.sleep(1)
 
     #print("Connecting to: ", sqlite_file)
-    print("Connecting to: ", self.sosdbfile)
+    print(("Connecting to: ", self.sosdbfile))
     # Connecting to the database file
     #conn = sqlite3.connect(sqlite_file)
     #fd = os.open(sqlite_file, os.O_RDONLY)
@@ -481,14 +481,14 @@
       
   def browsefontpolicy(self):
         print('browsefontpolicy')
-        fontpolicydiag = tkFileDialog.askopenfilename(filetypes=[("Text files","*.fft")])
+        fontpolicydiag = tkinter.filedialog.askopenfilename(filetypes=[("Text files","*.fft")])
 
   def onselectFontPolicy(self,evt):
         w = evt.widget
         selection = w.curselection()
         value = w.get(selection[0])
         self.selectedFontPolicy = value
-        print('select font: ', value)
+        print(('select font: ', value))
 
   def onselectFontSize(self, evt):
        print('select font size')
@@ -496,7 +496,7 @@
        selection = w.curselection()
        value = w.get(selection[0])
        self.selectedFontSize = value
-       print('select font: ', value)
+       print(('select font: ', value))
 
   def onselectFontWeight(self, evt):
        print('select font weight')
@@ -504,7 +504,7 @@
        selection = w.curselection()
        value = w.get(selection[0])
        self.selectedFontWeight = value
-       print('select font: ', value)
+       print(('select font: ', value))
 
   def loadFontPolicy(self):
         fontpolicydiag = askopenfilename(filetypes=(("*.fft"))) 
@@ -597,9 +597,9 @@
         #f1 = Tk.Frame(pvarswin,width=150,height=100) 
         s1 = Tk.Scrollbar(self.f1) 
 	#l1 = Tk.Listbox(f1,selectmode='multiple',width=80,height=40)
-        print("self.listmetrics",self.listmetrics)
-        print("len(self.listmetrics)",len(self.listmetrics))
-        print("self.nbsamples",self.nbsamples)
+        print(("self.listmetrics",self.listmetrics))
+        print(("len(self.listmetrics)",len(self.listmetrics)))
+        print(("self.nbsamples",self.nbsamples))
         for i in range(self.nbsamples): self.l1.insert(i, self.listmetrics[i]) 
         s1.config(command = self.l1.yview) 
         self.l1.config(yscrollcommand = s1.set) 
@@ -661,7 +661,7 @@
 
   def clearplot(self,idxGraph):
 
-       print('clearplot: idxGraph=', idxGraph)
+       print(('clearplot: idxGraph=', idxGraph))
        ax = self.ax[idxGraph]
        ax.cla()    
        #ax.clf()
@@ -735,7 +735,7 @@
                         total_val=total_val+ref4
                         num_vals=num_vals+1
                         mean_val=total_val/num_vals
-                        print('display record ref4='+str(ref4))
+                        print(('display record ref4='+str(ref4)))
                         self.data_lr[i].add(t,ref4)
                         #self.data_lr[i].add(t,mean_val)
                         goodrecord=1
@@ -810,7 +810,7 @@
                 try:
                   ax.cla()
                 except Exception as errCla:
-                  print('update_gui: Error cla(): ', type(errCla), errCla)
+                  print(('update_gui: Error cla(): ', type(errCla), errCla))
 
                 ax.set_xlim([t-gxsec, t])
                 #print 'get x and y'
@@ -894,7 +894,7 @@
 
         #print 'parse graphs'
         metric_value = max(sample[1],0)
-        print("metric_value",metric_value)
+        print(("metric_value",metric_value))
         numeric = re.search(r'\d+', metric_value)
         metric_value_num = numeric.group()
         metric_value_float = float(metric_value_num)
@@ -920,7 +920,7 @@
         try:
            ax.cla()
         except Exception as errCla:
-          print('update_gui: Error cla(): ', type(errCla), errCla)
+          print(('update_gui: Error cla(): ', type(errCla), errCla))
 
         ax.set_xlim([pack_time-gxsec, pack_time])
         #print 'get x and y'
@@ -1030,7 +1030,7 @@
         try:
            ax.cla()
         except Exception as errCla:
-          print('update_gui: Error cla(): ', type(errCla), errCla)
+          print(('update_gui: Error cla(): ', type(errCla), errCla))
 
         ax.set_xlim([pack_time-gxsec, pack_time])
         #print 'get x and y'
@@ -1158,7 +1158,7 @@
            try:
              j = json.loads(payload)
            except ValueError as e:
-             print('Failed to load json data: %s' %e)
+             print(('Failed to load json data: %s' %e))
              continue
              #return False
 
@@ -1193,7 +1193,7 @@
          if 'node' not in e and\
             'sample' not in e and\
             'time' not in e:
-             print('Ignore this invalid sample:', json.dumps(e))
+             print(('Ignore this invalid sample:', json.dumps(e)))
              continue
 
          #print 'set timestamp'
@@ -1225,7 +1225,7 @@
        try:
          self.canvas.draw()
        except Exception as errDraw:
-         print('Error drawing canvas: ', type(errDraw), errDraw)
+         print(('Error drawing canvas: ', type(errDraw), errDraw))
        #plt.draw()
 
        profile_t7 = time.time()
@@ -1307,7 +1307,7 @@
     all_rows = c.fetchall()
     ts = np.array([x[0] for x in all_rows])
     min_timestamp = ts[0]
-    print("min timestamp: ", min_timestamp)
+    print(("min timestamp: ", min_timestamp))
 
 
   def get_min_timestamp(self):
@@ -1315,25 +1315,25 @@
     sql_statement = ("SELECT min(time_pack) FROM viewCombined;")
     print("get_min_timestamp Executing query")
  
-    print("sql statement: ", sql_statement)
+    print(("sql statement: ", sql_statement))
     #self.try_execute(c, sql_statement)
     os.environ['SOS_SQL'] = sql_statement
     sos_bin_path = os.environ.get('SOS_BIN_DIR')
-    print('SOS BIN path: ', sos_bin_path)
+    print(('SOS BIN path: ', sos_bin_path))
     os.system('cd '+ sos_bin_path)
-    print('current dir: ', os.getcwd())
+    print(('current dir: ', os.getcwd()))
     # Redirect stdout of passed command into a string
 
     soscmd = sos_bin_path + "/demo_app_silent --sql SOS_SQL"
-    print('soscmd: ', soscmd)
+    print(('soscmd: ', soscmd))
     tmp_res_min_ts_sql = subprocess.check_output(soscmd, shell=True)
 
     #self.res_min_ts_sql = tmp_res_min_ts_sql.splitlines()
-    print('get min ts: tmp res sql=', tmp_res_min_ts_sql)
+    print(('get min ts: tmp res sql=', tmp_res_min_ts_sql))
     res_min_ts_sql = tmp_res_min_ts_sql.splitlines()
-    print("List of result SQL MIN TS: ", res_min_ts_sql)
+    print(("List of result SQL MIN TS: ", res_min_ts_sql))
     min_ts_rows = res_min_ts_sql[1].split(",")
-    print("List of result SQL MIN TS values: ", min_ts_rows)
+    print(("List of result SQL MIN TS values: ", min_ts_rows))
     # Remove first element of SQL result 
     #ts = np.array([x[0] for x in min_ts_rows])
     str_min_timestamp = min_ts_rows[0].replace('\"', '')
@@ -1375,31 +1375,31 @@
     sql_statement = ("SELECT value_name, value, time_pack FROM viewCombined WHERE value_name LIKE '" + metric+ "'")
     #sql_statement = ("SELECT * FROM viewCombined WHERE value_name LIKE '" + metric+ "'")
    
-    print("sql statement: ", sql_statement )
+    print(("sql statement: ", sql_statement ))
     #self.try_execute(c, sql_statement)
     os.environ['SOS_SQL'] = sql_statement
     sos_bin_path = os.environ.get('SOS_BIN_DIR')
-    print('SOS BIN path: ', sos_bin_path)
+    print(('SOS BIN path: ', sos_bin_path))
     os.system('cd '+ sos_bin_path)  
-    print('current dir: ', os.getcwd()) 
+    print(('current dir: ', os.getcwd())) 
     # Redirect stdout of passed command into a string
    
     soscmd = sos_bin_path + "/demo_app_silent --sql SOS_SQL"
-    print('soscmd: ', soscmd)
+    print(('soscmd: ', soscmd))
     tmp_res_sql = subprocess.check_output(soscmd, shell=True)
 
     self.try_execute(c, sql_statement)
 
     #print 'stdout of SOS demo: ', sys.stdout
     #self.res_sql = resultstdout.getvalue()
-    print('tmp res_sql: ', tmp_res_sql)
+    print(('tmp res_sql: ', tmp_res_sql))
     
     self.res_sql = tmp_res_sql.splitlines()
     # REmove first element of SQL result 
     self.res_sql.pop(0)
 
     for item_sql in self.res_sql:
-      print('res sql: ', item_sql) 
+      print(('res sql: ', item_sql)) 
       
  
   # Call demo with SQL statement given as argument and store standard output
@@ -1429,14 +1429,14 @@
     while self.ranks.size == 0:
         time.sleep(1)
         self.ranks,self.procs = self.get_ranks(self.conn)
-    print ("ranks: ", self.ranks)
+    print(("ranks: ", self.ranks))
 
     # get the number of nodes
     self.nodes,self.noderanks = self.get_nodes(self.conn)
     while self.nodes.size == 0:
         time.sleep(1)
         nodes,self.noderanks = self.get_nodes(self.conn)
-    print ("nodes: ", self.nodes)
+    print(("nodes: ", self.nodes))
 
     self.get_min_timestamp_db(self.conn)
     #resize the figure
@@ -1463,7 +1463,7 @@
     print('SOS: Execute demo app')
     sos_path = os.environ.get('SOS_BUILD_DIR') 
     self.sos_bin_path = sos_path+"/bin"
-    print('SOS BIN PATH: ', self.sos_bin_path)
+    print(('SOS BIN PATH: ', self.sos_bin_path))
     os.system("cd "+ self.sos_bin_path) 
 
 
@@ -1475,7 +1475,7 @@
 
     self.opendb()
 
-    print("metrics: ", self.metrics)
+    print(("metrics: ", self.metrics))
     #self.get_min_timestamp()  
  
     while True:  
@@ -1511,7 +1511,7 @@
            countsamples = 0
            for sample in self.rows[j]:
              params['ts'] = 0
-             print 'PYCOOLR sample: ', sample
+             print('PYCOOLR sample: ', sample)
              #self.req_sql(self.conn, self.ranks, self.rows)
              profile_t2 = time.time()
              self.lock.acquire()
@@ -1541,7 +1541,7 @@
          if self.listRecordSample[i] != -1:
            j = self.listRecordSample[i]
      
-           print('readsosmetrics: i=%d, j=%d' %(i,j))
+           print(('readsosmetrics: i=%d, j=%d' %(i,j)))
            
            #rank = self.ranks[j]
            #rank2 = self.ranks2[j]
@@ -1559,7 +1559,7 @@
            self.rows[j] = self.conn.fetchall()
            #print 'rows: ', self.rows[j]
            if len(self.rows[j]) <= 0:
-             print("Error: query returned no rows.",)
+             print(("Error: query returned no rows.",))
            else:
              goodrecord = 1
          
@@ -1646,11 +1646,11 @@
 
 
            payload.strip()
-           print('payload =',payload)
+           print(('payload =',payload))
            try:
              j = json.loads(payload)
            except ValueError as e:
-             print('Failed to load json data: %s' %e)
+             print(('Failed to load json data: %s' %e))
              continue
              #return False
 
@@ -1685,7 +1685,7 @@
          if 'node' not in e and\
             'sample' not in e and\
             'time' not in e:
-             print('Ignore this invalid sample:', json.dumps(e))
+             print(('Ignore this invalid sample:', json.dumps(e)))
              continue
 
          #print 'set timestamp'
@@ -1755,20 +1755,20 @@
          print('subSpawn: load beacon subscriber library')
          envlibpath = os.environ['PYCOOLR_LIBPATH']
          libarbjsonbeep = cdll.LoadLibrary(envlibpath+'/libarbitraryjsonbeepmulsub.so')
-         thread.start_new_thread(self.subscribe,(libarbjsonbeep,))
-         thread.start_new_thread(self.readEvents,(libarbjsonbeep,))
+         _thread.start_new_thread(self.subscribe,(libarbjsonbeep,))
+         _thread.start_new_thread(self.readEvents,(libarbjsonbeep,))
          #thread.start_new_thread(self.readEvents,(libarbjsonbeep,))
        except Exception as errThread:
-         print("Error: unable to start thread: ", errThread)
+         print(("Error: unable to start thread: ", errThread))
 
      elif self.tool == "sos":
        try:
          #thread.start_new_thread(self.subscribe,(libarbjsonbeep,))
-         thread.start_new_thread(self.readsosmetrics,())
+         _thread.start_new_thread(self.readsosmetrics,())
          #thread.start_new_thread(self.readsosmetrics_db,())
       
        except Exception as errThread:
-         print('Error: unable to start thread: ', errThread)
+         print(('Error: unable to start thread: ', errThread))
 
 
      self.refresh_plot()
@@ -1801,7 +1801,7 @@
 
             self.selectedcvarsvalues[i] =  self.listcvarsentry[i].get()
             strcvarsvalues += self.selectedcvarsvalues[i]
-            print('numselectedcvars=%d, index=%d' % (self.numselectedcvars, i))
+            print(('numselectedcvars=%d, index=%d' % (self.numselectedcvars, i)))
             if i+1 < self.numselectedcvars:
               strcvarsmetrics += ","
               strcvarsvalues += ","
@@ -1814,7 +1814,7 @@
             #self.strcvars += "=" 
             #self.strcvars += self.selectedcvarsvalues[i]
             #strcvars += ","
-            print('numselectedcvars=%d, index=%d' % (self.numselectedcvars, i))
+            print(('numselectedcvars=%d, index=%d' % (self.numselectedcvars, i)))
             if i+1 < self.numselectedcvars:
               strcvarsmetrics += ","
               strcvarsvalues += ","
@@ -1825,9 +1825,9 @@
         #self.strcvars += ":"
         self.strcvars += strcvarsvalues
 
-        print("strcvarsmetrics: ", strcvarsmetrics)
-        print("strcvarsvalues: ", strcvarsvalues)
-        print("strcvars: ", self.strcvars)
+        print(("strcvarsmetrics: ", strcvarsmetrics))
+        print(("strcvarsvalues: ", strcvarsvalues))
+        print(("strcvars: ", self.strcvars))
 
         # Test if we have to communicate MPI_T CVARS in a Publish/Subscribe mode       
         if cvars_comm_mode == "pub":
@@ -1863,7 +1863,7 @@
 
         for i in range(len(selection)):
           value = w.get(selection[i])
-          print("selection:", selection, ": '%s'" % value)
+          print(("selection:", selection, ": '%s'" % value))
           self.selectedcvarsmetrics[i] = value
 
         if self.listlabelcvarsmetric:
@@ -1885,19 +1885,19 @@
         self.listcvarsarrayindexentry = [None] * len(selection)
         self.listcvarsarrayindex = [None] * len(selection)
 
-        print('selection: ', selection)
-        print('range selection: ', range(len(selection)))
-
-        for cvaritem, cvarindex in zip(selection, range(len(selection))):
+        print(('selection: ', selection))
+        print(('range selection: ', list(range(len(selection)))))
+
+        for cvaritem, cvarindex in zip(selection, list(range(len(selection)))):
 
           value = w.get(selection[cvarindex])
-          print('len selection: ', len(selection))
-          print('value of item %d: %s ' % (cvarindex, value))
-          print('cvaritem: ', cvaritem)
-          print('cvarindex= ', cvarindex)
-          print('cvarsindexrow= ', self.cvarsindexrow)
-
-          print('cfg cvars array:', self.listcfgcvarsarray[0])
+          print(('len selection: ', len(selection)))
+          print(('value of item %d: %s ' % (cvarindex, value)))
+          print(('cvaritem: ', cvaritem))
+          print(('cvarindex= ', cvarindex))
+          print(('cvarsindexrow= ', self.cvarsindexrow))
+
+          print(('cfg cvars array:', self.listcfgcvarsarray[0]))
           if value == self.listcfgcvarsarray[0]:
 
             self.listlabelcvarsmetric[cvarindex]=Tk.Label(self.stepCvarsUpdate,  text=value)
@@ -1945,7 +1945,7 @@
           #print "selection:", selection, ": '%s'" % value
          
         listintselection = [int (i) for i in selection]
-        print('listintselection: ', listintselection)
+        print(('listintselection: ', listintselection))
 
         for i in range(self.nbsamples):
           if (self.listSamplesAllocated[i] > -1) and (i not in listintselection):
@@ -1960,7 +1960,7 @@
               if self.listSamplesAllocated[j] == -1:    
                 #index = int(j)
                 self.listUsedGraphs[i] = j
-                print('graph %d allocated to sample %d' % (i, j))
+                print(('graph %d allocated to sample %d' % (i, j)))
                 self.listRecordSample[i] = j
                 self.listSamplesAllocated[j] = i
                 break
@@ -1986,7 +1986,7 @@
                 # Mark current graph as used
                 self.listUsedGraphs[j] = 1           
                 # Record the current graph as plotting the current sample
-                print('Record Sample %d for graph %d' %(index,j))
+                print(('Record Sample %d for graph %d' %(index,j)))
                 self.listRecordSample[j] = index
 
                 # Mark current sample as allocated to the current graph
@@ -2087,7 +2087,7 @@
          self.canvas.draw()
          #self.frame.update()
        except Exception as errDraw:
-         print('refresh_plot: Error drawing canvas: ', type(errDraw), errDraw)
+         print(('refresh_plot: Error drawing canvas: ', type(errDraw), errDraw))
        self.lock.release()
 
        self.root.after(1000,self.refresh_plot)      
@@ -2097,11 +2097,11 @@
        try:
          self.canvas.draw()
        except Exception as errDraw:
-         print('Error drawing canvas: ', type(errDraw), errDraw)
+         print(('Error drawing canvas: ', type(errDraw), errDraw))
 
   def checkfn(self, idx, text): 
        print('checkfn')
-       print('Check index=%d text=%s' % (idx,text))
+       print(('Check index=%d text=%s' % (idx,text)))
        #print 'Size of listbtnchecked[]= ', len(self.listbtnchecked)
        #self.listbtnchecked[idx] = 1
 
@@ -2110,7 +2110,7 @@
 #     print 'nothing'
       
 
-root = Tkinter.Tk()
+root = tkinter.Tk()
 
 app = Coolrsub(root,2,3)
 root.mainloop()
--- a/examples/sos/pycoolrgui/pycoolr-plot/coolr-launch.py	(original)
--- b/examples/sos/pycoolrgui/pycoolr-plot/coolr-launch.py	(refactored)
@@ -39,8 +39,8 @@
 try:
     opts, args = getopt.getopt(sys.argv[1:],
                                shortopt, longopt)
-except getopt.GetoptError, err:
-    print err
+except getopt.GetoptError as err:
+    print(err)
     usage()
     sys.exit(1)
 
@@ -66,21 +66,21 @@
     elif o in ("--ncols"):
         ocfg["ncols"]=int(a)
     elif o in ("--list"):
-        print ''
-        print '[available graph modules]'
-        print ''
+        print('')
+        print('[available graph modules]')
+        print('')
         for i in cfg["modnames"]:
-            print i
-        print ''
-        print ''
+            print(i)
+        print('')
+        print('')
         sys.exit(0)
     elif o in ("--mods"):
         ocfg["modnames"] = a.split(",")
 
 if len(args) < 1:
-    print ''
-    print 'No config file is specified.  Enabled the fake mode.'
-    print ''
+    print('')
+    print('No config file is specified.  Enabled the fake mode.')
+    print('')
     cfg["masternode"] = "frontend"
     cfg["drawexternal"] = "no"
     cfg["drawacpipwr"] = "no"
@@ -102,30 +102,30 @@
     with open(cfgfn) as f:
         cfgtmp = json.load(f)
         # override if cfg defines any
-        for k in cfgtmp.keys():
+        for k in list(cfgtmp.keys()):
             cfg[k] = cfgtmp[k]
         # override if specifed as cmd option
-        for k in ocfg.keys():
+        for k in list(ocfg.keys()):
             cfg[k] = ocfg[k]
 
 if len(targetnode) == 0 :
     targetnode = cfg['masternode']
 if len(enclaves) == 0:
-    if cfg.has_key('enclaves'):
+    if 'enclaves' in cfg:
         enclaves = cfg['enclaves']
 
-print 'masternode:', cfg['masternode']
-print 'targetnode:', targetnode
-print 'enclaves:', enclaves
+print('masternode:', cfg['masternode'])
+print('targetnode:', targetnode)
+print('enclaves:', enclaves)
 
 if len(appcfgfn) > 0:
     with open(appcfgfn) as f:
         appcfg = json.load(f)
-    for k in appcfg.keys():
+    for k in list(appcfg.keys()):
         cfg[k] = appcfg[k]
 
-    if not (cfg.has_key('appname') and cfg.has_key('appsamples')):
-        print "Please double check %s: appname or appsamples tags" % appcfgfn
+    if not ('appname' in cfg and 'appsamples' in cfg):
+        print("Please double check %s: appname or appsamples tags" % appcfgfn)
         sys.exit(1)
 
 
@@ -143,9 +143,9 @@
 try:
     logf = open(cfg["outputfn"], 'w', 0) # unbuffered write
 except:
-    print 'unable to open', cfg["outputfn"]
-
-print >>logf, json.dumps(info)
+    print('unable to open', cfg["outputfn"])
+
+print(json.dumps(info), file=logf)
 
 #if not fakemode:
 #    querycmds = cfg['querycmds']
@@ -180,7 +180,7 @@
 
 
 if sys.version_info[0] < 3:
-    import Tkinter as Tk
+    import tkinter as Tk
 else:
     import tkinter as Tk
 
@@ -221,7 +221,7 @@
   #root.after(2000,mainLoop)
 
 ngraphs = len(params['cfg']['appsamples'])
-print 'samples ', params['cfg']['appsamples']
+print('samples ', params['cfg']['appsamples'])
 data_lr = [listrotate2D(length=params['lrlen']) for i in range(ngraphs)]
 
 #fig = plt.figure( figsize=(cfg["figwidth"],cfg["figheight"]) )
--- a/examples/sos/pycoolrgui/pycoolr-plot/coolr-sos-db.py	(original)
--- b/examples/sos/pycoolrgui/pycoolr-plot/coolr-sos-db.py	(refactored)
@@ -1,6 +1,6 @@
 #!/usr/bin/env python
 
-import sys, os, re, thread, signal
+import sys, os, re, _thread, signal
 import multiprocessing
 import json
 import sqlite3
@@ -74,8 +74,8 @@
 try:
     opts, args = getopt.getopt(sys.argv[1:],
                                shortopt, longopt)
-except getopt.GetoptError, err:
-    print err
+except getopt.GetoptError as err:
+    print(err)
     usage()
     sys.exit(1)
 
@@ -101,22 +101,22 @@
     elif o in ("--ncols"):
         ocfg["ncols"]=int(a)
     elif o in ("--list"):
-        print ''
-        print '[available graph modules]'
-        print ''
+        print('')
+        print('[available graph modules]')
+        print('')
         for i in cfg["modnames"]:
-            print i
-        print ''
-        print ''
+            print(i)
+        print('')
+        print('')
         sys.exit(0)
     elif o in ("--mods"):
         ocfg["modnames"] = a.split(",")
 
 
 if len(args) < 1:
-    print ''
-    print 'No config file is specified.  Enabled the fake mode.'
-    print ''
+    print('')
+    print('No config file is specified.  Enabled the fake mode.')
+    print('')
     cfg["masternode"] = "frontend"
     cfg["drawexternal"] = "no"
     cfg["drawacpipwr"] = "no"
@@ -140,10 +140,10 @@
     with open(cfgfn) as f:
         cfgtmp = json.load(f)
         # override if cfg defines any
-        for k in cfgtmp.keys():
+        for k in list(cfgtmp.keys()):
             cfg[k] = cfgtmp[k]
         # override if specifed as cmd option
-        for k in ocfg.keys():
+        for k in list(ocfg.keys()):
             cfg[k] = ocfg[k]
 
 
@@ -151,21 +151,21 @@
     targetnode = os.environ['PYCOOLR_NODE']
     #targetnode = cfg['masternode']
 if len(enclaves) == 0:
-    if cfg.has_key('enclaves'):
+    if 'enclaves' in cfg:
         enclaves = cfg['enclaves']
 
 #print 'masternode:', cfg['masternode']
-print 'targetnode:', targetnode
-print 'enclaves:', enclaves
+print('targetnode:', targetnode)
+print('enclaves:', enclaves)
 
 if len(appcfgfn) > 0:
     with open(appcfgfn) as f:
         appcfg = json.load(f)
-    for k in appcfg.keys():
+    for k in list(appcfg.keys()):
         cfg[k] = appcfg[k]
 
-    if not (cfg.has_key('appname') and cfg.has_key('appsamples')):
-        print "Please double check %s: appname or appsamples tags" % appcfgfn
+    if not ('appname' in cfg and 'appsamples' in cfg):
+        print("Please double check %s: appname or appsamples tags" % appcfgfn)
         sys.exit(1)
 
 
@@ -181,7 +181,7 @@
 try:
     logf = open(cfg["outputfn"], 'w', 0) # unbuffered write
 except:
-    print 'unable to open', cfg["outputfn"]
+    print('unable to open', cfg["outputfn"])
 
 
 #if not fakemode:
@@ -204,11 +204,11 @@
 params['enclaves'] = enclaves
 
 if sys.version_info[0] < 3:
-    import Tkinter
+    import tkinter
     #from Tkinter import *
-    import tkFileDialog
-    import tkFont
-    from tkFont import Font
+    import tkinter.filedialog
+    import tkinter.font
+    from tkinter.font import Font
     #from Tkinter.FileDialog import askopenfilename
 else:
     import tkinter
@@ -221,7 +221,7 @@
   def __init__(self, master, row=2, col=3):
 
         # Create a container
-        self.frame = Tkinter.Frame(master,width=200,height=100)
+        self.frame = tkinter.Frame(master,width=200,height=100)
         # Create 2 buttons
         #self.button_left = Tkinter.Button(frame,text="< Decrease Slope",
         #                               command=self.decrease)
@@ -290,14 +290,14 @@
         self.listFontFamily = ['serif', 'sans-serif', 'cursive', 'fantasy', 'monospace']
         self.listFontWeight = ['ultralight','light','normal','regular','book','medium','roman','semibold','demibold','demi','bold','heavy','extra bold','black']
 
-        self.list_fonts = list( tkFont.families() )
+        self.list_fonts = list( tkinter.font.families() )
 
         self.selectedFontPolicy = None
         self.selectedFontSize = None
         self.selectedFontWeight = None
        
         # create a custom font
-        self.customFont = tkFont.Font(family="Helvetica", size=12)
+        self.customFont = tkinter.font.Font(family="Helvetica", size=12)
  
         for idx in range(params['cfg']['nbgraphs']):
          self.listUsedGraphs.append(-1)
@@ -381,7 +381,7 @@
         try:       
           root.config(menu=menubar)
         except AttributeError as attErr:
-          print 'menu Exception: ', type(attErr), attErr 
+          print('menu Exception: ', type(attErr), attErr) 
 
         #self.winPvars()
         #self.winCvars()
@@ -393,27 +393,27 @@
         self.subSpawn(sos_db_file)
 
   def try_execute(self, c, statement, parameters=None):
-    print ("statement: ", statement)
-    print ("parameters: ", parameters)
+    print(("statement: ", statement))
+    print(("parameters: ", parameters))
     try:
         if parameters:
             c.execute(statement,parameters);
         else:
             c.execute(statement);
     except sqlite3.Error as e:
-        print("database error.....", e.args[0])
+        print(("database error.....", e.args[0]))
 
   def open_connection(self,sqlite_file):
     global conn
     # check for file to exist
     #print ("Checking for file: ", sqlite_file)
-    print ("Checking for file: ", "sosd.00000.db")
+    print(("Checking for file: ", "sosd.00000.db"))
     while not os.path.exists("sosd.00000.db"):
-        print ("Waiting on file: ", sqlite_file)
+        print(("Waiting on file: ", sqlite_file))
         time.sleep(1)
 
     #print("Connecting to: ", sqlite_file)
-    print("Connecting to: ", "sosd.00000.db")
+    print(("Connecting to: ", "sosd.00000.db"))
     # Connecting to the database file
     #conn = sqlite3.connect(sqlite_file)
     #fd = os.open(sqlite_file, os.O_RDONLY)
@@ -433,7 +433,7 @@
     return c
 
   def btnfontsupdate(self):
-       print 'Update font'
+       print('Update font')
        if self.selectedFontPolicy or self.selectedFontSize or self.selectedFontWeight:
          matplotlib.rcParams.update({'font.size': self.selectedFontSize, 'font.family': self.selectedFontPolicy})
          #self.customFont.configure(family=self.selectedFontPolicy)
@@ -442,40 +442,40 @@
          matplotlib.rc('font', **font)
 
   def ckbtnFontBold(self):
-        print 'Bold selected'
+        print('Bold selected')
 
   def ckbtnFontItalic(self):
-        print 'Italic selected'
+        print('Italic selected')
 
   def ckbtnFontUnderline(self):
-        print 'Underline selected'
+        print('Underline selected')
       
   def browsefontpolicy(self):
-        print 'browsefontpolicy'
-        fontpolicydiag = tkFileDialog.askopenfilename(filetypes=[("Text files","*.fft")])
+        print('browsefontpolicy')
+        fontpolicydiag = tkinter.filedialog.askopenfilename(filetypes=[("Text files","*.fft")])
 
   def onselectFontPolicy(self,evt):
         w = evt.widget
         selection = w.curselection()
         value = w.get(selection[0])
         self.selectedFontPolicy = value
-        print 'select font: ', value
+        print('select font: ', value)
 
   def onselectFontSize(self, evt):
-       print 'select font size'  
+       print('select font size')  
        w = evt.widget
        selection = w.curselection()
        value = w.get(selection[0])
        self.selectedFontSize = value
-       print 'select font: ', value
+       print('select font: ', value)
 
   def onselectFontWeight(self, evt):
-       print 'select font weight'  
+       print('select font weight')  
        w = evt.widget
        selection = w.curselection()
        value = w.get(selection[0])
        self.selectedFontWeight = value
-       print 'select font: ', value
+       print('select font: ', value)
 
   def loadFontPolicy(self):
         fontpolicydiag = askopenfilename(filetypes=(("*.fft"))) 
@@ -485,7 +485,7 @@
   #def cvarsmenu(self):
 
   def fontmenu(self):
-        print 'nothing'
+        print('nothing')
 
         self.paramswin = Tk.Tk()
         self.paramswin.title("Fonts: family, size and weight")
@@ -593,7 +593,7 @@
 
   def clearplot(self,idxGraph):
 
-       print 'clearplot: idxGraph=', idxGraph
+       print('clearplot: idxGraph=', idxGraph)
        ax = self.ax[idxGraph]
        ax.cla()    
        #ax.clf()
@@ -667,13 +667,13 @@
                         total_val=total_val+ref4
                         num_vals=num_vals+1
                         mean_val=total_val/num_vals
-                        print 'display record ref4='+str(ref4)
+                        print('display record ref4='+str(ref4))
                         self.data_lr[i].add(t,ref4)
                         #self.data_lr[i].add(t,mean_val)
                         goodrecord=1
 
         if goodrecord==0:
-                print 'bad record'
+                print('bad record')
                 return        
 
   def updategui3(self, params, rows):
@@ -684,7 +684,7 @@
         total_val=0
         num_vals=0
 
-	print '[PYCOOLR] Starting update gui'
+	print('[PYCOOLR] Starting update gui')
         #if sample['node'] == params['targetnode'] and sample['sample'] == 'tau':
             #
             # data handling
@@ -705,9 +705,9 @@
 
                   #print("Fetching rows.")
                   rows[j] = self.conn.fetchall()
-                  print 'row: ', rows[j]
+                  print('row: ', rows[j])
                   if len(rows[j]) <= 0:
-                    print("Error: query returned no rows.",)
+                    print(("Error: query returned no rows.",))
                   else:
                    goodrecord = 1
 
@@ -738,7 +738,7 @@
                 try:
                   ax.cla()
                 except Exception as errCla:
-                  print 'update_gui: Error cla(): ', type(errCla), errCla
+                  print('update_gui: Error cla(): ', type(errCla), errCla)
 
                 #ax.set_xlim([t-gxsec, t])
                 #print 'get x and y'
@@ -852,7 +852,7 @@
         try:
            ax.cla()
         except Exception as errCla:
-          print 'update_gui: Error cla(): ', type(errCla), errCla
+          print('update_gui: Error cla(): ', type(errCla), errCla)
 
         ax.set_xlim([pack_time-gxsec, pack_time])
         #print 'get x and y'
@@ -910,7 +910,7 @@
         graphs = [None, None, None, None, None, None]
         axises = [None, None, None, None, None, None]
 
-	print '[PYCOOLR] Starting update gui'
+	print('[PYCOOLR] Starting update gui')
         #if sample['node'] == params['targetnode'] and sample['sample'] == 'tau':
             #
             # data handling
@@ -931,9 +931,9 @@
 
                   #print("Fetching rows.")
                   rows[j] = self.conn.fetchall()
-                  print 'rows: ', rows[j]
+                  print('rows: ', rows[j])
                   if len(rows[j]) <= 0:
-                    print("Error: query returned no rows.",)
+                    print(("Error: query returned no rows.",))
                   else:
                    goodrecord = 1
 
@@ -967,7 +967,7 @@
                   graph = {}  
 
                 if newplot:
-                  print 'newplot True'
+                  print('newplot True')
                   axis = pl.subplot(1)
                   axis.set_title("Time per iteration");
                   graph[r] = (pl.plot(pack_time, metric_values, marker='*', linestyle='-', label=str(r))[0])
@@ -977,7 +977,7 @@
                   pl.ylabel("Seconds")
                   pl.xlabel("Timestamp")
                 else:
-                  print 'newplot False'
+                  print('newplot False')
                   #axis = pl.subplot(321)
                   graph[r].set_data(pack_time, metric_values)
                   axis.relim()        # Recalculate limits
@@ -1076,7 +1076,7 @@
                 try:
                   ax.cla()
                 except Exception as errCla:
-                  print 'update_gui: Error cla(): ', type(errCla), errCla
+                  print('update_gui: Error cla(): ', type(errCla), errCla)
 
                 ax.set_xlim([t-gxsec, t])
                 #print 'get x and y'
@@ -1136,7 +1136,7 @@
 
   def subscribe(self,libarbjsonbeep):
 
-     print 'start thread with Subscribe'
+     print('start thread with Subscribe')
 
      listargs = ['MEMORY','NODE_POWER_WATTS','MPI_T_PVAR']
 
@@ -1145,7 +1145,7 @@
 
   def publish(self,libarbpubcvars):
 
-     print 'start thread with Publish'
+     print('start thread with Publish')
 
      #listargs = ['MEMORY','NODE_POWER_WATTS','MPI_T_PVAR']
 
@@ -1211,11 +1211,11 @@
              payload += resultPayload[j]
 
            payload.strip()
-           print 'payload =',payload
+           print('payload =',payload)
            try:
              j = json.loads(payload)
            except ValueError as e:
-             print 'Failed to load json data: %s' %e
+             print('Failed to load json data: %s' %e)
              continue
              #return False
 
@@ -1250,7 +1250,7 @@
          if 'node' not in e and\
             'sample' not in e and\
             'time' not in e:
-             print 'Ignore this invalid sample:', json.dumps(e)
+             print('Ignore this invalid sample:', json.dumps(e))
              continue
 
          #print 'set timestamp'
@@ -1278,11 +1278,11 @@
        #print 'finished parsing listEvents'
        #draw to refresh plotting
        #layout.canvas.draw()
-       print 'draw canvas'
+       print('draw canvas')
        try:
          self.canvas.draw()
        except Exception as errDraw:
-         print 'Error drawing canvas: ', type(errDraw), errDraw
+         print('Error drawing canvas: ', type(errDraw), errDraw)
        #plt.draw()
 
        profile_t7 = time.time()
@@ -1364,10 +1364,10 @@
     all_rows = c.fetchall()
     ts = np.array([x[0] for x in all_rows])
     min_timestamp = ts[0]
-    print("min timestamp: ", min_timestamp)
+    print(("min timestamp: ", min_timestamp))
 
   def req_sql(self, c, ranks, ranks2, group_column, metric):
-    print 'req_sql entering'
+    print('req_sql entering')
     for r in ranks:
         sql_statement = ("SELECT distinct tbldata.name, tblvals.val, tblvals.time_pack, tblpubs.comm_rank FROM tblvals INNER JOIN tbldata ON tblvals.guid = tbldata.guid INNER JOIN tblpubs ON tblpubs.guid = tbldata.pub_guid WHERE tblvals.guid IN (SELECT guid FROM tbldata WHERE tbldata.name LIKE '" + metric + "') AND tblpubs." + group_column)
         """
@@ -1414,15 +1414,15 @@
             sql_statement = (sql_statement + " like '" + r + "' and tblvals.val > 0 order by tblvals.time_pack;")
 
         #params = [metric,r]
-        print "Executing query: ", sql_statement,
+        print("Executing query: ", sql_statement, end=' ')
         self.try_execute(c, sql_statement)
-        print "Done. "
+        print("Done. ")
 
         #print("Fetching rows.")
         all_rows = c.fetchall()
         if len(all_rows) <= 0:
-            print("Error: query returned no rows.",)
-            print(sql_statement, params)
+            print(("Error: query returned no rows.",))
+            print((sql_statement, params))
 
         #print("Making numpy array of: metric_values")
         metric_values = np.array([max(x[1],0) for x in all_rows])
@@ -1464,14 +1464,14 @@
     while self.ranks.size == 0:
         time.sleep(1)
         self.ranks,self.procs = self.get_ranks(self.conn)
-    print ("ranks: ", self.ranks)
+    print(("ranks: ", self.ranks))
 
     # get the number of nodes
     self.nodes,self.noderanks = self.get_nodes(self.conn)
     while self.nodes.size == 0:
         time.sleep(1)
         nodes,self.noderanks = self.get_nodes(self.conn)
-    print ("nodes: ", self.nodes)
+    print(("nodes: ", self.nodes))
 
     self.get_min_timestamp(self.conn)
     #resize the figure
@@ -1496,11 +1496,11 @@
 
   def readsosmetrics(self,arguments):
 
-     print 'readsosmetrics'
+     print('readsosmetrics')
      profile_t1 = time.time()
      self.opendb(arguments)
     
-     print 'after opening db, read db and plot ....'
+     print('after opening db, read db and plot ....')
  
      while True:
 
@@ -1510,7 +1510,7 @@
          if self.listRecordSample[i] != -1:
            j = self.listRecordSample[i]
      
-           print 'readsosmetrics: i=%d, j=%d' %(i,j)
+           print('readsosmetrics: i=%d, j=%d' %(i,j))
            
            #rank = self.ranks[j]
            #rank2 = self.ranks2[j]
@@ -1528,7 +1528,7 @@
            self.rows[j] = self.conn.fetchall()
            #print 'rows: ', self.rows[j]
            if len(self.rows[j]) <= 0:
-             print("Error: query returned no rows.",)
+             print(("Error: query returned no rows.",))
            else:
              goodrecord = 1
          
@@ -1546,7 +1546,7 @@
 
   def readEvents(self,libarbjsonbeep):
 
-    print '[PYCOOLR] readEvents begin'
+    print('[PYCOOLR] readEvents begin')
 
     low_index = 0
     high_index = 0
@@ -1622,7 +1622,7 @@
            try:
              j = json.loads(payload)
            except ValueError as e:
-             print 'Failed to load json data: %s' %e
+             print('Failed to load json data: %s' %e)
              continue
              #return False
 
@@ -1657,7 +1657,7 @@
          if 'node' not in e and\
             'sample' not in e and\
             'time' not in e:
-             print 'Ignore this invalid sample:', json.dumps(e)
+             print('Ignore this invalid sample:', json.dumps(e))
              continue
 
          #print 'set timestamp'
@@ -1714,7 +1714,7 @@
 
   def subSpawn(self,arguments):
 
-     print 'subSpawn: load beacon subscriber library'
+     print('subSpawn: load beacon subscriber library')
      envlibpath = os.environ['PYCOOLR_LIBPATH']
      libarbjsonbeep = cdll.LoadLibrary(envlibpath+'/libarbitraryjsonbeepmulsub.so')
 
@@ -1727,10 +1727,10 @@
 
      try:
        #thread.start_new_thread(self.subscribe,(libarbjsonbeep,))
-       thread.start_new_thread(self.readsosmetrics,(arguments,))
+       _thread.start_new_thread(self.readsosmetrics,(arguments,))
       
      except Exception as errThread:
-       print 'Error: unable to start thread: ', errThread
+       print('Error: unable to start thread: ', errThread)
 
      self.refresh_plot()
      #self.readEvents(libarbjsonbeep)
@@ -1751,7 +1751,7 @@
           #print "selection:", selection, ": '%s'" % value
          
         listintselection = [int (i) for i in selection]
-        print 'listintselection: ', listintselection
+        print('listintselection: ', listintselection)
 
         for i in range(self.nbsamples):
           if (self.listSamplesAllocated[i] > -1) and (i not in listintselection):
@@ -1766,7 +1766,7 @@
               if self.listSamplesAllocated[j] == -1:    
                 #index = int(j)
                 self.listUsedGraphs[i] = j
-                print 'graph %d allocated to sample %d' % (i, j)
+                print('graph %d allocated to sample %d' % (i, j))
                 self.listRecordSample[i] = j
                 self.listSamplesAllocated[j] = i
                 break
@@ -1792,7 +1792,7 @@
                 # Mark current graph as used
                 self.listUsedGraphs[j] = 1           
                 # Record the current graph as plotting the current sample
-                print 'Record Sample %d for graph %d' %(index,j)
+                print('Record Sample %d for graph %d' %(index,j))
                 self.listRecordSample[j] = index
 
                 # Mark current sample as allocated to the current graph
@@ -1893,21 +1893,21 @@
          self.canvas.draw()
          #self.frame.update()
        except Exception as errDraw:
-         print 'refresh_plot: Error drawing canvas: ', type(errDraw), errDraw
+         print('refresh_plot: Error drawing canvas: ', type(errDraw), errDraw)
        self.lock.release()
 
        self.root.after(1000,self.refresh_plot)      
 
   def updatebtn(self):
-       print 'update buttonupdate button'
+       print('update buttonupdate button')
        try:
          self.canvas.draw()
        except Exception as errDraw:
-         print 'Error drawing canvas: ', type(errDraw), errDraw
+         print('Error drawing canvas: ', type(errDraw), errDraw)
 
   def checkfn(self, idx, text): 
-       print 'checkfn'
-       print 'Check index=%d text=%s' % (idx,text)
+       print('checkfn')
+       print('Check index=%d text=%s' % (idx,text))
        #print 'Size of listbtnchecked[]= ', len(self.listbtnchecked)
        #self.listbtnchecked[idx] = 1
 
@@ -1916,7 +1916,7 @@
 #     print 'nothing'
       
 
-root = Tkinter.Tk()
+root = tkinter.Tk()
 
 app = Coolrsub(root,2,3)
 root.mainloop()
--- a/examples/sos/pycoolrgui/pycoolr-plot/coolr.py	(original)
--- b/examples/sos/pycoolrgui/pycoolr-plot/coolr.py	(refactored)
@@ -1,7 +1,7 @@
 #!/usr/bin/env python
 
 #import sys, os, re, _thread, signal
-import sys, os, re, thread, signal
+import sys, os, re, _thread, signal
 #from cStringIO import StringIO
 from io import StringIO
 import subprocess
@@ -147,10 +147,10 @@
     with open(cfgfn) as f:
         cfgtmp = json.load(f)
         # override if cfg defines any
-        for k in cfgtmp.keys():
+        for k in list(cfgtmp.keys()):
             cfg[k] = cfgtmp[k]
         # override if specifed as cmd option
-        for k in ocfg.keys():
+        for k in list(ocfg.keys()):
             cfg[k] = ocfg[k]
 
 
@@ -158,21 +158,21 @@
     targetnode = os.environ['PYCOOLR_NODE']
     #targetnode = cfg['masternode']
 if len(enclaves) == 0:
-    if cfg.has_key('enclaves'):
+    if 'enclaves' in cfg:
         enclaves = cfg['enclaves']
 
 #print 'masternode:', cfg['masternode']
-print('targetnode:', targetnode)
-print('enclaves:', enclaves)
+print(('targetnode:', targetnode))
+print(('enclaves:', enclaves))
 
 if len(appcfgfn) > 0:
     with open(appcfgfn) as f:
         appcfg = json.load(f)
-    for k in appcfg.keys():
+    for k in list(appcfg.keys()):
         cfg[k] = appcfg[k]
 
-    if not (cfg.has_key('appname') and cfg.has_key('appsamples')):
-        print("Please double check %s: appname or appsamples tags" % appcfgfn)
+    if not ('appname' in cfg and 'appsamples' in cfg):
+        print(("Please double check %s: appname or appsamples tags" % appcfgfn))
         sys.exit(1)
 
 
@@ -188,7 +188,7 @@
 try:
     logf = open(cfg["outputfn"], 'w', 0) # unbuffered write
 except:
-    print('unable to open', cfg["outputfn"])
+    print(('unable to open', cfg["outputfn"]))
 
 
 #if not fakemode:
@@ -211,11 +211,11 @@
 params['enclaves'] = enclaves
 
 if sys.version_info[0] < 3:
-    import Tkinter
+    import tkinter
     #from Tkinter import *
-    import tkFileDialog
-    import tkFont
-    from tkFont import Font
+    import tkinter.filedialog
+    import tkinter.font
+    from tkinter.font import Font
     #from Tkinter.FileDialog import askopenfilename
 else:
     import tkinter
@@ -228,7 +228,7 @@
   def __init__(self, master, row=2, col=3):
 
         # Create a container
-        self.frame = Tkinter.Frame(master,width=200,height=100)
+        self.frame = tkinter.Frame(master,width=200,height=100)
         # Create 2 buttons
         #self.button_left = Tkinter.Button(frame,text="< Decrease Slope",
         #                               command=self.decrease)
@@ -280,10 +280,10 @@
 	        sql_statement = ("SELECT MAX(frame) FROM tblVals;")
 	        self.try_execute(self.conn, sql_statement)
 	        query_result = self.conn.fetchall()
-	        print("query_result", query_result[0][0])
+	        print(("query_result", query_result[0][0]))
 	        if type(query_result[0][0]) == int:
 	        	frame = int(query_result[0][0])
-	        print("frame", frame)
+	        print(("frame", frame))
         self.metricsDB = ""
         #Get the metric's names
     	#sql_statement = ("SELECT distinct(value_name), comm_rank FROM viewCombined where frame > 0 ORDER BY value_name, comm_rank;")
@@ -299,13 +299,13 @@
         params['cfg']['units'] = ["KB" if (metric[0].find("KB") > -1) else "counts"  for metric in self.metrics]
         params['cfg']['units'] = ["#Events" if (metric[0].find("NumEvents") > -1)  else units for metric,units in zip(self.metrics,params['cfg']['units'])]
         print("---------------------------------------------------------------------------------------------------------")
-        print("self.nbsamples",self.nbsamples)
-        print("self.listmetrics",self.listmetrics)
+        print(("self.nbsamples",self.nbsamples))
+        print(("self.listmetrics",self.listmetrics))
 
 
 
         #self.metrics = params['cfg']['metrics']
-        print("self.metrics", self.metrics)
+        print(("self.metrics", self.metrics))
         #self.ranks = params['cfg']['ranks']
         self.ranks = [None] * self.nbsamples
         self.procs = [None] * self.nbsamples
@@ -357,14 +357,14 @@
         self.listFontFamily = ['serif', 'sans-serif', 'cursive', 'fantasy', 'monospace']
         self.listFontWeight = ['ultralight','light','normal','regular','book','medium','roman','semibold','demibold','demi','bold','heavy','extra bold','black']
 
-        self.list_fonts = list( tkFont.families() )
+        self.list_fonts = list( tkinter.font.families() )
 
         self.selectedFontPolicy = None
         self.selectedFontSize = None
         self.selectedFontWeight = None
        
         # create a custom font
-        self.customFont = tkFont.Font(family="Helvetica", size=12)
+        self.customFont = tkinter.font.Font(family="Helvetica", size=12)
  
         for idx in range(params['cfg']['nbgraphs']):
          self.listUsedGraphs.append(-1)
@@ -453,7 +453,7 @@
         try:       
           root.config(menu=menubar)
         except AttributeError as attErr:
-          print('menu Exception: ', type(attErr), attErr)
+          print(('menu Exception: ', type(attErr), attErr))
 
         #self.winPvars()
         #self.winCvars()
@@ -461,27 +461,27 @@
         self.subSpawn()
 
   def try_execute(self, c, statement, parameters=None):
-    print ("statement: ", statement)
-    print ("parameters: ", parameters)
+    print(("statement: ", statement))
+    print(("parameters: ", parameters))
     try:
         if parameters:
             c.execute(statement,parameters);
         else:
             c.execute(statement);
     except sqlite3.Error as e:
-        print("database error...", e.args[0])
+        print(("database error...", e.args[0]))
 
   def open_connection(self):
     global conn
     # check for file to exist
     #print ("Checking for file: ", sqlite_file)
-    print("Checking for file: ", self.sosdbfile)
+    print(("Checking for file: ", self.sosdbfile))
     while not os.path.exists(self.sosdbfile):
-        print("Waiting on file: ", self.sosdbfile)
+        print(("Waiting on file: ", self.sosdbfile))
         time.sleep(1)
 
     #print("Connecting to: ", sqlite_file)
-    print("Connecting to: ", self.sosdbfile)
+    print(("Connecting to: ", self.sosdbfile))
     # Connecting to the database file
     #conn = sqlite3.connect(sqlite_file)
     #fd = os.open(sqlite_file, os.O_RDONLY)
@@ -520,14 +520,14 @@
       
   def browsefontpolicy(self):
         print('browsefontpolicy')
-        fontpolicydiag = tkFileDialog.askopenfilename(filetypes=[("Text files","*.fft")])
+        fontpolicydiag = tkinter.filedialog.askopenfilename(filetypes=[("Text files","*.fft")])
 
   def onselectFontPolicy(self,evt):
         w = evt.widget
         selection = w.curselection()
         value = w.get(selection[0])
         self.selectedFontPolicy = value
-        print('select font: ', value)
+        print(('select font: ', value))
 
   def onselectFontSize(self, evt):
        print('select font size')
@@ -535,7 +535,7 @@
        selection = w.curselection()
        value = w.get(selection[0])
        self.selectedFontSize = value
-       print('select font: ', value)
+       print(('select font: ', value))
 
   def onselectFontWeight(self, evt):
        print('select font weight')
@@ -543,7 +543,7 @@
        selection = w.curselection()
        value = w.get(selection[0])
        self.selectedFontWeight = value
-       print('select font: ', value)
+       print(('select font: ', value))
 
   def loadFontPolicy(self):
         fontpolicydiag = askopenfilename(filetypes=(("*.fft"))) 
@@ -636,8 +636,8 @@
         #f1 = Tk.Frame(pvarswin,width=150,height=100) 
         s1 = Tk.Scrollbar(self.f1) 
 	#l1 = Tk.Listbox(f1,selectmode='multiple',width=80,height=40)
-        print("self.listmetrics",self.listmetrics)
-        print("len(self.listmetrics)",len(self.listmetrics))
+        print(("self.listmetrics",self.listmetrics))
+        print(("len(self.listmetrics)",len(self.listmetrics)))
 
 
         for i in range(self.nbsamples): 
@@ -702,7 +702,7 @@
 
   def clearplot(self,idxGraph):
 
-       print('clearplot: idxGraph=', idxGraph)
+       print(('clearplot: idxGraph=', idxGraph))
        ax = self.ax[idxGraph]
        ax.cla()    
        #ax.clf()
@@ -776,7 +776,7 @@
                         total_val=total_val+ref4
                         num_vals=num_vals+1
                         mean_val=total_val/num_vals
-                        print('display record ref4='+str(ref4))
+                        print(('display record ref4='+str(ref4)))
                         self.data_lr[i].add(t,ref4)
                         #self.data_lr[i].add(t,mean_val)
                         goodrecord=1
@@ -851,7 +851,7 @@
                 try:
                   ax.cla()
                 except Exception as errCla:
-                  print('update_gui: Error cla(): ', type(errCla), errCla)
+                  print(('update_gui: Error cla(): ', type(errCla), errCla))
 
                 ax.set_xlim([t-gxsec, t])
                 #print 'get x and y'
@@ -935,7 +935,7 @@
 
         #print 'parse graphs'
         metric_value = max(sample[1],0)
-        print("metric_value",metric_value)
+        print(("metric_value",metric_value))
         numeric = re.search(r'\d+', metric_value)
         metric_value_num = numeric.group()
         metric_value_float = float(metric_value_num)
@@ -961,7 +961,7 @@
         try:
            ax.cla()
         except Exception as errCla:
-          print('update_gui: Error cla(): ', type(errCla), errCla)
+          print(('update_gui: Error cla(): ', type(errCla), errCla))
 
         ax.set_xlim([pack_time-gxsec, pack_time])
         #print 'get x and y'
@@ -1071,7 +1071,7 @@
         try:
            ax.cla()
         except Exception as errCla:
-          print('update_gui: Error cla(): ', type(errCla), errCla)
+          print(('update_gui: Error cla(): ', type(errCla), errCla))
 
         ax.set_xlim([pack_time-gxsec, pack_time])
         #print 'get x and y'
@@ -1199,7 +1199,7 @@
            try:
              j = json.loads(payload)
            except ValueError as e:
-             print('Failed to load json data: %s' %e)
+             print(('Failed to load json data: %s' %e))
              continue
              #return False
 
@@ -1234,7 +1234,7 @@
          if 'node' not in e and\
             'sample' not in e and\
             'time' not in e:
-             print('Ignore this invalid sample:', json.dumps(e))
+             print(('Ignore this invalid sample:', json.dumps(e)))
              continue
 
          #print 'set timestamp'
@@ -1266,7 +1266,7 @@
        try:
          self.canvas.draw()
        except Exception as errDraw:
-         print('Error drawing canvas: ', type(errDraw), errDraw)
+         print(('Error drawing canvas: ', type(errDraw), errDraw))
        #plt.draw()
 
        profile_t7 = time.time()
@@ -1348,7 +1348,7 @@
     all_rows = c.fetchall()
     ts = np.array([x[0] for x in all_rows])
     min_timestamp = ts[0]
-    print("min timestamp: ", min_timestamp)
+    print(("min timestamp: ", min_timestamp))
 
 
   def get_min_timestamp(self):
@@ -1356,25 +1356,25 @@
     sql_statement = ("SELECT min(time_pack) FROM viewCombined;")
     print("get_min_timestamp Executing query")
  
-    print("sql statement: ", sql_statement)
+    print(("sql statement: ", sql_statement))
     #self.try_execute(c, sql_statement)
     os.environ['SOS_SQL'] = sql_statement
     sos_bin_path = os.environ.get('SOS_BIN_DIR')
-    print('SOS BIN path: ', sos_bin_path)
+    print(('SOS BIN path: ', sos_bin_path))
     os.system('cd '+ sos_bin_path)
-    print('current dir: ', os.getcwd())
+    print(('current dir: ', os.getcwd()))
     # Redirect stdout of passed command into a string
 
     soscmd = sos_bin_path + "/demo_app_silent --sql SOS_SQL"
-    print('soscmd: ', soscmd)
+    print(('soscmd: ', soscmd))
     tmp_res_min_ts_sql = subprocess.check_output(soscmd, shell=True)
 
     #self.res_min_ts_sql = tmp_res_min_ts_sql.splitlines()
-    print('get min ts: tmp res sql=', tmp_res_min_ts_sql)
+    print(('get min ts: tmp res sql=', tmp_res_min_ts_sql))
     res_min_ts_sql = tmp_res_min_ts_sql.splitlines()
-    print("List of result SQL MIN TS: ", res_min_ts_sql)
+    print(("List of result SQL MIN TS: ", res_min_ts_sql))
     min_ts_rows = res_min_ts_sql[1].split(",")
-    print("List of result SQL MIN TS values: ", min_ts_rows)
+    print(("List of result SQL MIN TS values: ", min_ts_rows))
     # Remove first element of SQL result 
     #ts = np.array([x[0] for x in min_ts_rows])
     str_min_timestamp = min_ts_rows[0].replace('\"', '')
@@ -1416,31 +1416,31 @@
     sql_statement = ("SELECT value_name, value, time_pack FROM viewCombined WHERE value_name LIKE '" + metric+ "'")
     #sql_statement = ("SELECT * FROM viewCombined WHERE value_name LIKE '" + metric+ "'")
    
-    print("sql statement: ", sql_statement )
+    print(("sql statement: ", sql_statement ))
     #self.try_execute(c, sql_statement)
     os.environ['SOS_SQL'] = sql_statement
     sos_bin_path = os.environ.get('SOS_BIN_DIR')
-    print('SOS BIN path: ', sos_bin_path)
+    print(('SOS BIN path: ', sos_bin_path))
     os.system('cd '+ sos_bin_path)  
-    print('current dir: ', os.getcwd()) 
+    print(('current dir: ', os.getcwd())) 
     # Redirect stdout of passed command into a string
    
     soscmd = sos_bin_path + "/demo_app_silent --sql SOS_SQL"
-    print('soscmd: ', soscmd)
+    print(('soscmd: ', soscmd))
     tmp_res_sql = subprocess.check_output(soscmd, shell=True)
 
     self.try_execute(c, sql_statement)
 
     #print 'stdout of SOS demo: ', sys.stdout
     #self.res_sql = resultstdout.getvalue()
-    print('tmp res_sql: ', tmp_res_sql)
+    print(('tmp res_sql: ', tmp_res_sql))
     
     self.res_sql = tmp_res_sql.splitlines()
     # REmove first element of SQL result 
     self.res_sql.pop(0)
 
     for item_sql in self.res_sql:
-      print('res sql: ', item_sql) 
+      print(('res sql: ', item_sql)) 
       
  
   # Call demo with SQL statement given as argument and store standard output
@@ -1448,8 +1448,8 @@
     print('req_sql entering')
     self.res_sql = ""
     for elem in metric:
-        print("elem: ", elem)
-    print("metric",metric[0])
+        print(("elem: ", elem))
+    print(("metric",metric[0]))
     sql_statement = ("SELECT value_name, value, time_pack, max(frame) FROM viewCombined WHERE value_name LIKE '" + metric[0]+ "' AND comm_rank="+ str(metric[1]) +" group by value_name;")
     #sql_statement = ("SELECT * FROM viewCombined WHERE value_name LIKE '" + metric+ "'")
    
@@ -1473,14 +1473,14 @@
     while self.ranks.size == 0:
         time.sleep(1)
         self.ranks,self.procs = self.get_ranks(self.conn)
-    print ("ranks: ", self.ranks)
+    print(("ranks: ", self.ranks))
 
     # get the number of nodes
     self.nodes,self.noderanks = self.get_nodes(self.conn)
     while self.nodes.size == 0:
         time.sleep(1)
         nodes,self.noderanks = self.get_nodes(self.conn)
-    print ("nodes: ", self.nodes)
+    print(("nodes: ", self.nodes))
 
     self.get_min_timestamp_db(self.conn)
     #resize the figure
@@ -1507,7 +1507,7 @@
     print('SOS: Execute demo app')
     sos_path = os.environ.get('SOS_BUILD_DIR') 
     self.sos_bin_path = sos_path+"/bin"
-    print('SOS BIN PATH: ', self.sos_bin_path)
+    print(('SOS BIN PATH: ', self.sos_bin_path))
     os.system("cd "+ self.sos_bin_path) 
 
 
@@ -1519,7 +1519,7 @@
 
     self.opendb()
 
-    print("metrics: ", self.metrics)
+    print(("metrics: ", self.metrics))
     #self.get_min_timestamp()  
  
     while True:  
@@ -1555,7 +1555,7 @@
            countsamples = 0
            for sample in self.rows[j]:
              params['ts'] = 0
-             print 'PYCOOLR sample: ', sample
+             print('PYCOOLR sample: ', sample)
              #self.req_sql(self.conn, self.ranks, self.rows)
              profile_t2 = time.time()
              self.lock.acquire()
@@ -1585,7 +1585,7 @@
          if self.listRecordSample[i] != -1:
            j = self.listRecordSample[i]
      
-           print('readsosmetrics: i=%d, j=%d' %(i,j))
+           print(('readsosmetrics: i=%d, j=%d' %(i,j)))
            
            #rank = self.ranks[j]
            #rank2 = self.ranks2[j]
@@ -1603,7 +1603,7 @@
            self.rows[j] = self.conn.fetchall()
            #print 'rows: ', self.rows[j]
            if len(self.rows[j]) <= 0:
-             print("Error: query returned no rows.",)
+             print(("Error: query returned no rows.",))
            else:
              goodrecord = 1
          
@@ -1690,11 +1690,11 @@
 
 
            payload.strip()
-           print('payload =',payload)
+           print(('payload =',payload))
            try:
              j = json.loads(payload)
            except ValueError as e:
-             print('Failed to load json data: %s' %e)
+             print(('Failed to load json data: %s' %e))
              continue
              #return False
 
@@ -1729,7 +1729,7 @@
          if 'node' not in e and\
             'sample' not in e and\
             'time' not in e:
-             print('Ignore this invalid sample:', json.dumps(e))
+             print(('Ignore this invalid sample:', json.dumps(e)))
              continue
 
          #print 'set timestamp'
@@ -1799,20 +1799,20 @@
          print('subSpawn: load beacon subscriber library')
          envlibpath = os.environ['PYCOOLR_LIBPATH']
          libarbjsonbeep = cdll.LoadLibrary(envlibpath+'/libarbitraryjsonbeepmulsub.so')
-         thread.start_new_thread(self.subscribe,(libarbjsonbeep,))
-         thread.start_new_thread(self.readEvents,(libarbjsonbeep,))
+         _thread.start_new_thread(self.subscribe,(libarbjsonbeep,))
+         _thread.start_new_thread(self.readEvents,(libarbjsonbeep,))
          #thread.start_new_thread(self.readEvents,(libarbjsonbeep,))
        except Exception as errThread:
-         print("Error: unable to start thread: ", errThread)
+         print(("Error: unable to start thread: ", errThread))
 
      elif self.tool == "sos":
        try:
          #thread.start_new_thread(self.subscribe,(libarbjsonbeep,))
-         thread.start_new_thread(self.readsosmetrics,())
+         _thread.start_new_thread(self.readsosmetrics,())
          #thread.start_new_thread(self.readsosmetrics_db,())
       
        except Exception as errThread:
-         print('Error: unable to start thread: ', errThread)
+         print(('Error: unable to start thread: ', errThread))
 
 
      self.refresh_plot()
@@ -1845,7 +1845,7 @@
 
             self.selectedcvarsvalues[i] =  self.listcvarsentry[i].get()
             strcvarsvalues += self.selectedcvarsvalues[i]
-            print('numselectedcvars=%d, index=%d' % (self.numselectedcvars, i))
+            print(('numselectedcvars=%d, index=%d' % (self.numselectedcvars, i)))
             if i+1 < self.numselectedcvars:
               strcvarsmetrics += ","
               strcvarsvalues += ","
@@ -1858,7 +1858,7 @@
             #self.strcvars += "=" 
             #self.strcvars += self.selectedcvarsvalues[i]
             #strcvars += ","
-            print('numselectedcvars=%d, index=%d' % (self.numselectedcvars, i))
+            print(('numselectedcvars=%d, index=%d' % (self.numselectedcvars, i)))
             if i+1 < self.numselectedcvars:
               strcvarsmetrics += ","
               strcvarsvalues += ","
@@ -1869,9 +1869,9 @@
         #self.strcvars += ":"
         self.strcvars += strcvarsvalues
 
-        print("strcvarsmetrics: ", strcvarsmetrics)
-        print("strcvarsvalues: ", strcvarsvalues)
-        print("strcvars: ", self.strcvars)
+        print(("strcvarsmetrics: ", strcvarsmetrics))
+        print(("strcvarsvalues: ", strcvarsvalues))
+        print(("strcvars: ", self.strcvars))
 
         # Test if we have to communicate MPI_T CVARS in a Publish/Subscribe mode       
         if cvars_comm_mode == "pub":
@@ -1907,7 +1907,7 @@
 
         for i in range(len(selection)):
           value = w.get(selection[i])
-          print("selection:", selection, ": '%s'" % value)
+          print(("selection:", selection, ": '%s'" % value))
           self.selectedcvarsmetrics[i] = value
 
         if self.listlabelcvarsmetric:
@@ -1929,19 +1929,19 @@
         self.listcvarsarrayindexentry = [None] * len(selection)
         self.listcvarsarrayindex = [None] * len(selection)
 
-        print('selection: ', selection)
-        print('range selection: ', range(len(selection)))
-
-        for cvaritem, cvarindex in zip(selection, range(len(selection))):
+        print(('selection: ', selection))
+        print(('range selection: ', list(range(len(selection)))))
+
+        for cvaritem, cvarindex in zip(selection, list(range(len(selection)))):
 
           value = w.get(selection[cvarindex])
-          print('len selection: ', len(selection))
-          print('value of item %d: %s ' % (cvarindex, value))
-          print('cvaritem: ', cvaritem)
-          print('cvarindex= ', cvarindex)
-          print('cvarsindexrow= ', self.cvarsindexrow)
-
-          print('cfg cvars array:', self.listcfgcvarsarray[0])
+          print(('len selection: ', len(selection)))
+          print(('value of item %d: %s ' % (cvarindex, value)))
+          print(('cvaritem: ', cvaritem))
+          print(('cvarindex= ', cvarindex))
+          print(('cvarsindexrow= ', self.cvarsindexrow))
+
+          print(('cfg cvars array:', self.listcfgcvarsarray[0]))
           if value == self.listcfgcvarsarray[0]:
 
             self.listlabelcvarsmetric[cvarindex]=Tk.Label(self.stepCvarsUpdate,  text=value)
@@ -1989,10 +1989,10 @@
           #print "selection:", selection, ": '%s'" % value
          
         listintselection = [int (i) for i in selection]
-        print('listintselection: ', listintselection)
-        print('listSamplesAllocated: ', self.listSamplesAllocated)
-        print('nbsamples', self.nbsamples)
-        print('len(self.listSamplesAllocated)', len(self.listSamplesAllocated))
+        print(('listintselection: ', listintselection))
+        print(('listSamplesAllocated: ', self.listSamplesAllocated))
+        print(('nbsamples', self.nbsamples))
+        print(('len(self.listSamplesAllocated)', len(self.listSamplesAllocated)))
 
         for i in range(self.nbsamples):
           if (self.listSamplesAllocated[i] > -1) and (i not in listintselection):
@@ -2007,7 +2007,7 @@
               if self.listSamplesAllocated[j] == -1:    
                 #index = int(j)
                 self.listUsedGraphs[i] = j
-                print('graph %d allocated to sample %d' % (i, j))
+                print(('graph %d allocated to sample %d' % (i, j)))
                 self.listRecordSample[i] = j
                 self.listSamplesAllocated[j] = i
                 break
@@ -2033,7 +2033,7 @@
                 # Mark current graph as used
                 self.listUsedGraphs[j] = 1           
                 # Record the current graph as plotting the current sample
-                print('Record Sample %d for graph %d' %(index,j))
+                print(('Record Sample %d for graph %d' %(index,j)))
                 self.listRecordSample[j] = index
 
                 # Mark current sample as allocated to the current graph
@@ -2134,7 +2134,7 @@
          self.canvas.draw()
          #self.frame.update()
        except Exception as errDraw:
-         print('refresh_plot: Error drawing canvas: ', type(errDraw), errDraw)
+         print(('refresh_plot: Error drawing canvas: ', type(errDraw), errDraw))
        self.lock.release()
 
        self.root.after(1000,self.refresh_plot)      
@@ -2144,11 +2144,11 @@
        try:
          self.canvas.draw()
        except Exception as errDraw:
-         print('Error drawing canvas: ', type(errDraw), errDraw)
+         print(('Error drawing canvas: ', type(errDraw), errDraw))
 
   def checkfn(self, idx, text): 
        print('checkfn')
-       print('Check index=%d text=%s' % (idx,text))
+       print(('Check index=%d text=%s' % (idx,text)))
        #print 'Size of listbtnchecked[]= ', len(self.listbtnchecked)
        #self.listbtnchecked[idx] = 1
 
@@ -2157,7 +2157,7 @@
 #     print 'nothing'
       
 
-root = Tkinter.Tk()
+root = tkinter.Tk()
 
 app = Coolrsub(root,2,3)
 root.mainloop()
--- a/examples/sos/pycoolrgui/pycoolr-plot/init_coolr.py	(original)
--- b/examples/sos/pycoolrgui/pycoolr-plot/init_coolr.py	(refactored)
@@ -38,8 +38,8 @@
 try:
     opts, args = getopt.getopt(sys.argv[1:],
                                shortopt, longopt)
-except getopt.GetoptError, err:
-    print err
+except getopt.GetoptError as err:
+    print(err)
     usage()
     sys.exit(1)
 
@@ -65,21 +65,21 @@
     elif o in ("--ncols"):
         ocfg["ncols"]=int(a)
     elif o in ("--list"):
-        print ''
-        print '[available graph modules]'
-        print ''
+        print('')
+        print('[available graph modules]')
+        print('')
         for i in cfg["modnames"]:
-            print i
-        print ''
-        print ''
+            print(i)
+        print('')
+        print('')
         sys.exit(0)
     elif o in ("--mods"):
         ocfg["modnames"] = a.split(",")
 
 if len(args) < 1:
-    print ''
-    print 'No config file is specified.  Enabled the fake mode.'
-    print ''
+    print('')
+    print('No config file is specified.  Enabled the fake mode.')
+    print('')
     cfg["masternode"] = "frontend"
     cfg["drawexternal"] = "no"
     cfg["drawacpipwr"] = "no"
@@ -101,30 +101,30 @@
     with open(cfgfn) as f:
         cfgtmp = json.load(f)
         # override if cfg defines any
-        for k in cfgtmp.keys():
+        for k in list(cfgtmp.keys()):
             cfg[k] = cfgtmp[k]
         # override if specifed as cmd option
-        for k in ocfg.keys():
+        for k in list(ocfg.keys()):
             cfg[k] = ocfg[k]
 
 if len(targetnode) == 0 :
     targetnode = cfg['masternode']
 if len(enclaves) == 0:
-    if cfg.has_key('enclaves'):
+    if 'enclaves' in cfg:
         enclaves = cfg['enclaves']
 
-print 'masternode:', cfg['masternode']
-print 'targetnode:', targetnode
-print 'enclaves:', enclaves
+print('masternode:', cfg['masternode'])
+print('targetnode:', targetnode)
+print('enclaves:', enclaves)
 
 if len(appcfgfn) > 0:
     with open(appcfgfn) as f:
         appcfg = json.load(f)
-    for k in appcfg.keys():
+    for k in list(appcfg.keys()):
         cfg[k] = appcfg[k]
 
-    if not (cfg.has_key('appname') and cfg.has_key('appsamples')):
-        print "Please double check %s: appname or appsamples tags" % appcfgfn
+    if not ('appname' in cfg and 'appsamples' in cfg):
+        print("Please double check %s: appname or appsamples tags" % appcfgfn)
         sys.exit(1)
 
 
@@ -142,9 +142,9 @@
 try:
     logf = open(cfg["outputfn"], 'w', 0) # unbuffered write
 except:
-    print 'unable to open', cfg["outputfn"]
+    print('unable to open', cfg["outputfn"])
 
-print >>logf, json.dumps(info)
+print(json.dumps(info), file=logf)
 
 #if not fakemode:
 #    querycmds = cfg['querycmds']
--- a/examples/sos/pycoolrgui/pycoolr-plot/layout.py	(original)
--- b/examples/sos/pycoolrgui/pycoolr-plot/layout.py	(refactored)
@@ -7,7 +7,7 @@
 from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
 
 if sys.version_info[0] < 3:
-    import Tkinter as Tk
+    import tkinter as Tk
 else:
     import tkinter as Tk
 
--- a/examples/sos/pycoolrgui/pycoolr-plot/listrotate.py	(original)
--- b/examples/sos/pycoolrgui/pycoolr-plot/listrotate.py	(refactored)
@@ -115,15 +115,15 @@
     lr = listrotate2D(5)
     for i in range(8):
         lr.add(i,i)
-        print lr.getlistx()
-        print lr.getlisty()
-        print lr.getlistr()
-        print 
+        print(lr.getlistx())
+        print(lr.getlisty())
+        print(lr.getlistr())
+        print() 
 
-    print '------------'
+    print('------------')
     lr = listrotate1D(5)
     for i in range(8):
         lr.add(i)
-        print lr.getlist()
-        print lr.getlistr()
-        print 
+        print(lr.getlist())
+        print(lr.getlistr())
+        print() 
--- a/src/Profile/ltau.py	(original)
--- b/src/Profile/ltau.py	(refactored)
@@ -90,11 +90,11 @@
         fullname = os.path.join(dirname, 'profile.doc')
         if os.path.exists(fullname):
             sts = os.system('${PAGER-more} ' + fullname)
-            if sts: print '*** Pager exit status:', sts
+            if sts: print('*** Pager exit status:', sts)
             break
     else:
-        print 'Sorry, can\'t find the help file "profile.doc"',
-        print 'along the Python search path.'
+        print('Sorry, can\'t find the help file "profile.doc"', end=' ')
+        print('along the Python search path.')
 
 
 
@@ -204,7 +204,7 @@
         self.simulate_call(cmd)
         sys.setprofile(self.dispatcher)
         try:
-            exec cmd in globals, locals
+            exec(cmd, globals, locals)
         finally:
             sys.setprofile(None)
         return self
@@ -224,7 +224,7 @@
 if __name__ == '__main__':
     usage = "tau.py scriptfile [arg] ..."
     if not sys.argv[1:]:
-        print "Usage: ", usage
+        print("Usage: ", usage)
         sys.exit(2)
 
     class ProfileParser(OptionParser):
@@ -246,4 +246,4 @@
         sys.path.insert(0, os.path.dirname(sys.argv[0]))
         run('execfile(%r)' % (sys.argv[0],), options.outfile, options.sort)
     else:
-        print "Usage: ", usage
+        print("Usage: ", usage)
--- a/src/Profile/tau_python_wrapper.py	(original)
--- b/src/Profile/tau_python_wrapper.py	(refactored)
@@ -32,7 +32,7 @@
 Runs MODULE with automatic Python instrumentation.
 """
 
-from __future__ import print_function
+
 import os
 import sys
 
--- a/src/python/tau_profile_parser.py	(original)
--- b/src/python/tau_profile_parser.py	(refactored)
@@ -4,7 +4,7 @@
 Parses a set of TAU profile files and yields multi-indexed Pandas dataframes for the
 interval and atomic events.
 """
-from __future__ import print_function
+
 import csv
 import glob
 import mmap
--- a/tests/programs/python/firstprime.py	(original)
--- b/tests/programs/python/firstprime.py	(refactored)
@@ -15,7 +15,7 @@
 				# Found factor. not prime
 				break # move on to next number
 			elif potentialfactor >= sqrtno:
-				print("The first prime number after {} is {}".format(x,current))
+				print(("The first prime number after {} is {}".format(x,current)))
 				return current
 		current += 1
 
--- a/tools/src/tau_prof2json.py	(original)
--- b/tools/src/tau_prof2json.py	(refactored)
@@ -3,7 +3,7 @@
 """A python script to convert TAU profiles to JSON
 """
 
-from __future__ import print_function
+
 import os
 import sys
 import argparse
@@ -78,13 +78,13 @@
     start_time_stamp = app_dict["Starting Timestamp"]
     end_time_stamp = None
     if "Ending Timestamp" not in app_dict:
-        end_time_stamp = str(long(start_time_stamp) + max_inclusive)
+        end_time_stamp = str(int(start_time_stamp) + max_inclusive)
     else:
         end_time_stamp = app_dict["Ending Timestamp"]
-    if workflow_start == 0 or workflow_start > long(start_time_stamp):
-        workflow_start = long(start_time_stamp)
-    if workflow_end == 0 or workflow_end < long(end_time_stamp):
-        workflow_end = long(end_time_stamp)
+    if workflow_start == 0 or workflow_start > int(start_time_stamp):
+        workflow_start = int(start_time_stamp)
+    if workflow_end == 0 or workflow_end < int(end_time_stamp):
+        workflow_end = int(end_time_stamp)
     local_time = app_dict["Local Time"]
     if start_time_stamp != None and have_workflow_file:
         for wc in workflow_dict["Workflow Component"]:
@@ -203,29 +203,29 @@
             timer["process index"] = int(node)
             timer["thread index"] = int(thread)
             timer["Function"] = function_name
-            timer["Calls"] = long(tokens[0])
-            timer["Subroutines"] = long(tokens[1])
-            timer["Exclusive Time"] = long(tokens[2])
-            timer["Inclusive Time"] = long(tokens[3])
+            timer["Calls"] = int(tokens[0])
+            timer["Subroutines"] = int(tokens[1])
+            timer["Exclusive Time"] = int(tokens[2])
+            timer["Inclusive Time"] = int(tokens[3])
             group = tokens[5]
             # handle the ADIOS special case
             if "ADIOS" in function_name:
                 if "ADIOS" not in group_totals:
-                    group_totals["ADIOS"] = long(tokens[2])
-                    group_counts["ADIOS"] = long(tokens[0])
-                else:
-                    group_totals["ADIOS"] = group_totals["ADIOS"] + long(tokens[2])
-                    group_counts["ADIOS"] = group_counts["ADIOS"] + long(tokens[0])
+                    group_totals["ADIOS"] = int(tokens[2])
+                    group_counts["ADIOS"] = int(tokens[0])
+                else:
+                    group_totals["ADIOS"] = group_totals["ADIOS"] + int(tokens[2])
+                    group_counts["ADIOS"] = group_counts["ADIOS"] + int(tokens[0])
             else:
                 if group not in group_totals:
-                    group_totals[group] = long(tokens[2])
-                    group_counts[group] = long(tokens[0])
-                else:
-                    group_totals[group] = group_totals[group] + long(tokens[2])
-                    group_counts[group] = group_counts[group] + long(tokens[0])
+                    group_totals[group] = int(tokens[2])
+                    group_counts[group] = int(tokens[0])
+                else:
+                    group_totals[group] = group_totals[group] + int(tokens[2])
+                    group_counts[group] = group_counts[group] + int(tokens[0])
             data["Timers"].append(timer)
-            if max_inclusive < long(tokens[3]):
-                max_inclusive = long(tokens[3])
+            if max_inclusive < int(tokens[3]):
+                max_inclusive = int(tokens[3])
     return max_inclusive
 
 def extract_group_totals():
@@ -297,7 +297,7 @@
         application_metadata["aggr_io_read_bytes"] = read_bytes
     if write_bytes > 0:
         application_metadata["aggr_io_write_bytes"] = write_bytes
-    application_metadata["total_time"] = long(application_metadata["end-timestamp"]) - long(application_metadata["start-timestamp"])
+    application_metadata["total_time"] = int(application_metadata["end-timestamp"]) - int(application_metadata["start-timestamp"])
 
 def parse_aggregates(node, context, thread, infile, data):
     aggregates = infile.readline()
@@ -377,48 +377,48 @@
             counter["process index"] = int(node)
             counter["thread index"] = int(thread)
             counter["Counter"] = counter_name
-            counter["Num Events"] = long(tokens[0])
+            counter["Num Events"] = int(tokens[0])
             counter["Max Value"] = float(tokens[1])
             counter["Min Value"] = float(tokens[2])
             counter["Mean Value"] = float(tokens[3])
             counter["SumSqr Value"] = float(tokens[4])
             if "Message size for " in counter_name:
-                value = long(tokens[0]) * float(tokens[3])
+                value = int(tokens[0]) * float(tokens[3])
                 c_name = "Collective_Bytes"
                 if c_name not in group_totals:
                     group_totals[c_name] = value
                 else:
                     group_totals[c_name] = group_totals[c_name] + value
             if counter_name == "Message size sent to all nodes":
-                value = long(tokens[0]) * float(tokens[3])
+                value = int(tokens[0]) * float(tokens[3])
                 c_name = "Send_Bytes"
                 if c_name not in group_totals:
                     group_totals[c_name] = value
                 else:
                     group_totals[c_name] = group_totals[c_name] + value
             if counter_name == "Message size received from all nodes":
-                value = long(tokens[0]) * float(tokens[3])
+                value = int(tokens[0]) * float(tokens[3])
                 c_name = "Recv_Bytes"
                 if c_name not in group_totals:
                     group_totals[c_name] = value
                 else:
                     group_totals[c_name] = group_totals[c_name] + value
             if counter_name == "Bytes Read":
-                value = long(tokens[0]) * float(tokens[3])
+                value = int(tokens[0]) * float(tokens[3])
                 c_name = "Read_Bytes"
                 if c_name not in group_totals:
                     group_totals[c_name] = value
                 else:
                     group_totals[c_name] = group_totals[c_name] + value
             if counter_name == "Bytes Written":
-                value = long(tokens[0]) * float(tokens[3])
+                value = int(tokens[0]) * float(tokens[3])
                 c_name = "Write_Bytes"
                 if c_name not in group_totals:
                     group_totals[c_name] = value
                 else:
                     group_totals[c_name] = group_totals[c_name] + value
             if counter_name == "ADIOS data size":
-                value = long(tokens[0]) * float(tokens[3])
+                value = int(tokens[0]) * float(tokens[3])
                 c_name = "ADIOS_data_size"
                 if c_name not in group_totals:
                     group_totals[c_name] = value
--- a/tools/src/tau_prof_to_json.py	(original)
--- b/tools/src/tau_prof_to_json.py	(refactored)
@@ -3,7 +3,7 @@
 """A python script to convert TAU profiles to JSON
 """
 
-from __future__ import print_function
+
 import os
 import sys
 import argparse
@@ -111,10 +111,10 @@
             timer["process index"] = int(node)
             timer["thread index"] = int(thread)
             timer["Function"] = function_name
-            timer["Calls"] = long(tokens[0])
-            timer["Subroutines"] = long(tokens[1])
-            timer["Exclusive Time"] = long(tokens[2])
-            timer["Inclusive Time"] = long(tokens[3])
+            timer["Calls"] = int(tokens[0])
+            timer["Subroutines"] = int(tokens[1])
+            timer["Exclusive Time"] = int(tokens[2])
+            timer["Inclusive Time"] = int(tokens[3])
             data["Timers"].append(timer)
     
 def parse_aggregates(node, context, thread, infile, data):
@@ -192,7 +192,7 @@
             counter["process index"] = int(node)
             counter["thread index"] = int(thread)
             counter["Counter"] = counter_name
-            counter["Num Events"] = long(tokens[0])
+            counter["Num Events"] = int(tokens[0])
             counter["Max Value"] = float(tokens[1])
             counter["Min Value"] = float(tokens[2])
             counter["Mean Value"] = float(tokens[3])
--- a/tools/src/tau_resolve_addresses.py	(original)
--- b/tools/src/tau_resolve_addresses.py	(refactored)
@@ -37,7 +37,7 @@
 OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 """
 
-from __future__ import with_statement
+
 
 import re
 import os
@@ -48,7 +48,7 @@
 from optparse import OptionParser
 from subprocess import Popen, PIPE
 from threading import Thread
-from Queue import Queue, Empty
+from queue import Queue, Empty
 from xml.sax import saxutils
 
 USAGE = """
@@ -91,7 +91,7 @@
         self.exe = exe
         self.cmdstr = ' '.join(cmd)
         if not os.path.exists(self.exe):
-            print 'WARNING: %r not found.  Addresses in this binary will not be resolved.' % self.exe
+            print('WARNING: %r not found.  Addresses in this binary will not be resolved.' % self.exe)
             self.p = self.q = self.t = None
         else:
             self.p = Popen(cmd, stdin=PIPE, stdout=PIPE, stderr=PIPE, bufsize=1)
@@ -99,7 +99,7 @@
             self.t = Thread(target=Addr2Line.enqueue_output, args=(self.p.stdout, self.q))
             self.t.daemon = True
             self.t.start()
-            print 'New process: %s' % self.cmdstr
+            print('New process: %s' % self.cmdstr)
 
     def close(self):
         if self.p:
@@ -162,7 +162,7 @@
             exe = match.group(2)
             addr = match.group(3)
             if exe == 'UNKNOWN':
-                for p in self.pipes.itervalues():
+                for p in self.pipes.values():
                     resolved = p.resolve(addr)
                     if resolved[0] != 'UNRESOLVED':
                         break
@@ -177,18 +177,18 @@
                 return match.group(0)
 
         # Extract lines from memory and rewrite
-        print 'New thread: %s' % self.name
+        print('New thread: %s' % self.name)
         t0 = time.clock()
         j = 1
-        for i in xrange(self.firstline, self.lastline):
+        for i in range(self.firstline, self.lastline):
             if j % ITERS_PER_REPORT == 0:
                 timespan = time.clock() - t0
                 time_per_iter = timespan / ITERS_PER_REPORT
                 eta = (self.linecount - j) * time_per_iter
                 etadate = time.ctime(time.time() + eta)
-                print '%s: %d records in %f seconds, ETA %f seconds (%s)' % (self.name, ITERS_PER_REPORT, timespan, eta, etadate)
+                print('%s: %d records in %f seconds, ETA %f seconds (%s)' % (self.name, ITERS_PER_REPORT, timespan, eta, etadate))
                 if eta > 1000:
-                    print 'This is going to take a long time. Maybe use the --jobs option? See --help'
+                    print('This is going to take a long time. Maybe use the --jobs option? See --help')
                 t0 = time.clock()
             lineno = self.unresolved[i]
             span = self.linespan[lineno]
@@ -197,8 +197,8 @@
             line = self.mm[start:stop]
             try:
                 result = (lineno, re.sub(PATTERN, repl, line))
-            except Addr2LineError, e:
-                print e.value
+            except Addr2LineError as e:
+                print(e.value)
                 break
             self.results.append(result)
             j += 1
@@ -220,7 +220,7 @@
         with open(outfile, 'wb') as fout:
 
             # Scan events from input file
-            print 'Scanning %r' % infile
+            print('Scanning %r' % infile)
             all_exes = set()
             linespan = list()
             unresolved = list()
@@ -233,7 +233,7 @@
                     break
                 if j % ITERS_PER_REPORT == 0:
                     timespan = time.clock() - t0
-                    print 'Scanned %d lines in %f seconds' % (j, timespan)
+                    print('Scanned %d lines in %f seconds' % (j, timespan))
                 linespan.append((offset, offset + len(line)))
                 offset += len(line)
                 match = re.search(PATTERN, line)
@@ -247,16 +247,16 @@
 
             # "Rewind" the input file and report
             fin.seek(0, 0)
-            print 'Found %d executables in profile' % len(all_exes)
-            print 'Found %d unresolved addresses' % linecount
+            print('Found %d executables in profile' % len(all_exes))
+            print('Found %d unresolved addresses' % linecount)
             if jobs > linecount:
                 jobs = linecount
-                print 'Reducing jobs to %d' % jobs
+                print('Reducing jobs to %d' % jobs)
 
             # Build list of executables to search
             all_exes |= fallback_exes
             if not all_exes:
-                print 'ERROR: No executables or other binary objects specified. See --help.'
+                print('ERROR: No executables or other binary objects specified. See --help.')
                 sys.exit(1)
 
             # Calculate work division
@@ -265,21 +265,21 @@
             if jobs > 1:
                 chunklen = linecount / jobs
                 chunkrem = linecount % jobs
-                for i in xrange(jobs):
+                for i in range(jobs):
                     count = chunklen
                     if i < chunkrem:
                         count += 1
                     chunks.append((start, count))
                     start += count
-                print '%d workers process %d records, %d process %d records' % (chunkrem, chunklen+1, (jobs-chunkrem), chunklen)
+                print('%d workers process %d records, %d process %d records' % (chunkrem, chunklen+1, (jobs-chunkrem), chunklen))
             else:
                 chunks = [(0, linecount)]
-                print 'One thread will process %d records' % linecount
+                print('One thread will process %d records' % linecount)
 
             # Launch worker processes
             mm = mmap(fin.fileno(), 0)
             workers = list()
-            for i in xrange(jobs):
+            for i in range(jobs):
                 w = Worker(addr2line, all_exes, mm, unresolved, linespan, chunks[i])
                 w.start()
                 workers.append(w)
@@ -294,19 +294,19 @@
             # Process worker output
             for rank, w in enumerate(workers):
                 w.join()
-                print '%s (%d/%d) completed' % (w.name, rank, len(workers))
+                print('%s (%d/%d) completed' % (w.name, rank, len(workers)))
                 for lineno, line in w.results:
                     if i < lineno:
                         start = linespan[i][0]
                         stop = linespan[lineno-1][1]
-                        print 'writing lines %d:%d' % (i, lineno-1)
+                        print('writing lines %d:%d' % (i, lineno-1))
                         fout.write(mm[start:stop])
                         i = lineno
                     fout.write(line)
                     i += 1
 
             # Write out remainder of file
-            print 'Address resolution complete, writing metrics to file...'
+            print('Address resolution complete, writing metrics to file...')
             start = linespan[i-1][1]
             fin.seek(start, 0)
             for line in fin:
@@ -373,10 +373,10 @@
 
     for infile in files:
         outfile = os.path.join(outdir, os.path.basename(infile))
-        print '%s => %s' % (infile, outfile)
+        print('%s => %s' % (infile, outfile))
         try:
             tauprofile_xml(infile, outfile, options)
         except IOError:
-            print 'Invalid input or output file.  Check command arguments'
+            print('Invalid input or output file.  Check command arguments')
             sys.exit(1)
 
--- a/tools/src/tausamp_constructParaverTrace.py	(original)
--- b/tools/src/tausamp_constructParaverTrace.py	(refactored)
@@ -82,16 +82,16 @@
 mpiCallerType = 70000000
 
 def usage():
-	print "\nUsage: process.py [-m --mpi] [-c --callpath]\n"
-	print "Where:"
-	print "\t-m, --mpi      : keep MPI events"
-	print "\t-c, --callpath : keep callpath\n"
+	print("\nUsage: process.py [-m --mpi] [-c --callpath]\n")
+	print("Where:")
+	print("\t-m, --mpi      : keep MPI events")
+	print("\t-c, --callpath : keep callpath\n")
 	sys.exit(1)
 
 def getFileExtents(infname):
 	global startTimestamp
 	global endTimestamp
-	print "Pre-processing", infname, "..."
+	print("Pre-processing", infname, "...")
 	input = open(infname, 'r')
 	localStartTimestamp = 0
 	localEndTimestamp = 0
@@ -159,7 +159,7 @@
 	appl = 1
 	thread = 1
 	eventSet = set()
-	print "Processing", infname, "..."
+	print("Processing", infname, "...")
 	input = open(infname, 'r')
 	currentCallpath = ""
 	for line in input:
@@ -282,7 +282,7 @@
 				traceFile.write(endEvent)
 
 def sortedDictValues(adict):
-	items = adict.items()
+	items = list(adict.items())
 	items.sort()
 	return [value for key, value in items]
 
@@ -363,7 +363,7 @@
 	pcfFile.write("EVENT_TYPE\n")
 	pcfFile.write("9    50000001    MPI Point-to-point\n")
 	pcfFile.write("VALUES\n")
-	for (k,v) in mpiValues.items():
+	for (k,v) in list(mpiValues.items()):
 		if mpiTypes[k] == 50000001:
 			pcfFile.write(str(v) + "   " + str(k) + "\n")
 	pcfFile.write("0   End\n")
@@ -372,7 +372,7 @@
 	pcfFile.write("EVENT_TYPE\n")
 	pcfFile.write("9    50000002    MPI Collective Comm\n")
 	pcfFile.write("VALUES\n")
-	for (k,v) in mpiValues.items():
+	for (k,v) in list(mpiValues.items()):
 		if mpiTypes[k] == 50000002:
 			pcfFile.write(str(v) + "   " + str(k) + "\n")
 	pcfFile.write("0   End\n")
@@ -381,13 +381,13 @@
 	pcfFile.write("EVENT_TYPE\n")
 	pcfFile.write("9    50000003    MPI Other\n")
 	pcfFile.write("VALUES\n")
-	for (k,v) in mpiValues.items():
+	for (k,v) in list(mpiValues.items()):
 		if mpiTypes[k] == 50000003:
 			pcfFile.write(str(v) + "   " + str(k) + "\n")
 	pcfFile.write("0   End\n")
 	pcfFile.write("\n\n")
 
-	sortedList = sorted(counterMap.iteritems(), key=itemgetter(1))
+	sortedList = sorted(iter(counterMap.items()), key=itemgetter(1))
 	pcfFile.write("EVENT_TYPE\n")
 	for i in sortedList:
 		pcfFile.write("7  " + str(i[1]) + " " + str(i[0]) + "\n")
@@ -427,16 +427,16 @@
 	pcfFile.write("13    Gradient 13\n")
 	pcfFile.write("14    Gradient 14\n\n\n")
 
-	sortedList = sorted(callpathMap.iteritems(), key=itemgetter(1))
-	pcfFile.write("EVENT_TYPE\n")
-	for (k,v) in callDepthMap.items():
+	sortedList = sorted(iter(callpathMap.items()), key=itemgetter(1))
+	pcfFile.write("EVENT_TYPE\n")
+	for (k,v) in list(callDepthMap.items()):
 		pcfFile.write("0    " + str(k) + "    " + v + "\n")
 	pcfFile.write("VALUES\n")
 	for i in sortedList:
 		pcfFile.write(str(i[1]) + "   " + str(i[0]) + "\n")
 	pcfFile.write("\n\n")
 
-	sortedList = sorted(callpathMap.iteritems(), key=itemgetter(1))
+	sortedList = sorted(iter(callpathMap.items()), key=itemgetter(1))
 	pcfFile.write("EVENT_TYPE\n")
 	pcfFile.write("0    60000019    User function\n")
 	pcfFile.write("VALUES\n")
@@ -451,7 +451,7 @@
 	pcfFile.write("2      CPU Bursts\n\n")
 
 	pcfFile.close()
-	print pcfname, "mapping file created"
+	print(pcfname, "mapping file created")
 
 def writeRowFile(numFiles):
 	rowfname = "tracefile.row"
@@ -462,7 +462,7 @@
 	rowFile.write("\n\n")
 	rowFile.write("LEVEL NODE SIZE " + str(1) + " \nunknown\n")
 	rowFile.close()
-	print rowfname, "row file created"
+	print(rowfname, "row file created")
 
 def createTraceFile(tracefname, numFiles):
 	traceFile = open(tracefname, 'w')
@@ -515,12 +515,12 @@
 		processFile(infname, traceFile)
 
 	traceFile.close()
-	print tracefname, "trace file created"
+	print(tracefname, "trace file created")
 
 	writePcfFile(callpathMap)
 	writeRowFile(numFiles);
 
-	print negatives, "negative values ignored out of", total, "total values"
+	print(negatives, "negative values ignored out of", total, "total values")
 
 if __name__ == "__main__":
 	main(sys.argv[1:])
--- a/tools/src/tausamp_extract4folding.py	(original)
--- b/tools/src/tausamp_extract4folding.py	(refactored)
@@ -41,10 +41,10 @@
 total = 0
 
 def usage():
-	print "\nUsage: process.py [-m --mpi] [-c --callpath]\n"
-	print "Where:"
-	print "\t-m, --mpi      : keep MPI events"
-	print "\t-c, --callpath : keep callpath\n"
+	print("\nUsage: process.py [-m --mpi] [-c --callpath]\n")
+	print("Where:")
+	print("\t-m, --mpi      : keep MPI events")
+	print("\t-c, --callpath : keep callpath\n")
 	sys.exit(1)
 
 def parseArgs(argv):
@@ -152,7 +152,7 @@
 				outputFile.write(tmp)
 
 def sortedDictValues(adict):
-	items = adict.items()
+	items = list(adict.items())
 	items.sort()
 	return [value for key, value in items]
 
@@ -168,29 +168,29 @@
 		if infname.startswith("ebstrace.processed."):
 			outfname = infname.replace("processed", "extracted")
 			outputFile = open(outfname, 'w')
-			print infname, "-->",
+			print(infname, "-->", end=' ')
 			processFile(infname, outputFile)
 			outputFile.close()
 			newOutfname = outfname.replace(".0.0.0", "." + node + "." + str(thread))
-			print newOutfname
+			print(newOutfname)
 			os.rename(outfname, newOutfname)
 
 	outfname = "ebstrace.extracted.maps.txt"
 	outputFile = open(outfname, 'w')
 
-	sortedList = sorted(callpathMap.iteritems(), key=itemgetter(1))
+	sortedList = sorted(iter(callpathMap.items()), key=itemgetter(1))
 	outputFile.write("# function map \n")
 	for i in sortedList:
 		outputFile.write(str(i[1]) + " " + str(i[0]) + "\n")
 
-	sortedList = sorted(counterMap.iteritems(), key=itemgetter(1))
+	sortedList = sorted(iter(counterMap.items()), key=itemgetter(1))
 	outputFile.write("# metric map \n")
 	for i in sortedList:
 		outputFile.write(str(i[1]) + " " + str(i[0]) + "\n")
 
 	outputFile.close()
-	print outfname, "mapping file created"
-	print negatives, "negative values ignored out of", total, "total values"
+	print(outfname, "mapping file created")
+	print(negatives, "negative values ignored out of", total, "total values")
 
 if __name__ == "__main__":
 	main(sys.argv[1:])
--- a/tools/src/perfexplorer/cqos/big.py	(original)
--- b/tools/src/perfexplorer/cqos/big.py	(refactored)
@@ -1,6 +1,6 @@
 import sys
 import time
-import commands
+import subprocess
 
 True = 1
 False = 0
@@ -23,12 +23,12 @@
 			#for gridx in ['16', '32']:
 			for gridx in ['64']:
 				gridy=gridx
-				gridsize = `gridx` + 'x' + `gridy`
+				gridsize = repr(gridx) + 'x' + repr(gridy)
 				#for pc in ['jacobi', 'bjacobi', 'none', 'sor', 'asm', 'cholesky']:
 				getrec = 'java -cp /home/khuck/tau2/tools/src/perfexplorer/classifier.jar:/home/khuck/.ParaProf/weka.jar cqos.CQoSClassifier /tmp/classifier.nosplit.' + classifier + ' lidvelocity:' + lidvelocity + ' gridsize:' + gridx + 'x' + gridx + ' grashof:' + grashof
 				# get KSP recommendation
 				#print getrec
-				(status, output) = commands.getstatusoutput(getrec) 
+				(status, output) = subprocess.getstatusoutput(getrec) 
 				#print output
 				if output.startswith('fgmres'):
 					ksp='fgmres'
@@ -38,11 +38,11 @@
 					ksp='bcgs'
 				if output.startswith('tfqmr'):
 					ksp='tfqmr'
-				print ksp
+				print(ksp)
 				# get PC recommendation
 				getrec = 'java -cp /home/khuck/tau2/tools/src/perfexplorer/classifier.jar:/home/khuck/.ParaProf/weka.jar cqos.CQoSClassifier /tmp/classifier.pc.' + classifier + ' lidvelocity:' + lidvelocity + ' gridsize:' + gridx + 'x' + gridx + ' grashof:' + grashof + ' ksp:' + ksp
 				#print getrec
-				(status, output) = commands.getstatusoutput(getrec) 
+				(status, output) = subprocess.getstatusoutput(getrec) 
 				#for pc in ['jacobi', 'bjacobi', 'none', 'sor', 'asm', 'cholesky']:
 				#print output
 				if output.startswith('jacobi'):
@@ -62,36 +62,36 @@
 				if output.startswith('icc'):
 					pc='icc'
 					procs='1'
-				print pc
+				print(pc)
 
 				# make directories for results
 				dirname = 'ex27'+'-'+ procs + '-' + 'x' + gridx + '-' + 'y' + gridy + '-' + 'lid' + lidvelocity + '-' + 'grh' + grashof + '-' + 'srtol' + snesrtol + '-' + 'krtol' + ksprtol + '-' + 'snes' + snes + '-' + 'pc' + pc
-				print dirname
+				print(dirname)
 				createdir= 'mkdir /home/khuck/data/petsc/' + classifier + '/' + dirname
 				#print createdir
-				commands.getstatusoutput(createdir)
-				commands.getstatusoutput(createdir + '/default')
-				commands.getstatusoutput(createdir + '/' + ksp)
+				subprocess.getstatusoutput(createdir)
+				subprocess.getstatusoutput(createdir + '/default')
+				subprocess.getstatusoutput(createdir + '/' + ksp)
 				# run with default solver
 				mycommand = '$MPIEXEC -np ' + procs + ' /home/khuck/src/petsc/metadata/ex27 ' ' -snes_type ' + snes + ' -ksp_type gmres -pc_type ilu -lidvelocity ' + lidvelocity + ' -da_grid_x ' + gridx + ' -da_grid_y ' + gridx + ' -print -snes_monitor -grashof ' + grashof + ' -cfl_ini ' + cflini + ' -snes_rtol ' + snesrtol + ' -ksp_rtol ' + ksprtol + ' -preload off' + ' >& /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default.log'
 				# print mycommand
 				start = time.time()
-				(status, output) = 	commands.getstatusoutput(mycommand)
+				(status, output) = 	subprocess.getstatusoutput(mycommand)
 				end = time.time()
 				default = end - start
-				print 'DEFAULT: ', default
-				commands.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default/.')
+				print('DEFAULT: ', default)
+				subprocess.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default/.')
 				# run with recommendation
 				mycommand = '$MPIEXEC -np ' + procs + ' /home/khuck/src/petsc/metadata/ex27 ' ' -snes_type ' + snes + ' -ksp_type ' + ksp + ' -pc_type ' + pc + ' -lidvelocity ' + lidvelocity + ' -da_grid_x ' + gridx + ' -da_grid_y ' + gridx + ' -print -snes_monitor -grashof ' + grashof + ' -cfl_ini ' + cflini + ' -snes_rtol ' + snesrtol + ' -ksp_rtol ' + ksprtol + ' -preload off' + ' >& /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + classifier + '.log'
 				start = time.time()
-				(status, output) = 	commands.getstatusoutput(mycommand)
+				(status, output) = 	subprocess.getstatusoutput(mycommand)
 				end = time.time()
 				recommended = end - start
 				# print output
-				print 'RECOMMENDED: ', recommended
-				commands.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + ksp + '/.')
+				print('RECOMMENDED: ', recommended)
+				subprocess.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + ksp + '/.')
 				#f.write('lidvelocity, grashof, gridsize, ksp, pc, default, recommended\n')
-				f.write(lidvelocity + ',' + grashof + ',' + gridsize + ',' + ksp + ',' + pc + ',' + `default` + ',' + `recommended` + '\n')
+				f.write(lidvelocity + ',' + grashof + ',' + gridsize + ',' + ksp + ',' + pc + ',' + repr(default) + ',' + repr(recommended) + '\n')
 				f.flush()
 
 f.close()
--- a/tools/src/perfexplorer/cqos/c60.py	(original)
--- b/tools/src/perfexplorer/cqos/c60.py	(refactored)
@@ -20,11 +20,11 @@
 	global inApp
 	global inExp
 	global fileName
-	print "getting parameters..."
+	print("getting parameters...")
 	parameterMap = PerfExplorerModel.getModel().getScriptParameters()
 	keys = parameterMap.keySet()
 	for key in keys:
-		print key, parameterMap.get(key)
+		print(key, parameterMap.get(key))
 	config = parameterMap.get("config")
 	tmp = parameterMap.get("app")
 	if tmp != None:
@@ -35,35 +35,35 @@
 	tmp = parameterMap.get("fileName")
 	if tmp != None:
 		fileName = tmp
-	print "...done."
+	print("...done.")
 
 def loadTrials():
 	global results
 	global inExp
-	print "loading trials for experiment..."
+	print("loading trials for experiment...")
 	Utilities.setSession(config)
 	trials = Utilities.getTrialsForExperiment(inApp, inExp)
 	for trial in trials:
 		loaded = TrialMeanResult(trial)
 		results.add(loaded)
-	print "...done."
+	print("...done.")
 	return results
 
 def loadExperiments():
 	global results
 	global inExp
-	print "loading experiments..."
+	print("loading experiments...")
 	Utilities.setSession(config)
 	experiments = Utilities.getExperimentsForApplication(inApp)
 	for experiment in experiments:
 		inExp = experiment.getName();
-		print "processing experiment: ", inExp
+		print("processing experiment: ", inExp)
 		results = loadTrials()
-	print "...done."
+	print("...done.")
 	return results
 
 def buildClassifier(results):
-	print "building classifier..."
+	print("building classifier...")
 	metadataFields = HashSet()
 	metadataFields.add("molecule name")
 	metadataFields.add("basis set")
@@ -80,35 +80,35 @@
 	classifier.setClassifierType(CQoSClassifierOperation.ALTERNATING_DECISION_TREE)
 	classifier.processData()
 	classifier.writeClassifier(fileName + ".adt")
-	print classifier.crossValidateModel()
+	print(classifier.crossValidateModel())
 	test(classifier)
 	classifier.setClassifierType(CQoSClassifierOperation.NAIVE_BAYES)
 	classifier.processData()
 	classifier.writeClassifier(fileName + ".nb")
-	print classifier.crossValidateModel()
+	print(classifier.crossValidateModel())
 	test(classifier)
 	classifier.setClassifierType(CQoSClassifierOperation.RANDOM_TREE)
 	classifier.processData()
 	classifier.writeClassifier(fileName + ".rt")
-	print classifier.crossValidateModel()
+	print(classifier.crossValidateModel())
 	test(classifier)
 	classifier.setClassifierType(CQoSClassifierOperation.SUPPORT_VECTOR_MACHINE)
 	classifier.processData()
 	classifier.writeClassifier(fileName + ".svm")
-	print classifier.crossValidateModel()
+	print(classifier.crossValidateModel())
 	test(classifier)
 	classifier.setClassifierType(CQoSClassifierOperation.J48)
 	classifier.processData()
 	classifier.writeClassifier(fileName + ".j48")
-	print classifier.crossValidateModel()
+	print(classifier.crossValidateModel())
 	test(classifier)
 	classifier.setClassifierType(CQoSClassifierOperation.MULTILAYER_PERCEPTRON)
 	classifier.processData()
 	classifier.writeClassifier(fileName + ".mp")
-	print classifier.crossValidateModel()
+	print(classifier.crossValidateModel())
 	test(classifier)
 	classifier.writeClassifier(fileName)
-	print "...done."
+	print("...done.")
 	return classifier
 
 def test(classifier):
@@ -129,22 +129,22 @@
 				inputFields.put("core count", "8")
 				inputFields.put("mplevl", mp)
 				if classifier.getClass(inputFields) == "DIRECT":
-					print inputFields, "Direct / Conventional: ", classifier.getClass(inputFields),  classifier.getConfidence()
+					print(inputFields, "Direct / Conventional: ", classifier.getClass(inputFields),  classifier.getConfidence())
 
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 getParameters()
 
-print "getting trials..."
+print("getting trials...")
 
 results = loadTrials()
 #results = loadExperiments()
 
-print "...done."
-print "Total Trials:", results.size()
+print("...done.")
+print("Total Trials:", results.size())
 
 classifier = buildClassifier(results)
 #test(classifier)
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/cqos/chemistry.new.py	(original)
--- b/tools/src/perfexplorer/cqos/chemistry.new.py	(refactored)
@@ -20,11 +20,11 @@
 	global inApp
 	global inExp
 	global fileName
-	print "getting parameters..."
+	print("getting parameters...")
 	parameterMap = PerfExplorerModel.getModel().getScriptParameters()
 	keys = parameterMap.keySet()
 	for key in keys:
-		print key, parameterMap.get(key)
+		print(key, parameterMap.get(key))
 	config = parameterMap.get("config")
 	tmp = parameterMap.get("app")
 	if tmp != None:
@@ -35,35 +35,35 @@
 	tmp = parameterMap.get("fileName")
 	if tmp != None:
 		fileName = tmp
-	print "...done."
+	print("...done.")
 
 def loadTrials():
 	global results
 	global inExp
-	print "loading trials for experiment..."
+	print("loading trials for experiment...")
 	Utilities.setSession(config)
 	trials = Utilities.getTrialsForExperiment(inApp, inExp)
 	for trial in trials:
 		loaded = TrialMeanResult(trial)
 		results.add(loaded)
-	print "...done."
+	print("...done.")
 	return results
 
 def loadExperiments():
 	global results
 	global inExp
-	print "loading experiments..."
+	print("loading experiments...")
 	Utilities.setSession(config)
 	experiments = Utilities.getExperimentsForApplication(inApp)
 	for experiment in experiments:
 		inExp = experiment.getName();
-		print "processing experiment: ", inExp
+		print("processing experiment: ", inExp)
 		results = loadTrials()
-	print "...done."
+	print("...done.")
 	return results
 
 def buildClassifier(results):
-	print "building classifier..."
+	print("building classifier...")
 	metadataFields = HashSet()
 	# metadataFields.add("basis set")
 	# ALEX metadataFields.add("NUCLEAR REPULSION ENERGY");  # molecule dependent
@@ -100,35 +100,35 @@
 	classifier.setClassifierType(CQoSClassifierOperation.ALTERNATING_DECISION_TREE)
 	classifier.processData()
 	classifier.writeClassifier(fileName + ".adt")
-	print classifier.crossValidateModel()
+	print(classifier.crossValidateModel())
 	test(classifier)
 	classifier.setClassifierType(CQoSClassifierOperation.NAIVE_BAYES)
 	classifier.processData()
 	classifier.writeClassifier(fileName + ".nb")
-	print classifier.crossValidateModel()
+	print(classifier.crossValidateModel())
 	test(classifier)
 	classifier.setClassifierType(CQoSClassifierOperation.RANDOM_TREE)
 	classifier.processData()
 	classifier.writeClassifier(fileName + ".rt")
-	print classifier.crossValidateModel()
+	print(classifier.crossValidateModel())
 	test(classifier)
 	classifier.setClassifierType(CQoSClassifierOperation.SUPPORT_VECTOR_MACHINE)
 	classifier.processData()
 	classifier.writeClassifier(fileName + ".svm")
-	print classifier.crossValidateModel()
+	print(classifier.crossValidateModel())
 	test(classifier)
 	classifier.setClassifierType(CQoSClassifierOperation.J48)
 	classifier.processData()
 	classifier.writeClassifier(fileName + ".j48")
-	print classifier.crossValidateModel()
+	print(classifier.crossValidateModel())
 	test(classifier)
 	classifier.setClassifierType(CQoSClassifierOperation.MULTILAYER_PERCEPTRON)
 	classifier.processData()
 	classifier.writeClassifier(fileName + ".mp")
-	print classifier.crossValidateModel()
+	print(classifier.crossValidateModel())
 	test(classifier)
 	classifier.writeClassifier(fileName)
-	print "...done."
+	print("...done.")
 	return classifier
 
 def test(classifier):
@@ -162,22 +162,22 @@
 			inputFields.put("core count", "8")
 			inputFields.put("mplevl", mp)
 			if classifier.getClass(inputFields) == "DIRECT":
-				print inputFields, "Direct / Conventional: ", classifier.getClass(inputFields),  classifier.getConfidence()
-	print ""
+				print(inputFields, "Direct / Conventional: ", classifier.getClass(inputFields),  classifier.getConfidence())
+	print("")
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 getParameters()
 
-print "getting trials..."
+print("getting trials...")
 
 #results = loadTrials()
 results = loadExperiments()
 
-print "...done."
-print "Total Trials:", results.size()
+print("...done.")
+print("Total Trials:", results.size())
 
 classifier = buildClassifier(results)
 #test(classifier)
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/cqos/chemistry.py	(original)
--- b/tools/src/perfexplorer/cqos/chemistry.py	(refactored)
@@ -20,11 +20,11 @@
 	global inApp
 	global inExp
 	global fileName
-	print "getting parameters..."
+	print("getting parameters...")
 	parameterMap = PerfExplorerModel.getModel().getScriptParameters()
 	keys = parameterMap.keySet()
 	for key in keys:
-		print key, parameterMap.get(key)
+		print(key, parameterMap.get(key))
 	config = parameterMap.get("config")
 	tmp = parameterMap.get("app")
 	if tmp != None:
@@ -35,35 +35,35 @@
 	tmp = parameterMap.get("fileName")
 	if tmp != None:
 		fileName = tmp
-	print "...done."
+	print("...done.")
 
 def loadTrials():
 	global results
 	global inExp
-	print "loading trials for experiment..."
+	print("loading trials for experiment...")
 	Utilities.setSession(config)
 	trials = Utilities.getTrialsForExperiment(inApp, inExp)
 	for trial in trials:
 		loaded = TrialMeanResult(trial)
 		results.add(loaded)
-	print "...done."
+	print("...done.")
 	return results
 
 def loadExperiments():
 	global results
 	global inExp
-	print "loading experiments..."
+	print("loading experiments...")
 	Utilities.setSession(config)
 	experiments = Utilities.getExperimentsForApplication(inApp)
 	for experiment in experiments:
 		inExp = experiment.getName();
-		print "processing experiment: ", inExp
+		print("processing experiment: ", inExp)
 		results = loadTrials()
-	print "...done."
+	print("...done.")
 	return results
 
 def buildClassifier(results):
-	print "building classifier..."
+	print("building classifier...")
 	metadataFields = HashSet()
 	metadataFields.add("molecule name")
 	metadataFields.add("basis set")
@@ -82,35 +82,35 @@
 	classifier.setClassifierType(CQoSClassifierOperation.ALTERNATING_DECISION_TREE)
 	classifier.processData()
 	classifier.writeClassifier(fileName + ".adt")
-	print classifier.crossValidateModel()
+	print(classifier.crossValidateModel())
 	test(classifier)
 	classifier.setClassifierType(CQoSClassifierOperation.NAIVE_BAYES)
 	classifier.processData()
 	classifier.writeClassifier(fileName + ".nb")
-	print classifier.crossValidateModel()
+	print(classifier.crossValidateModel())
 	#test(classifier)
 	classifier.setClassifierType(CQoSClassifierOperation.RANDOM_TREE)
 	classifier.processData()
 	classifier.writeClassifier(fileName + ".rt")
-	print classifier.crossValidateModel()
+	print(classifier.crossValidateModel())
 	#test(classifier)
 	classifier.setClassifierType(CQoSClassifierOperation.SUPPORT_VECTOR_MACHINE)
 	classifier.processData()
 	classifier.writeClassifier(fileName + ".svm")
-	print classifier.crossValidateModel()
+	print(classifier.crossValidateModel())
 	#test(classifier)
 	classifier.setClassifierType(CQoSClassifierOperation.J48)
 	classifier.processData()
 	classifier.writeClassifier(fileName + ".j48")
-	print classifier.crossValidateModel()
+	print(classifier.crossValidateModel())
 	#test(classifier)
 	classifier.setClassifierType(CQoSClassifierOperation.MULTILAYER_PERCEPTRON)
 	classifier.processData()
 	classifier.writeClassifier(fileName + ".mp")
-	print classifier.crossValidateModel()
+	print(classifier.crossValidateModel())
 	#test(classifier)
 	classifier.writeClassifier(fileName)
-	print "...done."
+	print("...done.")
 	return classifier
 
 def test(classifier):
@@ -130,22 +130,22 @@
 				inputFields.put("core count", "8")
 				inputFields.put("mplevl", mp)
 				if classifier.getClass(inputFields) == "DIRECT":
-					print inputFields, "Direct / Conventional: ", classifier.getClass(inputFields),  classifier.getConfidence()
+					print(inputFields, "Direct / Conventional: ", classifier.getClass(inputFields),  classifier.getConfidence())
 
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 getParameters()
 
-print "getting trials..."
+print("getting trials...")
 
 #results = loadTrials()
 results = loadExperiments()
 
-print "...done."
-print "Total Trials:", results.size()
+print("...done.")
+print("Total Trials:", results.size())
 
 classifier = buildClassifier(results)
 #test(classifier)
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/cqos/cqos.py	(original)
--- b/tools/src/perfexplorer/cqos/cqos.py	(refactored)
@@ -20,33 +20,33 @@
 	global inApp
 	global inExp
 	global fileName
-	print "getting parameters..."
+	print("getting parameters...")
 	parameterMap = PerfExplorerModel.getModel().getScriptParameters()
 	keys = parameterMap.keySet()
 	for key in keys:
-		print key, parameterMap.get(key)
+		print(key, parameterMap.get(key))
 	config = parameterMap.get("config")
 	inApp = parameterMap.get("app")
 	# inExp = parameterMap.get("exp")
 	fileName = parameterMap.get("fileName")
-	print "...done."
+	print("...done.")
 
 def loadTrials():
-	print "loading data..."
+	print("loading data...")
 	Utilities.setSession(config)
 	trials = Utilities.getTrialsForExperiment(inApp, inExp)
-	print "...done."
+	print("...done.")
 	return trials
 
 def loadExperiments():
-	print "loading data..."
+	print("loading data...")
 	Utilities.setSession(config)
 	experiments = Utilities.getExperimentsForApplication(inApp)
-	print "...done."
+	print("...done.")
 	return experiments
 
 def buildClassifier(results):
-	print "building classifier..."
+	print("building classifier...")
 	metadataFields = HashSet()
 	metadataFields.add("molecule name")
 	metadataFields.add("basis set")
@@ -66,15 +66,15 @@
 	#classifier.setClassifierType(CQoSClassifierOperation.SUPPORT_VECTOR_MACHINE)
 	classifier.processData()
 	classifier.writeClassifier(fileName)
-	print "...done."
+	print("...done.")
 
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 getParameters()
 results = ArrayList()
 
-print "getting trials..."
+print("getting trials...")
 
 # trials = loadTrials()
 # for trial in trials:
@@ -84,15 +84,15 @@
 experiments = loadExperiments()
 for experiment in experiments:
 	inExp = experiment.getName();
-	print "processing experiment: ", inExp
+	print("processing experiment: ", inExp)
 	trials = loadTrials()
 	for trial in trials:
 		loaded = TrialMeanResult(trial)
 		results.add(loaded)
 
-print "...done."
-print "Total Trials:", results.size()
+print("...done.")
+print("Total Trials:", results.size())
 
 buildClassifier(results)
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/cqos/evaluate.py	(original)
--- b/tools/src/perfexplorer/cqos/evaluate.py	(refactored)
@@ -21,16 +21,16 @@
 	global inApp
 	global inExp
 	global fileName
-	print "getting parameters..."
+	print("getting parameters...")
 	parameterMap = PerfExplorerModel.getModel().getScriptParameters()
 	keys = parameterMap.keySet()
 	for key in keys:
-		print key, parameterMap.get(key)
+		print(key, parameterMap.get(key))
 	config = parameterMap.get("config")
 	inApp = parameterMap.get("app")
 	inExp = parameterMap.get("exp")
 	fileName = parameterMap.get("fileName")
-	print "...done."
+	print("...done.")
 
 def testClassifier(classifier):
 	bcgs = 0
@@ -57,7 +57,7 @@
 						className =  classifier.getClass(inputFields)
 						confidence = classifier.getConfidence()
 						if className == "bcgs":
-							print inputFields
+							print(inputFields)
 							bcgs+=1
 						if className == "fgmres":
 							fgmres+=1
@@ -66,29 +66,29 @@
 						if className == "tfqmr":
 							tfqmr+=1
 
-	print "bcgs", bcgs
-	print "fgmres", fgmres
-	print "gmres", gmres
-	print "tfqmr", tfqmr
+	print("bcgs", bcgs)
+	print("fgmres", fgmres)
+	print("gmres", gmres)
+	print("tfqmr", tfqmr)
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 getParameters()
 
-print "TESTING J48"
+print("TESTING J48")
 classifier = CQoSClassifierOperation.readClassifier(fileName + ".j48")
 testClassifier(classifier)
 
-print "TESTING MP"
+print("TESTING MP")
 classifier = CQoSClassifierOperation.readClassifier(fileName + ".mp")
 testClassifier(classifier)
 
-print "TESTING NB"
+print("TESTING NB")
 classifier = CQoSClassifierOperation.readClassifier(fileName + ".nb")
 testClassifier(classifier)
 
-print "TESTING SVM"
+print("TESTING SVM")
 classifier = CQoSClassifierOperation.readClassifier(fileName + ".svm")
 testClassifier(classifier)
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/cqos/linear_solver.py	(original)
--- b/tools/src/perfexplorer/cqos/linear_solver.py	(refactored)
@@ -21,33 +21,33 @@
 	global inApp
 	global inExp
 	global fileName
-	print "getting parameters..."
+	print("getting parameters...")
 	parameterMap = PerfExplorerModel.getModel().getScriptParameters()
 	keys = parameterMap.keySet()
 	for key in keys:
-		print key, parameterMap.get(key)
+		print(key, parameterMap.get(key))
 	config = parameterMap.get("config")
 	inApp = parameterMap.get("app")
 	inExp = parameterMap.get("exp")
 	fileName = parameterMap.get("fileName")
-	print "...done."
+	print("...done.")
 
 def loadTrials():
-	print "loading data..."
+	print("loading data...")
 	Utilities.setSession(config)
 	trials = Utilities.getTrialsForExperiment(inApp, inExp)
-	print "...done."
+	print("...done.")
 	return trials
 
 def loadExperiments():
-	print "loading data..."
+	print("loading data...")
 	Utilities.setSession(config)
 	experiments = Utilities.getExperimentsForApplication(inApp)
-	print "...done."
+	print("...done.")
 	return experiments
 
 def buildClassifier(results):
-	print "building classifier..."
+	print("building classifier...")
 	metadataFields = HashSet()
 
 	# general properties
@@ -86,52 +86,52 @@
 	start = time.clock()
 	classifier = CQoSClassifierOperation(results, "P_WALL_CLOCK_TIME", metadataFields, "ksp")
 	end = time.clock()
-	print end - start, " seconds to initialize classifier"
+	print(end - start, " seconds to initialize classifier")
 	classifier.setClassifierType(CQoSClassifierOperation.J48)
 	start = time.clock()
 	classifier.processData()
 	end = time.clock()
-	print end - start, " seconds to build classifier"
-	print "validating classifier..."
-	start = time.clock()
-	print classifier.crossValidateModel()
-	end = time.clock()
-	print end - start, " seconds to validate classifier"
+	print(end - start, " seconds to build classifier")
+	print("validating classifier...")
+	start = time.clock()
+	print(classifier.crossValidateModel())
+	end = time.clock()
+	print(end - start, " seconds to validate classifier")
 	classifier.writeClassifier(fileName + ".j48")
 	classifier.setClassifierType(CQoSClassifierOperation.NAIVE_BAYES)
 	start = time.clock()
 	classifier.processData()
 	end = time.clock()
-	print end - start, " seconds to build classifier"
-	print "validating classifier..."
-	start = time.clock()
-	print classifier.crossValidateModel()
-	end = time.clock()
-	print end - start, " seconds to validate classifier"
+	print(end - start, " seconds to build classifier")
+	print("validating classifier...")
+	start = time.clock()
+	print(classifier.crossValidateModel())
+	end = time.clock()
+	print(end - start, " seconds to validate classifier")
 	classifier.writeClassifier(fileName + ".nb")
 	classifier.setClassifierType(CQoSClassifierOperation.SUPPORT_VECTOR_MACHINE)
 	start = time.clock()
 	classifier.processData()
 	end = time.clock()
-	print end - start, " seconds to build classifier"
-	print "validating classifier..."
-	start = time.clock()
-	print classifier.crossValidateModel()
-	end = time.clock()
-	print end - start, " seconds to validate classifier"
+	print(end - start, " seconds to build classifier")
+	print("validating classifier...")
+	start = time.clock()
+	print(classifier.crossValidateModel())
+	end = time.clock()
+	print(end - start, " seconds to validate classifier")
 	classifier.writeClassifier(fileName + ".svm")
 	classifier.setClassifierType(CQoSClassifierOperation.MULTILAYER_PERCEPTRON)
 	start = time.clock()
 	classifier.processData()
 	end = time.clock()
-	print end - start, " seconds to build classifier"
-	print "validating classifier..."
-	start = time.clock()
-	print classifier.crossValidateModel()
-	end = time.clock()
-	print end - start, " seconds to validate classifier"
+	print(end - start, " seconds to build classifier")
+	print("validating classifier...")
+	start = time.clock()
+	print(classifier.crossValidateModel())
+	end = time.clock()
+	print(end - start, " seconds to validate classifier")
 	classifier.writeClassifier(fileName + ".mp")
-	print "...done."
+	print("...done.")
 	return classifier
 
 def testClassifier(classifier):
@@ -168,24 +168,24 @@
 							className =  classifier.getClass(inputFields)
 							confidence = classifier.getConfidence()
 							if confidence != "bcgs":
-								print inputFields
-								print "\tSolver: ", className,  confidence
-
-
-
-print "--------------- JPython test script start ------------"
+								print(inputFields)
+								print("\tSolver: ", className,  confidence)
+
+
+
+print("--------------- JPython test script start ------------")
 
 getParameters()
 results = ArrayList()
 
-print "getting trials..."
+print("getting trials...")
 start = time.clock()
 
 trials = loadTrials()
 index = 1
 totalTrials = trials.size()
 for trial in trials:
-	print "\rLoading trial ", index, "of", totalTrials,
+	print("\rLoading trial ", index, "of", totalTrials, end=' ')
 	loaded = TrialMeanResult(trial)
 	"""
 	# important - split the trial, because it's iterative, and each iteration
@@ -211,13 +211,13 @@
 		# loaded = TrialMeanResult(trial)
 		# results.add(loaded)
 
-print "...done."
+print("...done.")
 end = time.clock()
-print end - start, " seconds to load data"
-print "Total Trials:", results.size()
+print(end - start, " seconds to load data")
+print("Total Trials:", results.size())
 
 classifier = buildClassifier(results)
 # classifier = CQoSClassifierOperation.readClassifier(fileName + ".j48")
 # testClassifier(classifier)
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/cqos/loopksp.py	(original)
--- b/tools/src/perfexplorer/cqos/loopksp.py	(refactored)
@@ -1,6 +1,6 @@
 import sys
 import time
-import commands
+import subprocess
 
 True = 1
 False = 0
@@ -20,13 +20,13 @@
 		for kspmaxit in ['200', '400', '600']:
 			for gridx in ['16', '32']:
 				gridy=gridx
-				gridsize = `gridx` + 'x' + `gridy`
+				gridsize = repr(gridx) + 'x' + repr(gridy)
 				#for pc in ['jacobi', 'bjacobi', 'none', 'sor', 'asm', 'cholesky']:
 				for ksprtol in ['1.000000e-04', '1.000000e-05']:
 					getrec = 'java -cp /home/khuck/tau2/tools/src/perfexplorer/classifier.jar:/home/khuck/.ParaProf/weka.jar cqos.CQoSClassifier /tmp/classifier.nosplit.mp lidvelocity:' + lidvelocity + ' gridsize:' + gridx + 'x' + gridx + ' grashof:' + grashof + ' cflini:' + cflini + ' snesrtol:' + snesrtol + ' kspmaxit:' + kspmaxit + ' ksprtol:' + ksprtol
 					# get KSP recommendation
 					#print getrec
-					(status, output) = commands.getstatusoutput(getrec) 
+					(status, output) = subprocess.getstatusoutput(getrec) 
 					#print output
 					if output.startswith('fgmres'):
 						ksp='fgmres'
@@ -36,7 +36,7 @@
 						ksp='bcgs'
 					if output.startswith('tfqmr'):
 						ksp='tfqmr'
-					print ksp
+					print(ksp)
 					"""
 					# get PC recommendation
 					getrec = 'java -cp /home/khuck/tau2/tools/src/perfexplorer/classifier.jar:/home/khuck/.ParaProf/weka.jar cqos.CQoSClassifier /tmp/classifier.pc.mp lidvelocity:' + lidvelocity + ' gridsize:' + gridx + 'x' + gridx + ' grashof:' + grashof + ' cflini:' + cflini + ' snesrtol:' + snesrtol + ' kspmaxit:' + kspmaxit + ' ksp:' + ksp + ' ksprtol:' + ksprtol
@@ -66,31 +66,31 @@
 
 					# make directories for results
 					dirname = 'ex27'+'-'+ procs + '-' + 'x' + gridx + '-' + 'y' + gridy + '-' + 'lid' + lidvelocity + '-' + 'grh' + grashof + '-' + 'srtol' + snesrtol + '-' + 'krtol' + ksprtol + '-' + 'snes' + snes
-					print dirname
+					print(dirname)
 					createdir= 'mkdir /home/khuck/data/petsc/' + classifier + '/' + dirname
 					#print createdir
-					commands.getstatusoutput(createdir)
-					commands.getstatusoutput(createdir + '/default')
-					commands.getstatusoutput(createdir + '/' + ksp)
+					subprocess.getstatusoutput(createdir)
+					subprocess.getstatusoutput(createdir + '/default')
+					subprocess.getstatusoutput(createdir + '/' + ksp)
 					# run with default solver
 					mycommand = '$MPIEXEC -np ' + procs + ' /home/khuck/src/petsc/metadata/ex27 ' ' -snes_type ' + snes + ' -lidvelocity ' + lidvelocity + ' -da_grid_x ' + gridx + ' -da_grid_y ' + gridx + ' -print -snes_monitor -snes_monitor_metadata -grashof ' + grashof + ' -cfl_ini ' + cflini + ' -snes_rtol ' + snesrtol + ' -ksp_rtol ' + ksprtol + ' -preload off' + ' >& /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default.log'
 					# print mycommand
 					start = time.time()
-					(status, output) = 	commands.getstatusoutput(mycommand)
+					(status, output) = 	subprocess.getstatusoutput(mycommand)
 					end = time.time()
 					default = end - start
-					print 'DEFAULT: ', default
-					commands.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default/.')
+					print('DEFAULT: ', default)
+					subprocess.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default/.')
 					# run with recommendation
 					mycommand = '$MPIEXEC -np ' + procs + ' /home/khuck/src/petsc/metadata/ex27 ' ' -snes_type ' + snes + ' -ksp_type ' + ksp + ' -lidvelocity ' + lidvelocity + ' -da_grid_x ' + gridx + ' -da_grid_y ' + gridx + ' -print -snes_monitor -snes_monitor_metadata -grashof ' + grashof + ' -cfl_ini ' + cflini + ' -snes_rtol ' + snesrtol + ' -ksp_rtol ' + ksprtol + ' -preload off' + ' >& /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + classifier + '.log'
 					start = time.time()
-					(status, output) = 	commands.getstatusoutput(mycommand)
+					(status, output) = 	subprocess.getstatusoutput(mycommand)
 					end = time.time()
 					recommended = end - start
 					# print output
-					print 'RECOMMENDED: ', recommended
-					commands.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + ksp + '/.')
-					f.write(lidvelocity + ',' + snesrtol + ',' + grashof + ',' + cflini + ',' + kspmaxit + ',' + gridsize + ',' + ksprtol + ',' + ksp + ',' + `default` + ',' + `recommended` + '\n')
+					print('RECOMMENDED: ', recommended)
+					subprocess.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + ksp + '/.')
+					f.write(lidvelocity + ',' + snesrtol + ',' + grashof + ',' + cflini + ',' + kspmaxit + ',' + gridsize + ',' + ksprtol + ',' + ksp + ',' + repr(default) + ',' + repr(recommended) + '\n')
 					f.flush()
 
 f.close()
--- a/tools/src/perfexplorer/cqos/looppc.py	(original)
--- b/tools/src/perfexplorer/cqos/looppc.py	(refactored)
@@ -1,6 +1,6 @@
 import sys
 import time
-import commands
+import subprocess
 
 True = 1
 False = 0
@@ -20,13 +20,13 @@
 		for kspmaxit in ['200', '400', '600']:
 			for gridx in ['16', '32']:
 				gridy=gridx
-				gridsize = `gridx` + 'x' + `gridy`
+				gridsize = repr(gridx) + 'x' + repr(gridy)
 				#for pc in ['jacobi', 'bjacobi', 'none', 'sor', 'asm', 'cholesky']:
 				for ksprtol in ['1.000000e-04', '1.000000e-05']:
 					getrec = 'java -cp /home/khuck/tau2/tools/src/perfexplorer/classifier.jar:/home/khuck/.ParaProf/weka.jar cqos.CQoSClassifier /tmp/classifier.nosplit.mp lidvelocity:' + lidvelocity + ' gridsize:' + gridx + 'x' + gridx + ' grashof:' + grashof + ' cflini:' + cflini + ' snesrtol:' + snesrtol + ' kspmaxit:' + kspmaxit + ' ksprtol:' + ksprtol
 					# get KSP recommendation
 					#print getrec
-					(status, output) = commands.getstatusoutput(getrec) 
+					(status, output) = subprocess.getstatusoutput(getrec) 
 					#print output
 					if output.startswith('fgmres'):
 						ksp='fgmres'
@@ -36,11 +36,11 @@
 						ksp='bcgs'
 					if output.startswith('tfqmr'):
 						ksp='tfqmr'
-					print ksp
+					print(ksp)
 					# get PC recommendation
 					getrec = 'java -cp /home/khuck/tau2/tools/src/perfexplorer/classifier.jar:/home/khuck/.ParaProf/weka.jar cqos.CQoSClassifier /tmp/classifier.pc.mp lidvelocity:' + lidvelocity + ' gridsize:' + gridx + 'x' + gridx + ' grashof:' + grashof + ' cflini:' + cflini + ' snesrtol:' + snesrtol + ' kspmaxit:' + kspmaxit + ' ksp:' + ksp + ' ksprtol:' + ksprtol
 					#print getrec
-					(status, output) = commands.getstatusoutput(getrec) 
+					(status, output) = subprocess.getstatusoutput(getrec) 
 					#for pc in ['jacobi', 'bjacobi', 'none', 'sor', 'asm', 'cholesky']:
 					#print output
 					if output.startswith('jacobi'):
@@ -60,35 +60,35 @@
 					if output.startswith('icc'):
 						pc='icc'
 						procs='1'
-					print pc
+					print(pc)
 
 					# make directories for results
 					dirname = 'ex27'+'-'+ procs + '-' + 'x' + gridx + '-' + 'y' + gridy + '-' + 'lid' + lidvelocity + '-' + 'grh' + grashof + '-' + 'srtol' + snesrtol + '-' + 'krtol' + ksprtol + '-' + 'snes' + snes + '-' + 'pc' + pc
-					print dirname
+					print(dirname)
 					createdir= 'mkdir /home/khuck/data/petsc/' + classifier + '/' + dirname
 					#print createdir
-					commands.getstatusoutput(createdir)
-					commands.getstatusoutput(createdir + '/default')
-					commands.getstatusoutput(createdir + '/' + ksp)
+					subprocess.getstatusoutput(createdir)
+					subprocess.getstatusoutput(createdir + '/default')
+					subprocess.getstatusoutput(createdir + '/' + ksp)
 					# run with default solver
 					mycommand = '$MPIEXEC -np ' + procs + ' /home/khuck/src/petsc/metadata/ex27 ' ' -snes_type ' + snes + ' -ksp_type gmres -pc_type ilu -lidvelocity ' + lidvelocity + ' -da_grid_x ' + gridx + ' -da_grid_y ' + gridx + ' -print -snes_monitor -snes_monitor_metadata -grashof ' + grashof + ' -cfl_ini ' + cflini + ' -snes_rtol ' + snesrtol + ' -ksp_rtol ' + ksprtol + ' -preload off' + ' >& /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default.log'
 					# print mycommand
 					start = time.time()
-					(status, output) = 	commands.getstatusoutput(mycommand)
+					(status, output) = 	subprocess.getstatusoutput(mycommand)
 					end = time.time()
 					default = end - start
-					print 'DEFAULT: ', default
-					commands.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default/.')
+					print('DEFAULT: ', default)
+					subprocess.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default/.')
 					# run with recommendation
 					mycommand = '$MPIEXEC -np ' + procs + ' /home/khuck/src/petsc/metadata/ex27 ' ' -snes_type ' + snes + ' -ksp_type ' + ksp + ' -pc_type ' + pc + ' -lidvelocity ' + lidvelocity + ' -da_grid_x ' + gridx + ' -da_grid_y ' + gridx + ' -print -snes_monitor -snes_monitor_metadata -grashof ' + grashof + ' -cfl_ini ' + cflini + ' -snes_rtol ' + snesrtol + ' -ksp_rtol ' + ksprtol + ' -preload off' + ' >& /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + classifier + '.log'
 					start = time.time()
-					(status, output) = 	commands.getstatusoutput(mycommand)
+					(status, output) = 	subprocess.getstatusoutput(mycommand)
 					end = time.time()
 					recommended = end - start
 					# print output
-					print 'RECOMMENDED: ', recommended
-					commands.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + ksp + '/.')
-					f.write(lidvelocity + ',' + snesrtol + ',' + grashof + ',' + cflini + ',' + kspmaxit + ',' + gridsize + ',' + ksprtol + ',' + pc + ',' + ksp + ',' + `default` + ',' + `recommended` + '\n')
+					print('RECOMMENDED: ', recommended)
+					subprocess.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + ksp + '/.')
+					f.write(lidvelocity + ',' + snesrtol + ',' + grashof + ',' + cflini + ',' + kspmaxit + ',' + gridsize + ',' + ksprtol + ',' + pc + ',' + ksp + ',' + repr(default) + ',' + repr(recommended) + '\n')
 					f.flush()
 
 f.close()
--- a/tools/src/perfexplorer/cqos/loopy.py	(original)
--- b/tools/src/perfexplorer/cqos/loopy.py	(refactored)
@@ -1,6 +1,6 @@
 import sys
 import time
-import commands
+import subprocess
 
 True = 1
 False = 0
@@ -30,7 +30,7 @@
 		for kspmaxit in ['200', '400', '600']:
 			for gridx in ['16', '32']:
 				gridy=gridx
-				gridsize = `gridx` + 'x' + `gridy`
+				gridsize = repr(gridx) + 'x' + repr(gridy)
 				#for pc in ['jacobi', 'ilu', 'bjacobi', 'none', 'sor', 'asm', 'cholesky', 'icc']:
 				for pc in ['jacobi', 'bjacobi', 'none', 'sor', 'asm', 'cholesky']:
 					#for matrixsize in ['15876x15876', '3844x3844']:
@@ -42,7 +42,7 @@
 							getrec = 'java -cp /home/khuck/tau2/tools/src/perfexplorer/classifier.jar:/home/khuck/.ParaProf/weka.jar cqos.CQoSClassifier /tmp/classifier.nosplit.mp lidvelocity:' + lidvelocity + ' gridsize:' + gridx + 'x' + gridx + ' grashof:' + grashof + ' cflini:' + cflini + ' snesrtol:' + snesrtol + ' kspmaxit:' + kspmaxit + ' pc:' + pc2 + ' ksprtol:' + ksprtol
 							# get recommendation
 							#print getrec
-							(status, output) = commands.getstatusoutput(getrec) 
+							(status, output) = subprocess.getstatusoutput(getrec) 
 							#print output
 							if output.startswith('fgmres'):
 								ksp='fgmres'
@@ -52,34 +52,34 @@
 								ksp='bcgs'
 							if output.startswith('tfqmr'):
 								ksp='tfqmr'
-							print ksp
+							print(ksp)
 							# make directories for results
 							dirname = 'ex27'+'-'+ procs + '-' + 'x' + gridx + '-' + 'y' + gridy + '-' + 'lid' + lidvelocity + '-' + 'grh' + grashof + '-' + 'srtol' + snesrtol + '-' + 'krtol' + ksprtol + '-' + 'snes' + snes + '-' + 'pc' + pc
-							print dirname
+							print(dirname)
 							createdir= 'mkdir /home/khuck/data/petsc/' + classifier + '/' + dirname
 							#print createdir
-							commands.getstatusoutput(createdir)
-							commands.getstatusoutput(createdir + '/default')
-							commands.getstatusoutput(createdir + '/' + ksp)
+							subprocess.getstatusoutput(createdir)
+							subprocess.getstatusoutput(createdir + '/default')
+							subprocess.getstatusoutput(createdir + '/' + ksp)
 							# run with default solver
 							mycommand = '$MPIEXEC -np ' + procs + ' /home/khuck/src/petsc/metadata/ex27 ' ' -snes_type ' + snes + ' -ksp_type ' + ksp + ' -lidvelocity ' + lidvelocity + ' -da_grid_x ' + gridx + ' -da_grid_y ' + gridx + ' -print -snes_monitor -snes_monitor_metadata -grashof ' + grashof + ' -cfl_ini ' + cflini + ' -snes_rtol ' + snesrtol + ' -ksp_rtol ' + ksprtol + ' -pc_type ' + pc + ' -preload off' + ' >& /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default.log'
 							# print mycommand
 							start = time.time()
-							(status, output) = 	commands.getstatusoutput(mycommand)
+							(status, output) = 	subprocess.getstatusoutput(mycommand)
 							end = time.time()
 							default = end - start
-							print 'DEFAULT: ', default
-							commands.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default/.')
+							print('DEFAULT: ', default)
+							subprocess.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default/.')
 							# run with recommendation
 							mycommand = '$MPIEXEC -np ' + procs + ' /home/khuck/src/petsc/metadata/ex27 ' ' -snes_type ' + snes + ' -ksp_type ' + ksp + ' -lidvelocity ' + lidvelocity + ' -da_grid_x ' + gridx + ' -da_grid_y ' + gridx + ' -print -snes_monitor -snes_monitor_metadata -grashof ' + grashof + ' -cfl_ini ' + cflini + ' -snes_rtol ' + snesrtol + ' -ksp_rtol ' + ksprtol + ' -pc_type ' + pc + ' -preload off' + ' >& /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + classifier + '.log'
 							start = time.time()
-							(status, output) = 	commands.getstatusoutput(mycommand)
+							(status, output) = 	subprocess.getstatusoutput(mycommand)
 							end = time.time()
 							recommended = end - start
 							# print output
-							print 'RECOMMENDED: ', recommended
-							commands.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + ksp + '/.')
-							f.write(lidvelocity + ',' + snesrtol + ',' + grashof + ',' + cflini + ',' + kspmaxit + ',' + gridsize + ',' + pc + ',' + ksprtol + ',' + ksp + ',' + `default` + ',' + `recommended` + '\n')
+							print('RECOMMENDED: ', recommended)
+							subprocess.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + ksp + '/.')
+							f.write(lidvelocity + ',' + snesrtol + ',' + grashof + ',' + cflini + ',' + kspmaxit + ',' + gridsize + ',' + pc + ',' + ksprtol + ',' + ksp + ',' + repr(default) + ',' + repr(recommended) + '\n')
 
 f.close()
 
--- a/tools/src/perfexplorer/cqos/loopy2.py	(original)
--- b/tools/src/perfexplorer/cqos/loopy2.py	(refactored)
@@ -1,6 +1,6 @@
 import sys
 import time
-import commands
+import subprocess
 
 True = 1
 False = 0
@@ -20,13 +20,13 @@
 		for kspmaxit in ['200', '400', '600']:
 			for gridx in ['16', '32']:
 				gridy=gridx
-				gridsize = `gridx` + 'x' + `gridy`
+				gridsize = repr(gridx) + 'x' + repr(gridy)
 				#for pc in ['jacobi', 'bjacobi', 'none', 'sor', 'asm', 'cholesky']:
 				for ksprtol in ['1.000000e-04', '1.000000e-05']:
 					getrec = 'java -cp /home/khuck/tau2/tools/src/perfexplorer/classifier.jar:/home/khuck/.ParaProf/weka.jar cqos.CQoSClassifier /tmp/classifier.nosplit.mp lidvelocity:' + lidvelocity + ' gridsize:' + gridx + 'x' + gridx + ' grashof:' + grashof + ' cflini:' + cflini + ' snesrtol:' + snesrtol + ' kspmaxit:' + kspmaxit + ' ksprtol:' + ksprtol
 					# get KSP recommendation
 					#print getrec
-					(status, output) = commands.getstatusoutput(getrec) 
+					(status, output) = subprocess.getstatusoutput(getrec) 
 					#print output
 					if output.startswith('fgmres'):
 						ksp='fgmres'
@@ -36,7 +36,7 @@
 						ksp='bcgs'
 					if output.startswith('tfqmr'):
 						ksp='tfqmr'
-					print ksp
+					print(ksp)
 					"""
 					# get PC recommendation
 					getrec = 'java -cp /home/khuck/tau2/tools/src/perfexplorer/classifier.jar:/home/khuck/.ParaProf/weka.jar cqos.CQoSClassifier /tmp/classifier.pc.mp lidvelocity:' + lidvelocity + ' gridsize:' + gridx + 'x' + gridx + ' grashof:' + grashof + ' cflini:' + cflini + ' snesrtol:' + snesrtol + ' kspmaxit:' + kspmaxit + ' ksp:' + ksp + ' ksprtol:' + ksprtol
@@ -66,31 +66,31 @@
 
 					# make directories for results
 					dirname = 'ex27'+'-'+ procs + '-' + 'x' + gridx + '-' + 'y' + gridy + '-' + 'lid' + lidvelocity + '-' + 'grh' + grashof + '-' + 'srtol' + snesrtol + '-' + 'krtol' + ksprtol + '-' + 'snes' + snes
-					print dirname
+					print(dirname)
 					createdir= 'mkdir /home/khuck/data/petsc/' + classifier + '/' + dirname
 					#print createdir
-					commands.getstatusoutput(createdir)
-					commands.getstatusoutput(createdir + '/default')
-					commands.getstatusoutput(createdir + '/' + ksp)
+					subprocess.getstatusoutput(createdir)
+					subprocess.getstatusoutput(createdir + '/default')
+					subprocess.getstatusoutput(createdir + '/' + ksp)
 					# run with default solver
 					mycommand = '$MPIEXEC -np ' + procs + ' /home/khuck/src/petsc/metadata/ex27 ' ' -snes_type ' + snes + ' -lidvelocity ' + lidvelocity + ' -da_grid_x ' + gridx + ' -da_grid_y ' + gridx + ' -print -snes_monitor -snes_monitor_metadata -grashof ' + grashof + ' -cfl_ini ' + cflini + ' -snes_rtol ' + snesrtol + ' -ksp_rtol ' + ksprtol + ' -preload off' + ' >& /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default.log'
 					# print mycommand
 					start = time.time()
-					(status, output) = 	commands.getstatusoutput(mycommand)
+					(status, output) = 	subprocess.getstatusoutput(mycommand)
 					end = time.time()
 					default = end - start
-					print 'DEFAULT: ', default
-					commands.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default/.')
+					print('DEFAULT: ', default)
+					subprocess.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default/.')
 					# run with recommendation
 					mycommand = '$MPIEXEC -np ' + procs + ' /home/khuck/src/petsc/metadata/ex27 ' ' -snes_type ' + snes + ' -ksp_type ' + ksp + ' -lidvelocity ' + lidvelocity + ' -da_grid_x ' + gridx + ' -da_grid_y ' + gridx + ' -print -snes_monitor -snes_monitor_metadata -grashof ' + grashof + ' -cfl_ini ' + cflini + ' -snes_rtol ' + snesrtol + ' -ksp_rtol ' + ksprtol + ' -preload off' + ' >& /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + classifier + '.log'
 					start = time.time()
-					(status, output) = 	commands.getstatusoutput(mycommand)
+					(status, output) = 	subprocess.getstatusoutput(mycommand)
 					end = time.time()
 					recommended = end - start
 					# print output
-					print 'RECOMMENDED: ', recommended
-					commands.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + ksp + '/.')
-					f.write(lidvelocity + ',' + snesrtol + ',' + grashof + ',' + cflini + ',' + kspmaxit + ',' + gridsize + ',' + ksprtol + ',' + ksp + ',' + `default` + ',' + `recommended` + '\n')
+					print('RECOMMENDED: ', recommended)
+					subprocess.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + ksp + '/.')
+					f.write(lidvelocity + ',' + snesrtol + ',' + grashof + ',' + cflini + ',' + kspmaxit + ',' + gridsize + ',' + ksprtol + ',' + ksp + ',' + repr(default) + ',' + repr(recommended) + '\n')
 					f.flush()
 
 f.close()
--- a/tools/src/perfexplorer/cqos/optimizer.py	(original)
--- b/tools/src/perfexplorer/cqos/optimizer.py	(refactored)
@@ -19,33 +19,33 @@
 	global inApp
 	global inExp
 	global fileName
-	print "getting parameters..."
+	print("getting parameters...")
 	parameterMap = PerfExplorerModel.getModel().getScriptParameters()
 	keys = parameterMap.keySet()
 	for key in keys:
-		print key, parameterMap.get(key)
+		print(key, parameterMap.get(key))
 	config = parameterMap.get("config")
 	inApp = parameterMap.get("app")
 	inExp = parameterMap.get("exp")
 	fileName = parameterMap.get("fileName")
-	print "...done."
+	print("...done.")
 
 def loadTrials():
-	print "loading data..."
+	print("loading data...")
 	Utilities.setSession(config)
 	trials = Utilities.getTrialsForExperiment(inApp, inExp)
-	print "...done."
+	print("...done.")
 	return trials
 
 def loadExperiments():
-	print "loading data..."
+	print("loading data...")
 	Utilities.setSession(config)
 	experiments = Utilities.getExperimentsForApplication(inApp)
-	print "...done."
+	print("...done.")
 	return experiments
 
 def buildClassifier(results):
-	print "building classifier..."
+	print("building classifier...")
 	metadataFields = HashSet()
 	metadataFields.add("Time")
 	metadataFields.add("A")
@@ -58,37 +58,37 @@
 	# for performance
 	classifier = LinearOptimizerOperation(results, "Time", metadataFields, "Time")
 	classifier.processData()
-	print "...done."
+	print("...done.")
 	return classifier
 
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 #getParameters()
 results = ArrayList()
 
-print "getting trials..."
+print("getting trials...")
 
 trials = loadTrials()
 for trial in trials:
 	loaded = TrialMeanResult(trial)
 	results.add(loaded)
 
-print "...done."
-print "Total Trials:", results.size()
+print("...done.")
+print("Total Trials:", results.size())
 
 classifier = buildClassifier(results)
 r = classifier.getCoefficients()
 
-print r
+print(r)
 for a in range(0,11):
 	for b in range(0,11):
 		for c in range(0,11):
 			if a+b+c == 10:
 				inputFields = HashMap()
-				inputFields.put("A", `a`)
-				inputFields.put("B", `b`)
-				inputFields.put("C", `c`)
-				print a, b, c, " = ", classifier.classifyInstance(inputFields)
+				inputFields.put("A", repr(a))
+				inputFields.put("B", repr(b))
+				inputFields.put("C", repr(c))
+				print(a, b, c, " = ", classifier.classifyInstance(inputFields))
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/cqos/pc.py	(original)
--- b/tools/src/perfexplorer/cqos/pc.py	(refactored)
@@ -21,33 +21,33 @@
 	global inApp
 	global inExp
 	global fileName
-	print "getting parameters..."
+	print("getting parameters...")
 	parameterMap = PerfExplorerModel.getModel().getScriptParameters()
 	keys = parameterMap.keySet()
 	for key in keys:
-		print key, parameterMap.get(key)
+		print(key, parameterMap.get(key))
 	config = parameterMap.get("config")
 	inApp = parameterMap.get("app")
 	inExp = parameterMap.get("exp")
 	fileName = parameterMap.get("fileName")
-	print "...done."
+	print("...done.")
 
 def loadTrials():
-	print "loading data..."
+	print("loading data...")
 	Utilities.setSession(config)
 	trials = Utilities.getTrialsForExperiment(inApp, inExp)
-	print "...done."
+	print("...done.")
 	return trials
 
 def loadExperiments():
-	print "loading data..."
+	print("loading data...")
 	Utilities.setSession(config)
 	experiments = Utilities.getExperimentsForApplication(inApp)
-	print "...done."
+	print("...done.")
 	return experiments
 
 def buildClassifier(results):
-	print "building classifier..."
+	print("building classifier...")
 	metadataFields = HashSet()
 
 	# general properties
@@ -86,52 +86,52 @@
 	start = time.clock()
 	classifier = CQoSClassifierOperation(results, "P_WALL_CLOCK_TIME", metadataFields, "pc")
 	end = time.clock()
-	print end - start, " seconds to initialize classifier"
+	print(end - start, " seconds to initialize classifier")
 	classifier.setClassifierType(CQoSClassifierOperation.J48)
 	start = time.clock()
 	classifier.processData()
 	end = time.clock()
-	print end - start, " seconds to build classifier"
-	print "validating classifier..."
-	start = time.clock()
-	print classifier.crossValidateModel()
-	end = time.clock()
-	print end - start, " seconds to validate classifier"
+	print(end - start, " seconds to build classifier")
+	print("validating classifier...")
+	start = time.clock()
+	print(classifier.crossValidateModel())
+	end = time.clock()
+	print(end - start, " seconds to validate classifier")
 	classifier.writeClassifier(fileName + ".j48")
 	classifier.setClassifierType(CQoSClassifierOperation.NAIVE_BAYES)
 	start = time.clock()
 	classifier.processData()
 	end = time.clock()
-	print end - start, " seconds to build classifier"
-	print "validating classifier..."
-	start = time.clock()
-	print classifier.crossValidateModel()
-	end = time.clock()
-	print end - start, " seconds to validate classifier"
+	print(end - start, " seconds to build classifier")
+	print("validating classifier...")
+	start = time.clock()
+	print(classifier.crossValidateModel())
+	end = time.clock()
+	print(end - start, " seconds to validate classifier")
 	classifier.writeClassifier(fileName + ".nb")
 	classifier.setClassifierType(CQoSClassifierOperation.SUPPORT_VECTOR_MACHINE)
 	start = time.clock()
 	classifier.processData()
 	end = time.clock()
-	print end - start, " seconds to build classifier"
-	print "validating classifier..."
-	start = time.clock()
-	print classifier.crossValidateModel()
-	end = time.clock()
-	print end - start, " seconds to validate classifier"
+	print(end - start, " seconds to build classifier")
+	print("validating classifier...")
+	start = time.clock()
+	print(classifier.crossValidateModel())
+	end = time.clock()
+	print(end - start, " seconds to validate classifier")
 	classifier.writeClassifier(fileName + ".svm")
 	classifier.setClassifierType(CQoSClassifierOperation.MULTILAYER_PERCEPTRON)
 	start = time.clock()
 	classifier.processData()
 	end = time.clock()
-	print end - start, " seconds to build classifier"
-	print "validating classifier..."
-	start = time.clock()
-	print classifier.crossValidateModel()
-	end = time.clock()
-	print end - start, " seconds to validate classifier"
+	print(end - start, " seconds to build classifier")
+	print("validating classifier...")
+	start = time.clock()
+	print(classifier.crossValidateModel())
+	end = time.clock()
+	print(end - start, " seconds to validate classifier")
 	classifier.writeClassifier(fileName + ".mp")
-	print "...done."
+	print("...done.")
 	return classifier
 
 def testClassifier(classifier):
@@ -168,24 +168,24 @@
 							className =  classifier.getClass(inputFields)
 							confidence = classifier.getConfidence()
 							if confidence != "bcgs":
-								print inputFields
-								print "\tSolver: ", className,  confidence
-
-
-
-print "--------------- JPython test script start ------------"
+								print(inputFields)
+								print("\tSolver: ", className,  confidence)
+
+
+
+print("--------------- JPython test script start ------------")
 
 getParameters()
 results = ArrayList()
 
-print "getting trials..."
+print("getting trials...")
 start = time.clock()
 
 trials = loadTrials()
 index = 1
 totalTrials = trials.size()
 for trial in trials:
-	print "\rLoading trial ", index, "of", totalTrials,
+	print("\rLoading trial ", index, "of", totalTrials, end=' ')
 	loaded = TrialMeanResult(trial)
 	"""
 	# important - split the trial, because it's iterative, and each iteration
@@ -211,13 +211,13 @@
 		# loaded = TrialMeanResult(trial)
 		# results.add(loaded)
 
-print "...done."
+print("...done.")
 end = time.clock()
-print end - start, " seconds to load data"
-print "Total Trials:", results.size()
+print(end - start, " seconds to load data")
+print("Total Trials:", results.size())
 
 classifier = buildClassifier(results)
 # classifier = CQoSClassifierOperation.readClassifier(fileName + ".j48")
 # testClassifier(classifier)
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/cqos/recreate.py	(original)
--- b/tools/src/perfexplorer/cqos/recreate.py	(refactored)
@@ -1,6 +1,6 @@
 import sys
 import time
-import commands
+import subprocess
 
 True = 1
 False = 0
@@ -22,12 +22,12 @@
 	for grashof in ['100', '500', '1000']:
 		for gridx in ['16', '32']:
 			gridy=gridx
-			gridsize = `gridx` + 'x' + `gridy`
+			gridsize = repr(gridx) + 'x' + repr(gridy)
 			#for pc in ['jacobi', 'bjacobi', 'none', 'sor', 'asm', 'cholesky']:
 			getrec = 'java -cp /home/khuck/tau2/tools/src/perfexplorer/classifier.jar:/home/khuck/.ParaProf/weka.jar cqos.CQoSClassifier /tmp/classifier.nosplit.' + classifier + ' lidvelocity:' + lidvelocity + ' gridsize:' + gridx + 'x' + gridx + ' grashof:' + grashof
 			# get KSP recommendation
 			#print getrec
-			(status, output) = commands.getstatusoutput(getrec) 
+			(status, output) = subprocess.getstatusoutput(getrec) 
 			#print output
 			if output.startswith('fgmres'):
 				ksp='fgmres'
@@ -37,11 +37,11 @@
 				ksp='bcgs'
 			if output.startswith('tfqmr'):
 				ksp='tfqmr'
-			print ksp
+			print(ksp)
 			# get PC recommendation
 			getrec = 'java -cp /home/khuck/tau2/tools/src/perfexplorer/classifier.jar:/home/khuck/.ParaProf/weka.jar cqos.CQoSClassifier /tmp/classifier.pc.' + classifier + ' lidvelocity:' + lidvelocity + ' gridsize:' + gridx + 'x' + gridx + ' grashof:' + grashof + ' ksp:' + ksp
 			#print getrec
-			(status, output) = commands.getstatusoutput(getrec) 
+			(status, output) = subprocess.getstatusoutput(getrec) 
 			#for pc in ['jacobi', 'bjacobi', 'none', 'sor', 'asm', 'cholesky']:
 			#print output
 			if output.startswith('jacobi'):
@@ -61,36 +61,36 @@
 			if output.startswith('icc'):
 				pc='icc'
 				procs='1'
-			print pc
+			print(pc)
 
 			# make directories for results
 			dirname = 'ex27'+'-'+ procs + '-' + 'x' + gridx + '-' + 'y' + gridy + '-' + 'lid' + lidvelocity + '-' + 'grh' + grashof + '-' + 'srtol' + snesrtol + '-' + 'krtol' + ksprtol + '-' + 'snes' + snes + '-' + 'pc' + pc
-			print dirname
+			print(dirname)
 			createdir= 'mkdir /home/khuck/data/petsc/' + classifier + '/' + dirname
 			#print createdir
-			commands.getstatusoutput(createdir)
-			commands.getstatusoutput(createdir + '/default')
-			commands.getstatusoutput(createdir + '/' + ksp)
+			subprocess.getstatusoutput(createdir)
+			subprocess.getstatusoutput(createdir + '/default')
+			subprocess.getstatusoutput(createdir + '/' + ksp)
 			# run with default solver
 			mycommand = '$MPIEXEC -np ' + procs + ' /home/khuck/src/petsc/metadata/ex27 ' ' -snes_type ' + snes + ' -ksp_type gmres -pc_type ilu -lidvelocity ' + lidvelocity + ' -da_grid_x ' + gridx + ' -da_grid_y ' + gridx + ' -print -snes_monitor -grashof ' + grashof + ' -cfl_ini ' + cflini + ' -snes_rtol ' + snesrtol + ' -ksp_rtol ' + ksprtol + ' -preload off' + ' >& /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default.log'
 			# print mycommand
 			start = time.time()
-			(status, output) = 	commands.getstatusoutput(mycommand)
+			(status, output) = 	subprocess.getstatusoutput(mycommand)
 			end = time.time()
 			default = end - start
-			print 'DEFAULT: ', default
-			commands.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default/.')
+			print('DEFAULT: ', default)
+			subprocess.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default/.')
 			# run with recommendation
 			mycommand = '$MPIEXEC -np ' + procs + ' /home/khuck/src/petsc/metadata/ex27 ' ' -snes_type ' + snes + ' -ksp_type ' + ksp + ' -pc_type ' + pc + ' -lidvelocity ' + lidvelocity + ' -da_grid_x ' + gridx + ' -da_grid_y ' + gridx + ' -print -snes_monitor -grashof ' + grashof + ' -cfl_ini ' + cflini + ' -snes_rtol ' + snesrtol + ' -ksp_rtol ' + ksprtol + ' -preload off' + ' >& /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + classifier + '.log'
 			start = time.time()
-			(status, output) = 	commands.getstatusoutput(mycommand)
+			(status, output) = 	subprocess.getstatusoutput(mycommand)
 			end = time.time()
 			recommended = end - start
 			# print output
-			print 'RECOMMENDED: ', recommended
-			commands.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + ksp + '/.')
+			print('RECOMMENDED: ', recommended)
+			subprocess.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + ksp + '/.')
 			#f.write('lidvelocity, grashof, gridsize, ksp, pc, default, recommended\n')
-			f.write(lidvelocity + ',' + grashof + ',' + gridsize + ',' + ksp + ',' + pc + ',' + `default` + ',' + `recommended` + '\n')
+			f.write(lidvelocity + ',' + grashof + ',' + gridsize + ',' + ksp + ',' + pc + ',' + repr(default) + ',' + repr(recommended) + '\n')
 			f.flush()
 
 f.close()
--- a/tools/src/perfexplorer/cqos/small.py	(original)
--- b/tools/src/perfexplorer/cqos/small.py	(refactored)
@@ -1,6 +1,6 @@
 import sys
 import time
-import commands
+import subprocess
 
 True = 1
 False = 0
@@ -23,12 +23,12 @@
 			#for gridx in ['16', '32']:
 			for gridx in ['16']:
 				gridy=gridx
-				gridsize = `gridx` + 'x' + `gridy`
+				gridsize = repr(gridx) + 'x' + repr(gridy)
 				#for pc in ['jacobi', 'bjacobi', 'none', 'sor', 'asm', 'cholesky']:
 				getrec = 'java -cp /home/khuck/tau2/tools/src/perfexplorer/classifier.jar:/home/khuck/.ParaProf/weka.jar cqos.CQoSClassifier /tmp/classifier.nosplit.' + classifier + ' lidvelocity:' + lidvelocity + ' gridsize:' + gridx + 'x' + gridx + ' grashof:' + grashof
 				# get KSP recommendation
 				#print getrec
-				(status, output) = commands.getstatusoutput(getrec) 
+				(status, output) = subprocess.getstatusoutput(getrec) 
 				#print output
 				if output.startswith('fgmres'):
 					ksp='fgmres'
@@ -38,11 +38,11 @@
 					ksp='bcgs'
 				if output.startswith('tfqmr'):
 					ksp='tfqmr'
-				print ksp
+				print(ksp)
 				# get PC recommendation
 				getrec = 'java -cp /home/khuck/tau2/tools/src/perfexplorer/classifier.jar:/home/khuck/.ParaProf/weka.jar cqos.CQoSClassifier /tmp/classifier.pc.' + classifier + ' lidvelocity:' + lidvelocity + ' gridsize:' + gridx + 'x' + gridx + ' grashof:' + grashof + ' ksp:' + ksp
 				#print getrec
-				(status, output) = commands.getstatusoutput(getrec) 
+				(status, output) = subprocess.getstatusoutput(getrec) 
 				#for pc in ['jacobi', 'bjacobi', 'none', 'sor', 'asm', 'cholesky']:
 				#print output
 				if output.startswith('jacobi'):
@@ -62,36 +62,36 @@
 				if output.startswith('icc'):
 					pc='icc'
 					procs='1'
-				print pc
+				print(pc)
 
 				# make directories for results
 				dirname = 'ex27'+'-'+ procs + '-' + 'x' + gridx + '-' + 'y' + gridy + '-' + 'lid' + lidvelocity + '-' + 'grh' + grashof + '-' + 'srtol' + snesrtol + '-' + 'krtol' + ksprtol + '-' + 'snes' + snes + '-' + 'pc' + pc
-				print dirname
+				print(dirname)
 				createdir= 'mkdir /home/khuck/data/petsc/' + classifier + '/' + dirname
 				#print createdir
-				commands.getstatusoutput(createdir)
-				commands.getstatusoutput(createdir + '/default')
-				commands.getstatusoutput(createdir + '/' + ksp)
+				subprocess.getstatusoutput(createdir)
+				subprocess.getstatusoutput(createdir + '/default')
+				subprocess.getstatusoutput(createdir + '/' + ksp)
 				# run with default solver
 				mycommand = '$MPIEXEC -np ' + procs + ' /home/khuck/src/petsc/metadata/ex27 ' ' -snes_type ' + snes + ' -ksp_type gmres -pc_type ilu -lidvelocity ' + lidvelocity + ' -da_grid_x ' + gridx + ' -da_grid_y ' + gridx + ' -print -snes_monitor -grashof ' + grashof + ' -cfl_ini ' + cflini + ' -snes_rtol ' + snesrtol + ' -ksp_rtol ' + ksprtol + ' -preload off' + ' >& /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default.log'
 				# print mycommand
 				start = time.time()
-				(status, output) = 	commands.getstatusoutput(mycommand)
+				(status, output) = 	subprocess.getstatusoutput(mycommand)
 				end = time.time()
 				default = end - start
-				print 'DEFAULT: ', default
-				commands.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default/.')
+				print('DEFAULT: ', default)
+				subprocess.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/default/.')
 				# run with recommendation
 				mycommand = '$MPIEXEC -np ' + procs + ' /home/khuck/src/petsc/metadata/ex27 ' ' -snes_type ' + snes + ' -ksp_type ' + ksp + ' -pc_type ' + pc + ' -lidvelocity ' + lidvelocity + ' -da_grid_x ' + gridx + ' -da_grid_y ' + gridx + ' -print -snes_monitor -grashof ' + grashof + ' -cfl_ini ' + cflini + ' -snes_rtol ' + snesrtol + ' -ksp_rtol ' + ksprtol + ' -preload off' + ' >& /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + classifier + '.log'
 				start = time.time()
-				(status, output) = 	commands.getstatusoutput(mycommand)
+				(status, output) = 	subprocess.getstatusoutput(mycommand)
 				end = time.time()
 				recommended = end - start
 				# print output
-				print 'RECOMMENDED: ', recommended
-				commands.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + ksp + '/.')
+				print('RECOMMENDED: ', recommended)
+				subprocess.getstatusoutput('mv profile.* /home/khuck/data/petsc/' + classifier + '/' + dirname + '/' + ksp + '/.')
 				#f.write('lidvelocity, grashof, gridsize, ksp, pc, default, recommended\n')
-				f.write(lidvelocity + ',' + grashof + ',' + gridsize + ',' + ksp + ',' + pc + ',' + `default` + ',' + `recommended` + '\n')
+				f.write(lidvelocity + ',' + grashof + ',' + gridsize + ',' + ksp + ',' + pc + ',' + repr(default) + ',' + repr(recommended) + '\n')
 				f.flush()
 
 f.close()
--- a/tools/src/perfexplorer/cqos/test_linear_solver.py	(original)
--- b/tools/src/perfexplorer/cqos/test_linear_solver.py	(refactored)
@@ -21,16 +21,16 @@
 	global inApp
 	global inExp
 	global fileName
-	print "getting parameters..."
+	print("getting parameters...")
 	parameterMap = PerfExplorerModel.getModel().getScriptParameters()
 	keys = parameterMap.keySet()
 	for key in keys:
-		print key, parameterMap.get(key)
+		print(key, parameterMap.get(key))
 	config = parameterMap.get("config")
 	inApp = parameterMap.get("app")
 	inExp = parameterMap.get("exp")
 	fileName = parameterMap.get("fileName")
-	print "...done."
+	print("...done.")
 
 def testClassifier(classifier):
 	bcgs = 0
@@ -80,32 +80,32 @@
 											tfqmr+=1
 										if className == "cg":
 											cg+=1
-	print "bcgs", bcgs
-	print "fgmres", fgmres
-	print "gmres", gmres
-	print "tfqmr", tfqmr
-	print "cg", cg
+	print("bcgs", bcgs)
+	print("fgmres", fgmres)
+	print("gmres", gmres)
+	print("tfqmr", tfqmr)
+	print("cg", cg)
 
 
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 getParameters()
 
-print "TESTING J48"
+print("TESTING J48")
 classifier = CQoSClassifierOperation.readClassifier(fileName + ".j48")
 testClassifier(classifier)
 
-print "TESTING MP"
+print("TESTING MP")
 classifier = CQoSClassifierOperation.readClassifier(fileName + ".mp")
 testClassifier(classifier)
 
-print "TESTING NB"
+print("TESTING NB")
 classifier = CQoSClassifierOperation.readClassifier(fileName + ".nb")
 testClassifier(classifier)
 
-print "TESTING SVM"
+print("TESTING SVM")
 classifier = CQoSClassifierOperation.readClassifier(fileName + ".svm")
 testClassifier(classifier)
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/bluegene.long.py	(original)
--- b/tools/src/perfexplorer/etc/bluegene.long.py	(refactored)
@@ -6,7 +6,7 @@
 True = 1
 
 def glue():
-	print "doing long run test for ocracoke"
+	print("doing long run test for ocracoke")
 	# load the trial
 	Utilities.setSession("perfdmf_test")
 	trial1 = Utilities.getTrial("gtc_bench", "ocracoke.longrun", "256p_5000ts_100micell")
@@ -38,10 +38,10 @@
 			# grapher.setLogYAxis(True)
 			grapher.processData()
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 glue()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/bluemult.long.py	(original)
--- b/tools/src/perfexplorer/etc/bluemult.long.py	(refactored)
@@ -6,7 +6,7 @@
 True = 1
 
 def glue():
-	print "doing long run test for ocracoke"
+	print("doing long run test for ocracoke")
 	# load the trial
 	Utilities.setSession("perfdmf_test")
 	trial1 = Utilities.getTrial("gtc_bench", "superphases", "64")
@@ -34,10 +34,10 @@
 		# grapher.setLogYAxis(True)
 		grapher.processData()
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 glue()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/bluemultphases.long.py	(original)
--- b/tools/src/perfexplorer/etc/bluemultphases.long.py	(refactored)
@@ -6,7 +6,7 @@
 True = 1
 
 def glue():
-	print "doing long run test for ocracoke"
+	print("doing long run test for ocracoke")
 	# load the trial
 	Utilities.setSession("perfdmf_test")
 	# trial1 = Utilities.getTrial("gtc_bench", "superphases", "64")
@@ -21,13 +21,13 @@
 	extractor = ExtractEventOperation(result1, events)
 	extracted = extractor.processData().get(0)
 
-	print "extracted phases..."
+	print("extracted phases...")
 
 	# get the Statistics
 	dostats = BasicStatisticsOperation(extracted, False)
 	stats = dostats.processData()
 
-	print "got stats..."
+	print("got stats...")
 
 	metrics = ArrayList()
 	metrics.add("BGL_TIMERS")
@@ -45,10 +45,10 @@
 		# grapher.setLogYAxis(True)
 		grapher.processData()
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 glue()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/characterization.py	(original)
--- b/tools/src/perfexplorer/etc/characterization.py	(refactored)
@@ -3,7 +3,7 @@
 from edu.uoregon.tau.perfdmf import *
 
 def glue(pe):
-	print "doing glue test"
+	print("doing glue test")
 	Utilities.setSession("peri_test")
 	trial1 = Utilities.GetTrial("GTC_s_PAPI", "VN XT3", "004")
 	trial2 = Utilities.GetTrial("GTC_s_PAPI", "VN XT3", "008")
@@ -17,14 +17,14 @@
 	for thread in diffs.getThreads():
 		for event in diffs.getEvents():
 			for metric in diffs.getMetrics():
-				print thread , event , metric
+				print(thread , event , metric)
 				# print diffs.getDataPoint(thread, event, metric, AbstractResult.EXCLUSIVE)
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 pe = ScriptFacade()
 glue(pe)
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/clusterTest.py	(original)
--- b/tools/src/perfexplorer/etc/clusterTest.py	(refactored)
@@ -6,7 +6,7 @@
 True = 1
 
 def glue():
-	print "doing cluster test"
+	print("doing cluster test")
 	# load the trial
 	Utilities.setSession("peri_s3d")
 	trial = Utilities.getTrial("S3D", "hybrid-study", "hybrid")
@@ -21,10 +21,10 @@
 			kmeans = KMeansOperation(reduced, metric, AbstractResult.EXCLUSIVE, k)
 			kmeans.processData()
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 glue()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/computeDilation.py	(original)
--- b/tools/src/perfexplorer/etc/computeDilation.py	(refactored)
@@ -13,11 +13,11 @@
 inTrial = ""
 
 def load():
-	print "loading data..."
+	print("loading data...")
 	parameterMap = PerfExplorerModel.getModel().getScriptParameters()
 	keys = parameterMap.keySet()
 	for key in keys:
-		print key, parameterMap.get(key)
+		print(key, parameterMap.get(key))
 	config = parameterMap.get("config")
 	inApp = parameterMap.get("app")
 	inExp = parameterMap.get("exp")
@@ -25,7 +25,7 @@
 	Utilities.setSession(config)
 	#trial = Utilities.getTrial("s3d", "intrepid-c2h4-spacemap", "1728")
 	trial = Utilities.getTrial(inApp, inExp, inTrial)
-	print "...done."
+	print("...done.")
 	return trial
 
 def computeDilation(networkSize, senderCoords, receiverCoords):
@@ -53,15 +53,15 @@
 
 	return distX+distY+distZ
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 trial = load()
 start = time.clock()
-print "getting thread metadata"
+print("getting thread metadata")
 metadata = TrialThreadMetadata(trial)
-print "getting common metadata"
+print("getting common metadata")
 commonMetadata = TrialMetadata(trial)
 end = time.clock()
-print "metadata time:", end-start, "seconds"
+print("metadata time:", end-start, "seconds")
 
 networkSize = commonMetadata.getCommonAttributes().get("BGP Size")
 tauConfig =  commonMetadata.getCommonAttributes().get("TAU Config")
@@ -76,11 +76,11 @@
 
 start = time.clock()
 if haveSendData:
-	print "TAU_EACH_SEND data found."
+	print("TAU_EACH_SEND data found.")
 	start = time.clock()
 	input = TrialResult(trial)
 	end = time.clock()
-	print "loading time:", end-start, "seconds"
+	print("loading time:", end-start, "seconds")
 	for thread in input.getThreads():
 		for event in input.getUserEvents():
 			senderCoords = metadata.getNameValue(thread, "BGP Coords")
@@ -144,10 +144,10 @@
 				data.addColumn(0, dilation/6.0, dilation/6.0)
 
 end = time.clock()
-print "computation time:", end-start, "seconds"
+print("computation time:", end-start, "seconds")
 				
 avgDilation = float(dilation) / float(count)
-print avgDilation, worst
+print(avgDilation, worst)
 PerfExplorerHistogramChart.doHistogram(data);
 	
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/correlation.py	(original)
--- b/tools/src/perfexplorer/etc/correlation.py	(refactored)
@@ -4,7 +4,7 @@
 from java.util import ArrayList
 
 def glue():
-	print "doing correlation test"
+	print("doing correlation test")
 	Utilities.setSession("peri_gtc")
 	trial = Utilities.getTrial("GTC", "ocracoke-O5", "2048")
 	result = TrialResult(trial)
@@ -21,13 +21,13 @@
 	for event in result.getEvents():
 		for metric in result.getMetrics():
 			for thread in result.getThreads():
-				print event, CorrelationResult.typeToString(thread), metric, ":", AbstractResult.typeToString(type), result.getDataPoint(thread, event, metric, type)
+				print(event, CorrelationResult.typeToString(thread), metric, ":", AbstractResult.typeToString(type), result.getDataPoint(thread, event, metric, type))
 
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 glue()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/difference.py	(original)
--- b/tools/src/perfexplorer/etc/difference.py	(refactored)
@@ -7,7 +7,7 @@
 False = 0
 
 def diffs():
-	print "doing phase test for gtc on jaguar"
+	print("doing phase test for gtc on jaguar")
 	# load the trials
 	Utilities.setSession("PERI_DB_production")
 	baseline = Utilities.getTrial("gtc", "jaguar", "64")
@@ -17,14 +17,14 @@
 	diff.addInput(comparison)
 	diff.processData()
 	metaDiff = DifferenceMetadataOperation(baseline, comparison)
-	print metaDiff.differencesAsString()
+	print(metaDiff.differencesAsString())
 
 	return
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 diffs()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/expectation.rules.py	(original)
--- b/tools/src/perfexplorer/etc/expectation.rules.py	(refactored)
@@ -6,7 +6,7 @@
 True = 1
 
 def glue():
-	print "Comparing performance between two trials, including metadata"
+	print("Comparing performance between two trials, including metadata")
 
 	# load the trials
 	Utilities.setSession("perfdmf_test")
@@ -28,10 +28,10 @@
 	ruleHarness.processRules()
 	# print ruleHarness.getLog()
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 glue()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/generalcharttest.py	(original)
--- b/tools/src/perfexplorer/etc/generalcharttest.py	(refactored)
@@ -2,7 +2,7 @@
 from edu.uoregon.tau.perfexplorer.common import TransformationType
 from edu.uoregon.tau.perfexplorer.common import AnalysisType
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 pe = ScriptFacade()
 
@@ -140,4 +140,4 @@
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/glue.py	(original)
--- b/tools/src/perfexplorer/etc/glue.py	(refactored)
@@ -3,7 +3,7 @@
 from edu.uoregon.tau.perfdmf import Trial
 
 def glue():
-	print "doing glue test"
+	print("doing glue test")
 	Utilities.setSession("peri_gtc")
 	trial = Utilities.getTrial("GTC", "ocracoke-O2", "64")
 	trial2 = Utilities.getTrial("GTC", "ocracoke-O2", "128")
@@ -23,13 +23,13 @@
 	for thread in total.getThreads():
 		for event in total.getEvents():
 			for metric in total.getMetrics():
-				print thread , event , metric
+				print(thread , event , metric)
 				# print mean.getDataPoint(thread, event, metric, AbstractResult.EXCLUSIVE)
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 glue()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/graphlongrun.py	(original)
--- b/tools/src/perfexplorer/etc/graphlongrun.py	(refactored)
@@ -7,7 +7,7 @@
 True = 1
 
 def glue():
-	print "doing long run test"
+	print("doing long run test")
 	# load the trial
 	Utilities.setSession("perfdmf_test")
 	trial1 = Utilities.getTrial("gtc_bench", "jaguar.longrun", "64.first")
@@ -100,10 +100,10 @@
 	grapher.processData()
 
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 glue()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/graphphases.py	(original)
--- b/tools/src/perfexplorer/etc/graphphases.py	(refactored)
@@ -7,7 +7,7 @@
 True = 1
 
 def glue():
-	print "doing long run test"
+	print("doing long run test")
 	# load the trial
 	Utilities.setSession("perfdmf_test")
 	trial = Utilities.getTrial("gtc_bench", "jaguar.longrun2", "64")
@@ -30,10 +30,10 @@
 	grapher.processData()
 
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 glue()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/gtc.py	(original)
--- b/tools/src/perfexplorer/etc/gtc.py	(refactored)
@@ -113,7 +113,7 @@
 	pe.setChartHorizontal(1)
 	pe.doGeneralChart()
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 pe = ScriptFacade()
 Simple(pe)
@@ -127,4 +127,4 @@
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/heatmap.datasource.py	(original)
--- b/tools/src/perfexplorer/etc/heatmap.datasource.py	(refactored)
@@ -4,7 +4,7 @@
 True = 1
 False = 0
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 files = []
 #files.append("/home/khuck/tau2/examples/NPB2.3/bin")
 #input = DataSourceResult(DataSourceResult.TAUPROFILE, files, False);
@@ -16,7 +16,7 @@
 start = time.clock()
 input = DataSourceResult(DataSourceResult.PPK, files, False);
 end = time.clock()
-print "Loaded the data! Time:", end-start, "seconds"
+print("Loaded the data! Time:", end-start, "seconds")
 messageHeatMap = BuildMessageHeatMap(input)
 messageHeatMap.processData()
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/heatmap.py	(original)
--- b/tools/src/perfexplorer/etc/heatmap.py	(refactored)
@@ -6,7 +6,7 @@
 True = 1
 False = 0
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 #Utilities.setSession("peris3d")
 #trial = Utilities.getTrial("s3d", "intrepid-c2h4-misc", "512_com")
 #trial = Utilities.getTrial("s3d", "intrepid-c2h4-misc", "8000_comm_callpath")
@@ -18,4 +18,4 @@
 input = TrialResult(trial)
 messageHeatMap = BuildMessageHeatMap(input)
 messageHeatMap.processData()
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/hlrs_gtc.py	(original)
--- b/tools/src/perfexplorer/etc/hlrs_gtc.py	(refactored)
@@ -8,28 +8,28 @@
 False = 0
 
 def load():
-	print "loading data..."
+	print("loading data...")
 	Utilities.setSession("perfdmf.demo")
 	trial1 = Utilities.getTrial("gtc", "phases", "jaguar.64")
 	result = TrialResult(trial1)
-	print "...done."
+	print("...done.")
 	return result
 
 def first(input):
 	# get the iteration inclusive totals
 
-	print "searching for iteration events (no classpath)..."
+	print("searching for iteration events (no classpath)...")
 	events = ArrayList()
 	for event in input.getEvents():
 		#if event.find("Iteration") >= 0 and input.getEventGroupName(event).find("TAU_PHASE") < 0:
 		if event.find("Iteration") >= 0 and event.find("=>") < 0:
 			events.add(event)
-	print "...done."
+	print("...done.")
 
-	print "extracting phases..."
+	print("extracting phases...")
 	extractor = ExtractEventOperation(input, events)
 	extracted = extractor.processData().get(0)
-	print "...done."
+	print("...done.")
 
 	return extracted
 
@@ -43,21 +43,21 @@
 	return input
 
 def second(extracted):
-	print "deriving metrics..."
+	print("deriving metrics...")
 	extracted = deriveStat(extracted, "PAPI_L1_TCA", "PAPI_L1_TCM", DeriveMetricOperation.SUBTRACT)
 	extracted = deriveStat(extracted, "(PAPI_L1_TCA-PAPI_L1_TCM)", "PAPI_L1_TCA", DeriveMetricOperation.DIVIDE)
 	extracted = deriveStat(extracted, "PAPI_L1_TCM", "PAPI_L2_TCM", DeriveMetricOperation.SUBTRACT)
 	extracted = deriveStat(extracted, "(PAPI_L1_TCM-PAPI_L2_TCM)", "PAPI_L1_TCM", DeriveMetricOperation.DIVIDE)
 	extracted = deriveStat(extracted, "PAPI_FP_INS", "P_WALL_CLOCK_TIME", DeriveMetricOperation.DIVIDE)
 	extracted = deriveStat(extracted, "PAPI_FP_INS", "PAPI_TOT_INS", DeriveMetricOperation.DIVIDE)
-	print "...done."
+	print("...done.")
 
-	print "getting stats..."
+	print("getting stats...")
 	dostats = BasicStatisticsOperation(extracted, False)
 	stats = dostats.processData()
-	print "...done."
+	print("...done.")
 
-	print "drawing charts..."
+	print("drawing charts...")
 	for metric in stats.get(0).getMetrics():
 		if metric != "(PAPI_L1_TCA-PAPI_L1_TCM)" and metric != "(PAPI_L1_TCM-PAPI_L2_TCM)" and metric != "PAPI_TOT_INS" and metric != "PAPI_L1_TCA" and metric != "PAPI_FP_INS":
 			grapher = DrawMMMGraph(stats)
@@ -87,7 +87,7 @@
 			grapher.setYAxisLabel("Inclusive " + metric);
 			# grapher.setLogYAxis(True)
 			grapher.processData()
-	print "...done."
+	print("...done.")
 
 	extracted = None
 	stats = None
@@ -104,7 +104,7 @@
 	subsetevents.add("SHIFTI")
 
 	for subsetevent in subsetevents:
-		print "extracting callpath phases..."
+		print("extracting callpath phases...")
 		events = ArrayList()
 		for event in input.getEvents():
 			if event.find("Iteration") >= 0 and event.rfind(subsetevent) >= 0:
@@ -112,26 +112,26 @@
 
 		extractor = ExtractEventOperation(input, events)
 		extracted = extractor.processData().get(0)
-		print "...done."
+		print("...done.")
 
 		# derive metrics
 
-		print "deriving metrics..."
+		print("deriving metrics...")
 		extracted = deriveStat(extracted, "PAPI_L1_TCA", "PAPI_L1_TCM", DeriveMetricOperation.SUBTRACT)
 		extracted = deriveStat(extracted, "(PAPI_L1_TCA-PAPI_L1_TCM)", "PAPI_L1_TCA", DeriveMetricOperation.DIVIDE)
 		extracted = deriveStat(extracted, "PAPI_L1_TCM", "PAPI_L2_TCM", DeriveMetricOperation.SUBTRACT)
 		extracted = deriveStat(extracted, "(PAPI_L1_TCM-PAPI_L2_TCM)", "PAPI_L1_TCM", DeriveMetricOperation.DIVIDE)
 		extracted = deriveStat(extracted, "PAPI_FP_INS", "P_WALL_CLOCK_TIME", DeriveMetricOperation.DIVIDE)
 		extracted = deriveStat(extracted, "PAPI_FP_INS", "PAPI_TOT_INS", DeriveMetricOperation.DIVIDE)
-		print "...done."
+		print("...done.")
 
 		# get the Statistics
-		print "getting stats..."
+		print("getting stats...")
 		dostats = BasicStatisticsOperation(extracted, False)
 		stats = dostats.processData()
-		print "...done."
+		print("...done.")
 
-		print "drawing charts..."
+		print("drawing charts...")
 		for metric in stats.get(0).getMetrics():
 			if metric == "((PAPI_L1_TCA-PAPI_L1_TCM)/PAPI_L1_TCA)" or metric == "((PAPI_L1_TCM-PAPI_L2_TCM)/PAPI_L1_TCM)":
 				grapher = DrawMMMGraph(stats)
@@ -160,7 +160,7 @@
 				grapher.setValueType(AbstractResult.INCLUSIVE)
 				# grapher.setLogYAxis(True)
 				grapher.processData()
-		print "...done."
+		print("...done.")
 
 	extracted = None
 	stats = None
@@ -168,7 +168,7 @@
 
 	return
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 loaded = load()
 extracted = first(loaded)
@@ -178,4 +178,4 @@
 loaded = None
 System.gc()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/jaguar.gtc.phases.chargei.py	(original)
--- b/tools/src/perfexplorer/etc/jaguar.gtc.phases.chargei.py	(refactored)
@@ -7,12 +7,12 @@
 False = 0
 
 def glue():
-	print "doing phase test for gtc on jaguar"
+	print("doing phase test for gtc on jaguar")
 
 	operations = Provenance.getCurrent().getOperations()
 	result1 = operations.get(0).getInputs().get(0)
 	for operation in operations:
-		print operation.getClass().getName()
+		print(operation.getClass().getName())
 		if operation.getClass().getName() == "glue.BasicStatisticsOperation":
 			stats = operation.getOutputs()
 
@@ -23,7 +23,7 @@
 	# subsetevents.add("PUSHI")
 	# subsetevents.add("SHIFTI")
 
-	print "got data..."
+	print("got data...")
 
 	for subsetevent in subsetevents:
 		events = ArrayList()
@@ -34,7 +34,7 @@
 		extractor = ExtractEventOperation(result1, events)
 		extracted = extractor.processData().get(0)
 
-		print "extracted phases..."
+		print("extracted phases...")
 
 		# derive metrics
 
@@ -69,13 +69,13 @@
 		merger.addInput(derived)
 		extracted = merger.processData().get(0)
 
-		print "derived metrics..."
+		print("derived metrics...")
 
 		# get the Statistics
 		dostats = BasicStatisticsOperation(extracted, False)
 		stats = dostats.processData()
 
-		print "got stats..."
+		print("got stats...")
 
 		for metric in stats.get(0).getMetrics():
 			if metric != "PAPI_L1_TCA-PAPI_L1_TCM" and metric != "PAPI_L1_TCM-PAPI_L2_TCM":
@@ -94,10 +94,10 @@
 
 	return
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 glue()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/jaguar.gtc.phases.first.py	(original)
--- b/tools/src/perfexplorer/etc/jaguar.gtc.phases.first.py	(refactored)
@@ -7,13 +7,13 @@
 False = 0
 
 def glue():
-	print "doing phase test for gtc on jaguar"
+	print("doing phase test for gtc on jaguar")
 	# load the trial
 	Utilities.setSession("perigtc")
 	trial1 = Utilities.getTrial("GTC", "Jaguar Compiler Options", "fastsse")
 	result1 = TrialResult(trial1)
 
-	print "got the data"
+	print("got the data")
 
 	# get the iteration inclusive totals
 
@@ -26,7 +26,7 @@
 	extractor = ExtractEventOperation(result1, events)
 	extracted = extractor.processData().get(0)
 
-	print "extracted phases"
+	print("extracted phases")
 
 	return
 
@@ -63,13 +63,13 @@
 	merger.addInput(derived)
 	extracted = merger.processData().get(0)
 
-	print "derived metrics..."
+	print("derived metrics...")
 
 	# get the Statistics
 	dostats = BasicStatisticsOperation(extracted, False)
 	stats = dostats.processData()
 
-	print "got stats..."
+	print("got stats...")
 
 	return
 
@@ -96,7 +96,7 @@
 	subsetevents.add("PUSHI")
 	subsetevents.add("SHIFTI")
 
-	print "got data..."
+	print("got data...")
 
 	for subsetevent in subsetevents:
 		events = ArrayList()
@@ -107,13 +107,13 @@
 		extractor = ExtractEventOperation(result1, events)
 		extracted = extractor.processData().get(0)
 
-		print "extracted phases..."
+		print("extracted phases...")
 
 		# get the Statistics
 		dostats = BasicStatisticsOperation(extracted, False)
 		stats = dostats.processData()
 
-		print "got stats..."
+		print("got stats...")
 
 		for metric in stats.get(0).getMetrics():
 			grapher = DrawMMMGraph(stats)
@@ -129,10 +129,10 @@
 
 	return
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 glue()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/jaguar.gtc.phases.long.py	(original)
--- b/tools/src/perfexplorer/etc/jaguar.gtc.phases.long.py	(refactored)
@@ -7,7 +7,7 @@
 False = 0
 
 def glue():
-	print "doing phase test for gtc on jaguar"
+	print("doing phase test for gtc on jaguar")
 	# load the trial
 	Utilities.setSession("perfdmf_test")
 	trial1 = Utilities.getTrial("gtc_bench", "jaguar.longrun.sampled.phases", "64")
@@ -24,13 +24,13 @@
 	extractor = ExtractEventOperation(result1, events)
 	extracted = extractor.processData().get(0)
 
-	print "extracted phases..."
+	print("extracted phases...")
 
 	# get the Statistics
 	dostats = BasicStatisticsOperation(extracted, False)
 	stats = dostats.processData()
 
-	print "got stats..."
+	print("got stats...")
 
 	for metric in stats.get(0).getMetrics():
 		grapher = DrawMMMGraph(stats)
@@ -53,7 +53,7 @@
 	subsetevents.add("PUSHI")
 	subsetevents.add("SHIFTI")
 
-	print "got data..."
+	print("got data...")
 
 	for subsetevent in subsetevents:
 		events = ArrayList()
@@ -64,13 +64,13 @@
 		extractor = ExtractEventOperation(result1, events)
 		extracted = extractor.processData().get(0)
 
-		print "extracted phases..."
+		print("extracted phases...")
 
 		# get the Statistics
 		dostats = BasicStatisticsOperation(extracted, False)
 		stats = dostats.processData()
 
-		print "got stats..."
+		print("got stats...")
 
 		for metric in stats.get(0).getMetrics():
 			grapher = DrawMMMGraph(stats)
@@ -86,10 +86,10 @@
 
 	return
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 glue()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/jaguar.gtc.phases.pushi.py	(original)
--- b/tools/src/perfexplorer/etc/jaguar.gtc.phases.pushi.py	(refactored)
@@ -7,12 +7,12 @@
 False = 0
 
 def glue():
-	print "doing phase test for gtc on jaguar"
+	print("doing phase test for gtc on jaguar")
 
 	operations = Provenance.getCurrent().getOperations()
 	result1 = operations.get(0).getInputs().get(0)
 	for operation in operations:
-		print operation.getClass().getName()
+		print(operation.getClass().getName())
 		if operation.getClass().getName() == "glue.BasicStatisticsOperation":
 			stats = operation.getOutputs()
 
@@ -23,7 +23,7 @@
 	subsetevents.add("PUSHI")
 	# subsetevents.add("SHIFTI")
 
-	print "got data..."
+	print("got data...")
 
 	for subsetevent in subsetevents:
 		events = ArrayList()
@@ -34,7 +34,7 @@
 		extractor = ExtractEventOperation(result1, events)
 		extracted = extractor.processData().get(0)
 
-		print "extracted phases..."
+		print("extracted phases...")
 
 		# derive metrics
 
@@ -69,13 +69,13 @@
 		merger.addInput(derived)
 		extracted = merger.processData().get(0)
 
-		print "derived metrics..."
+		print("derived metrics...")
 
 		# get the Statistics
 		dostats = BasicStatisticsOperation(extracted, False)
 		stats = dostats.processData()
 
-		print "got stats..."
+		print("got stats...")
 
 		for metric in stats.get(0).getMetrics():
 			if metric != "PAPI_L1_TCA-PAPI_L1_TCM" and metric != "PAPI_L1_TCM-PAPI_L2_TCM":
@@ -94,10 +94,10 @@
 
 	return
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 glue()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/jaguar.gtc.phases.py	(original)
--- b/tools/src/perfexplorer/etc/jaguar.gtc.phases.py	(refactored)
@@ -7,60 +7,60 @@
 False = 0
 
 def glue():
-	print "doing phase test for gtc on jaguar"
+	print("doing phase test for gtc on jaguar")
 	# load the trial
-	print "loading the data..."
+	print("loading the data...")
 	Utilities.setSession("perigtc")
 	trial1 = Utilities.getTrial("GTC", "Jaguar Compiler Options", "fastsse")
 	result1 = TrialResult(trial1)
 
 	# get the iteration inclusive totals
 
-	print "getting phases..."
+	print("getting phases...")
 	events = ArrayList()
 	for event in result1.getEvents():
 		#if event.find("Iteration") >= 0 and result1.getEventGroupName(event).find("TAU_PHASE") < 0:
 		if event.find("Iteration") >= 0 and event.find("=>") < 0:
 			events.add(event)
 
-	print "extracting phases..."
+	print("extracting phases...")
 	extractor = ExtractEventOperation(result1, events)
 	extracted = extractor.processData().get(0)
 
 	# derive metrics
 
-	print "deriving metrics (1)..."
+	print("deriving metrics (1)...")
 	derivor = DeriveMetricOperation(extracted, "PAPI_L1_TCA", "PAPI_L1_TCM", DeriveMetricOperation.SUBTRACT)
 	derived = derivor.processData().get(0)
 	merger = MergeTrialsOperation(extracted)
 	merger.addInput(derived)
 	extracted = merger.processData().get(0)
-	print "deriving metrics (2)..."
+	print("deriving metrics (2)...")
 	derivor = DeriveMetricOperation(extracted, "(PAPI_L1_TCA-PAPI_L1_TCM)", "PAPI_L1_TCA", DeriveMetricOperation.DIVIDE)
 	derived = derivor.processData().get(0)
 	merger = MergeTrialsOperation(extracted)
 	merger.addInput(derived)
 	extracted = merger.processData().get(0)
-	print "deriving metrics (3)..."
+	print("deriving metrics (3)...")
 	derivor = DeriveMetricOperation(extracted, "PAPI_L1_TCM", "PAPI_L2_TCM", DeriveMetricOperation.SUBTRACT)
 	derived = derivor.processData().get(0)
 	merger = MergeTrialsOperation(extracted)
 	merger.addInput(derived)
 	extracted = merger.processData().get(0)
-	print "deriving metrics (4)..."
+	print("deriving metrics (4)...")
 	derivor = DeriveMetricOperation(extracted, "(PAPI_L1_TCM-PAPI_L2_TCM)", "PAPI_L1_TCM", DeriveMetricOperation.DIVIDE)
 	derived = derivor.processData().get(0)
 	merger = MergeTrialsOperation(extracted)
 	merger.addInput(derived)
 	extracted = merger.processData().get(0)
 
-	print "doing stats..."
+	print("doing stats...")
 
 	# get the Statistics
 	dostats = BasicStatisticsOperation(extracted, False)
 	stats = dostats.processData()
 
-	print "drawing..."
+	print("drawing...")
 
 	for metric in stats.get(0).getMetrics():
 		grapher = DrawMMMGraph(stats)
@@ -85,7 +85,7 @@
 	subsetevents.add("PUSHI")
 	subsetevents.add("SHIFTI")
 
-	print "got data..."
+	print("got data...")
 
 	for subsetevent in subsetevents:
 		events = ArrayList()
@@ -96,13 +96,13 @@
 		extractor = ExtractEventOperation(result1, events)
 		extracted = extractor.processData().get(0)
 
-		print "extracted phases..."
+		print("extracted phases...")
 
 		# get the Statistics
 		dostats = BasicStatisticsOperation(extracted, False)
 		stats = dostats.processData()
 
-		print "got stats..."
+		print("got stats...")
 
 		for metric in stats.get(0).getMetrics():
 			grapher = DrawMMMGraph(stats)
@@ -119,10 +119,10 @@
 
 	return
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 glue()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/jaguar.gtc.phases.shifti.py	(original)
--- b/tools/src/perfexplorer/etc/jaguar.gtc.phases.shifti.py	(refactored)
@@ -7,12 +7,12 @@
 False = 0
 
 def glue():
-	print "doing phase test for gtc on jaguar"
+	print("doing phase test for gtc on jaguar")
 
 	operations = Provenance.getCurrent().getOperations()
 	result1 = operations.get(0).getInputs().get(0)
 	for operation in operations:
-		print operation.getClass().getName()
+		print(operation.getClass().getName())
 		if operation.getClass().getName() == "glue.BasicStatisticsOperation":
 			stats = operation.getOutputs()
 
@@ -23,7 +23,7 @@
 	# subsetevents.add("PUSHI")
 	subsetevents.add("SHIFTI")
 
-	print "got data..."
+	print("got data...")
 
 	for subsetevent in subsetevents:
 		events = ArrayList()
@@ -34,7 +34,7 @@
 		extractor = ExtractEventOperation(result1, events)
 		extracted = extractor.processData().get(0)
 
-		print "extracted phases..."
+		print("extracted phases...")
 
 		# derive metrics
 
@@ -59,13 +59,13 @@
 		merger.addInput(derived)
 		extracted = merger.processData().get(0)
 
-		print "derived metrics..."
+		print("derived metrics...")
 
 		# get the Statistics
 		dostats = BasicStatisticsOperation(extracted, False)
 		stats = dostats.processData()
 
-		print "got stats..."
+		print("got stats...")
 
 		for metric in stats.get(0).getMetrics():
 			if metric != "PAPI_L1_TCA-PAPI_L1_TCM" and metric != "PAPI_L1_TCM-PAPI_L2_TCM":
@@ -82,10 +82,10 @@
 
 	return
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 glue()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/jaguar.gtc.phases.spaceghost.first.py	(original)
--- b/tools/src/perfexplorer/etc/jaguar.gtc.phases.spaceghost.first.py	(refactored)
@@ -7,13 +7,13 @@
 False = 0
 
 def glue():
-	print "doing phase test for gtc on jaguar"
+	print("doing phase test for gtc on jaguar")
 	# load the trial
 	Utilities.setSession("perfdmf.demo")
 	trial1 = Utilities.getTrial("gtc_bench", "Jaguar Compiler Options", "fastsse")
 	result1 = TrialResult(trial1)
 
-	print "got the data"
+	print("got the data")
 
 	# get the iteration inclusive totals
 
@@ -26,7 +26,7 @@
 	extractor = ExtractEventOperation(result1, events)
 	extracted = extractor.processData().get(0)
 
-	print "extracted phases"
+	print("extracted phases")
 
 	# derive metrics
 
@@ -51,7 +51,7 @@
 	merger.addInput(derived)
 	extracted = merger.processData().get(0)
 
-	print "derived metrics..."
+	print("derived metrics...")
 
 	return
 
@@ -59,7 +59,7 @@
 	dostats = BasicStatisticsOperation(extracted, False)
 	stats = dostats.processData()
 
-	print "got stats..."
+	print("got stats...")
 
 	"""for metric in stats.get(0).getMetrics():
 		grapher = DrawMMMGraph(stats)
@@ -84,7 +84,7 @@
 	subsetevents.add("PUSHI")
 	subsetevents.add("SHIFTI")
 
-	print "got data..."
+	print("got data...")
 
 	for subsetevent in subsetevents:
 		events = ArrayList()
@@ -95,13 +95,13 @@
 		extractor = ExtractEventOperation(result1, events)
 		extracted = extractor.processData().get(0)
 
-		print "extracted phases..."
+		print("extracted phases...")
 
 		# get the Statistics
 		dostats = BasicStatisticsOperation(extracted, False)
 		stats = dostats.processData()
 
-		print "got stats..."
+		print("got stats...")
 
 		for metric in stats.get(0).getMetrics():
 			grapher = DrawMMMGraph(stats)
@@ -117,10 +117,10 @@
 
 	return
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 glue()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/jaguar.gtc.phases.third.py	(original)
--- b/tools/src/perfexplorer/etc/jaguar.gtc.phases.third.py	(refactored)
@@ -7,12 +7,12 @@
 False = 0
 
 def glue():
-	print "doing phase test for gtc on jaguar"
+	print("doing phase test for gtc on jaguar")
 
 	operations = Provenance.getCurrent().getOperations()
 	result1 = operations.get(0).getInputs().get(0)
 	for operation in operations:
-		print operation.getClass().getName()
+		print(operation.getClass().getName())
 		if operation.getClass().getName() == "glue.BasicStatisticsOperation":
 			stats = operation.getOutputs()
 
@@ -23,7 +23,7 @@
 	subsetevents.add("PUSHI")
 	subsetevents.add("SHIFTI")
 
-	print "got data..."
+	print("got data...")
 
 	for subsetevent in subsetevents:
 		events = ArrayList()
@@ -34,7 +34,7 @@
 		extractor = ExtractEventOperation(result1, events)
 		extracted = extractor.processData().get(0)
 
-		print "extracted phases..."
+		print("extracted phases...")
 
 		# derive metrics
 
@@ -59,13 +59,13 @@
 		merger.addInput(derived)
 		extracted = merger.processData().get(0)
 
-		print "derived metrics..."
+		print("derived metrics...")
 
 		# get the Statistics
 		dostats = BasicStatisticsOperation(extracted, False)
 		stats = dostats.processData()
 
-		print "got stats..."
+		print("got stats...")
 
 		for metric in stats.get(0).getMetrics():
 			grapher = DrawMMMGraph(stats)
@@ -81,10 +81,10 @@
 
 	return
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 glue()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/longrun.py	(original)
--- b/tools/src/perfexplorer/etc/longrun.py	(refactored)
@@ -7,7 +7,7 @@
 True = 1
 
 def glue():
-	print "doing long run test"
+	print("doing long run test")
 	# load the trial
 	Utilities.setSession("perfdmf_test")
 	trial1 = Utilities.getTrial("gtc_bench", "jaguar.longrun", "64.first")
@@ -32,7 +32,7 @@
 		for metric in reduced.getMetrics():
 			for thread in reduced.getThreads():
 				if event.find("measurement") >= 0:
-					print metric, thread, reduced.getInclusive(thread, event, metric)
+					print(metric, thread, reduced.getInclusive(thread, event, metric))
 
 	# do the correlation
 	correlation = CorrelationOperation(reduced)
@@ -65,10 +65,10 @@
 		grapher.processData()
 
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 glue()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/lu-interactive.py	(original)
--- b/tools/src/perfexplorer/etc/lu-interactive.py	(refactored)
@@ -48,7 +48,7 @@
 	returnEvents = {}
 	events = pe.getEventList(trial, metricIndex)
 	while events.hasNext():
-		event = events.next()
+		event = next(events)
 		if (groupName == "") or \
 		(contains == True and event.getGroup().find(groupName) > -1) or \
 		(contains == False and event.getGroup().find(groupName) < 0):
@@ -58,7 +58,7 @@
 def findMain(events, metric):
 	inclusive = 0.0
 	main = {}
-	for key in events.keys():
+	for key in list(events.keys()):
 		data = events[key]
 		if data.getInclusive(metric) > inclusive:
 			inclusive = data.getInclusive(metric)
@@ -84,7 +84,7 @@
 
 def sort_by_value(d):
     """ Returns the keys of dictionary d sorted by their values """
-    items=d.items()
+    items=list(d.items())
     backitems=[ [v[1],v[0]] for v in items]
     backitems.sort()
     return [ backitems[i][1] for i in range(0,len(backitems))]
@@ -92,7 +92,7 @@
 def pairwiseEvent(baseEvents, otherEvents, i, j, filter):
 	faster = {}
 	slower = {}
-	for event in baseEvents.keys():
+	for event in list(baseEvents.keys()):
 		# print event
 		baseValues = baseEvents[event]
 		otherValues = otherEvents[event]
@@ -110,7 +110,7 @@
 def pairwiseEventDerived(baseEvents, otherEvents, i, j, m, n, filter):
 	faster = {}
 	slower = {}
-	for event in baseEvents.keys():
+	for event in list(baseEvents.keys()):
 		if filter[event] == 1:
 			baseValues = baseEvents[event]
 			otherValues = otherEvents[event]
@@ -133,28 +133,28 @@
 def mainReport(baseMain, otherMain, baseName, otherName):
 	if baseMain["inclusive"] > otherMain["inclusive"]:
 		tmp = "\nSelected trial (" + otherName + ") is relatively faster than baseline trial (" + baseName + ").\n"
-		print tmp
+		print(tmp)
 		percentage = (baseMain["inclusive"] - otherMain["inclusive"]) / otherMain["inclusive"]
 		fasterSlower = -1
 	elif baseMain["inclusive"] < otherMain["inclusive"]:
 		tmp = "\nSelected trial (" + otherName + ") is relatively slower than baseline trial (" + baseName + ").\n"
-		print tmp
+		print(tmp)
 		percentage = (otherMain["inclusive"] - baseMain["inclusive"]) / baseMain["inclusive"]
 		fasterSlower = 1
 	else:
-		print "\nBaseline trial and second trial have the same execution time."
+		print("\nBaseline trial and second trial have the same execution time.")
 		fasterSlower = 0
 		percentage = 0.0
 	# print "\t", baseName, baseMain["name"], ":", baseMain["inclusive"], "seconds\n", 
 	# print "\t", otherName, otherMain["name"], ":", otherMain["inclusive"], "seconds\n", 
-	print "\t", baseName, ":", baseMain["inclusive"]/million, "seconds\n", 
-	print "\t", otherName, ":", otherMain["inclusive"]/million, "seconds\n", 
+	print("\t", baseName, ":", baseMain["inclusive"]/million, "seconds\n", end=' ') 
+	print("\t", otherName, ":", otherMain["inclusive"]/million, "seconds\n", end=' ') 
 	if fasterSlower > 0:
-		print "\t Relative Difference: ", percentage*100, "% slower\n"
+		print("\t Relative Difference: ", percentage*100, "% slower\n")
 	elif fasterSlower < 0:
-		print "\t Relative Difference: ", percentage*100, "% faster\n"
-	else:
-		print "\t Relative Difference: ", percentage*100, "%\n"
+		print("\t Relative Difference: ", percentage*100, "% faster\n")
+	else:
+		print("\t Relative Difference: ", percentage*100, "%\n")
 	return fasterSlower
 
 def showSignificantTimeEvents(diffs, type, totalRuntime, significant, baseEvents, x):
@@ -171,7 +171,7 @@
 					percent = ( events[key]/baseEvents[key].getExclusive(x) ) * 100.0
 				else:
 					percent = 0.0
-				print "\t", key, ":", events[key]/million, "seconds", type.upper(), "than baseline (", percent, "% )"
+				print("\t", key, ":", events[key]/million, "seconds", type.upper(), "than baseline (", percent, "% )")
 
 				significant[key] = 1
 				shown += 1
@@ -199,7 +199,7 @@
 				percent = ( events[key]/baseEvents[key].getExclusive(x) ) * 100.0
 			else:
 				percent = 0.0
-			print "\t", key, ":", events[key]/million, "million", type, "than baseline (", percent, "% )"
+			print("\t", key, ":", events[key]/million, "million", type, "than baseline (", percent, "% )")
 			shown += 1
 	return shown
 
@@ -222,7 +222,7 @@
 				percent = ( events[key]/(baseGFLOP/baseSeconds) ) * 100.0
 			else:
 				percent = 0.0
-			print "\t", key, ":", events[key], type, "than baseline (", percent, "% )"
+			print("\t", key, ":", events[key], type, "than baseline (", percent, "% )")
 			shown += 1
 	return shown
 
@@ -274,7 +274,7 @@
 	if baseMain["name"] == otherMain["name"]:
 		fasterSlower = mainReport(baseMain, otherMain, baseTrial.getName(), otherTrial.getName())
 	else:
-		print "Main events do not match: ", baseMain["name"], ", ", otherMain["name"]
+		print("Main events do not match: ", baseMain["name"], ", ", otherMain["name"])
 		return
 
 	# compare the events for metric i
@@ -282,13 +282,13 @@
 
 	# tell the user the significant differences
 	significant = {}
-	print "Significant", baseMetrics[baseTime], "differences between trials:\n"
+	print("Significant", baseMetrics[baseTime], "differences between trials:\n")
 	shown = showSignificantTimeEvents(diffs, "faster", baseMain["inclusive"], significant, baseEvents, baseTime)
 	if shown > 0:
-		print ""
+		print("")
 	shown += showSignificantTimeEvents(diffs, "slower", baseMain["inclusive"], significant, baseEvents, baseTime)
 	if shown == 0:
-		print "\t None.\n"
+		print("\t None.\n")
 
 	# significant is now populated with the names of events that are significant.
 	# iterate through the metrics to locate possible causes for the time difference.
@@ -302,32 +302,32 @@
 				pass
 			else:
 				diffs = pairwiseEvent(baseEvents, otherEvents, x, y, significant)
-				print "\nSignificant", baseMetrics[x], "differences between trials:\n"
+				print("\nSignificant", baseMetrics[x], "differences between trials:\n")
 				shown = showSignificantEvents(diffs, "faster", significant, baseEvents, x)
 				if shown > 0:
-					print ""
+					print("")
 				shown += showSignificantEvents(diffs, "slower", significant, baseEvents, x)
 				if shown == 0:
-					print "\t None.\n"
+					print("\t None.\n")
 				if x == baseFlops:
 				# also do GFLOP/Second per processor
 					diffs = pairwiseEventDerived(baseEvents, otherEvents, x, y, baseTime, otherTime, significant)
-					print "\nSignificant GFLOP/sec per processor differences between trials:\n"
+					print("\nSignificant GFLOP/sec per processor differences between trials:\n")
 					shown = showSignificantEventsDerived(diffs, "faster", significant, baseEvents, x, baseTime)
 					if shown > 0:
-						print ""
+						print("")
 					shown += showSignificantEventsDerived(diffs, "slower", significant, baseEvents, x, baseTime)
 					if shown == 0:
-						print "\t None.\n"
+						print("\t None.\n")
 		x += 1
 	
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 pe = ScriptFacade()
 DoAnalysis(pe)
 
-print "\n"
-print "---------------- JPython test script end -------------"
+print("\n")
+print("---------------- JPython test script end -------------")
 
 # pe.exit()
 
--- a/tools/src/perfexplorer/etc/lu.py	(original)
--- b/tools/src/perfexplorer/etc/lu.py	(refactored)
@@ -44,7 +44,7 @@
 	returnEvents = {}
 	events = pe.getEventList(trial, metricIndex)
 	while events.hasNext():
-		event = events.next()
+		event = next(events)
 		# print event.getName()
 		returnEvents[event.getName()] = event.getMeanSummary()
 	return returnEvents
@@ -52,7 +52,7 @@
 def findMain(events, metric):
 	inclusive = 0.0
 	main = {}
-	for key in events.keys():
+	for key in list(events.keys()):
 		data = events[key]
 		if data.getInclusive(metric) > inclusive:
 			inclusive = data.getInclusive(metric)
@@ -78,7 +78,7 @@
 
 def sort_by_value(d):
     """ Returns the keys of dictionary d sorted by their values """
-    items=d.items()
+    items=list(d.items())
     backitems=[ [v[1],v[0]] for v in items]
     backitems.sort()
     return [ backitems[i][1] for i in range(0,len(backitems))]
@@ -86,7 +86,7 @@
 def pairwiseEvent(baseEvents, otherEvents, i, j, filter):
 	faster = {}
 	slower = {}
-	for event in baseEvents.keys():
+	for event in list(baseEvents.keys()):
 		# print event
 		baseValues = baseEvents[event]
 		otherValues = otherEvents[event]
@@ -109,28 +109,28 @@
 def mainReport(baseMain, otherMain, baseName, otherName):
 	if baseMain["inclusive"] > otherMain["inclusive"]:
 		tmp = "\nSelected trial (" + otherName + ") is relatively faster than baseline trial (" + baseName + ").\n"
-		print tmp
+		print(tmp)
 		percentage = (baseMain["inclusive"] - otherMain["inclusive"]) / otherMain["inclusive"]
 		fasterSlower = -1
 	elif baseMain["inclusive"] < otherMain["inclusive"]:
 		tmp = "\nSelected trial (" + otherName + ") is relatively slower than baseline trial (" + baseName + ").\n"
-		print tmp
+		print(tmp)
 		percentage = (otherMain["inclusive"] - baseMain["inclusive"]) / baseMain["inclusive"]
 		fasterSlower = 1
 	else:
-		print "\nBaseline trial and second trial have the same execution time."
+		print("\nBaseline trial and second trial have the same execution time.")
 		fasterSlower = 0
 		percentage = 0.0
 	# print "\t", baseName, baseMain["name"], ":", baseMain["inclusive"], "seconds\n", 
 	# print "\t", otherName, otherMain["name"], ":", otherMain["inclusive"], "seconds\n", 
-	print "\t", baseName, ":", baseMain["inclusive"]/million, "seconds\n", 
-	print "\t", otherName, ":", otherMain["inclusive"]/million, "seconds\n", 
+	print("\t", baseName, ":", baseMain["inclusive"]/million, "seconds\n", end=' ') 
+	print("\t", otherName, ":", otherMain["inclusive"]/million, "seconds\n", end=' ') 
 	if fasterSlower > 0:
-		print "\t Relative Difference: ", percentage*100, "% slower\n"
+		print("\t Relative Difference: ", percentage*100, "% slower\n")
 	elif fasterSlower < 0:
-		print "\t Relative Difference: ", percentage*100, "% faster\n"
-	else:
-		print "\t Relative Difference: ", percentage*100, "%\n"
+		print("\t Relative Difference: ", percentage*100, "% faster\n")
+	else:
+		print("\t Relative Difference: ", percentage*100, "%\n")
 	return fasterSlower
 
 def showSignificantTimeEvents(diffs, type, totalRuntime, significant, baseEvents, x):
@@ -147,7 +147,7 @@
 					percent = ( events[key]/baseEvents[key].getExclusive(x) ) * 100.0
 				else:
 					percent = 0.0
-				print "\t", key, ":", events[key]/million, "seconds", type.upper(), "than baseline (", percent, "% )"
+				print("\t", key, ":", events[key]/million, "seconds", type.upper(), "than baseline (", percent, "% )")
 
 				significant[key] = 1
 				shown += 1
@@ -175,7 +175,7 @@
 				percent = ( events[key]/baseEvents[key].getExclusive(x) ) * 100.0
 			else:
 				percent = 0.0
-			print "\t", key, ":", events[key]/million, "million", type, "than baseline (", percent, "% )"
+			print("\t", key, ":", events[key]/million, "million", type, "than baseline (", percent, "% )")
 			shown += 1
 	return shown
 
@@ -197,7 +197,7 @@
 	baseEvents = getEvents(pe, baseTrial, baseTime)
 	
 	# find the main event
-	print baseTime
+	print(baseTime)
 	baseMain = findMain(baseEvents, baseTime)
 	# print baseMain
 	
@@ -211,7 +211,7 @@
 	# find the time metric
 	metricMap = mapMetrics(baseMetrics, otherMetrics)
 	otherTime = metricMap[baseTime]
-	print otherTime
+	print(otherTime)
 
 	# get all the data for each event
 	otherEvents = getEvents(pe, otherTrial, otherTime)
@@ -224,7 +224,7 @@
 	if baseMain["name"] == otherMain["name"]:
 		fasterSlower = mainReport(baseMain, otherMain, baseTrial.getName(), otherTrial.getName())
 	else:
-		print "Main events do not match: ", baseMain["name"], ", ", otherMain["name"]
+		print("Main events do not match: ", baseMain["name"], ", ", otherMain["name"])
 		return
 
 	# compare the events for metric i
@@ -232,13 +232,13 @@
 
 	# tell the user the significant differences
 	significant = {}
-	print "Significant", baseMetrics[baseTime], "differences between trials:\n"
+	print("Significant", baseMetrics[baseTime], "differences between trials:\n")
 	shown = showSignificantTimeEvents(diffs, "faster", baseMain["inclusive"], significant, baseEvents, baseTime)
 	if shown > 0:
-		print ""
+		print("")
 	shown += showSignificantTimeEvents(diffs, "slower", baseMain["inclusive"], significant, baseEvents, baseTime)
 	if shown == 0:
-		print "\t None.\n"
+		print("\t None.\n")
 
 	# significant is now populated with the names of events that are significant.
 	# iterate through the metrics to locate possible causes for the time difference.
@@ -252,22 +252,22 @@
 				pass
 			else:
 				diffs = pairwiseEvent(baseEvents, otherEvents, x, y, significant)
-				print "\nSignificant", baseMetrics[x], "differences between trials:\n"
+				print("\nSignificant", baseMetrics[x], "differences between trials:\n")
 				shown = showSignificantEvents(diffs, "faster", significant, baseEvents, x)
 				if shown > 0:
-					print ""
+					print("")
 				shown += showSignificantEvents(diffs, "slower", significant, baseEvents, x)
 				if shown == 0:
-					print "\t None.\n"
+					print("\t None.\n")
 		x += 1
 	
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 pe = ScriptFacade()
 DoAnalysis(pe)
 
-print "\n"
-print "---------------- JPython test script end -------------"
+print("\n")
+print("---------------- JPython test script end -------------")
 
 # pe.exit()
 
--- a/tools/src/perfexplorer/etc/milc.py	(original)
--- b/tools/src/perfexplorer/etc/milc.py	(refactored)
@@ -97,7 +97,7 @@
 	pe.doGeneralChart()
 
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 pe = ScriptFacade()
 TotalExecutionTime(pe)
@@ -111,4 +111,4 @@
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/mm2.py	(original)
--- b/tools/src/perfexplorer/etc/mm2.py	(refactored)
@@ -26,7 +26,7 @@
 	pe.setChartEventNoCallPath(1)
 	pe.doGeneralChart()
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 pe = ScriptFacade()
 TotalExecutionTime(pe)
@@ -34,4 +34,4 @@
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/optimization.py	(original)
--- b/tools/src/perfexplorer/etc/optimization.py	(refactored)
@@ -12,38 +12,38 @@
 inTrial = ""
 
 def load():
-	print "loading data..."
+	print("loading data...")
 	parameterMap = PerfExplorerModel.getModel().getScriptParameters()
 	keys = parameterMap.keySet()
 	for key in keys:
-		print key, parameterMap.get(key)
+		print(key, parameterMap.get(key))
 	config = parameterMap.get("config")
 	inApp = parameterMap.get("app")
 	inExp = parameterMap.get("exp")
 	Utilities.setSession(config)
 	trials = Utilities.getTrialsForExperiment(inApp, inExp)
-	print "...done."
+	print("...done.")
 	return trials
 
 def extractMain(inputs):
 	events = ArrayList()
 	events.add(inputs.get(0).getMainEvent())
 
-	print "extracting main event..."
+	print("extracting main event...")
 	extractor = ExtractEventOperation(inputs, events)
 	extracted = extractor.processData()
-	print "...done."
+	print("...done.")
 
 	return extracted
 
 def getTop3(inputs):
-	print "extracting top 3 events..."
+	print("extracting top 3 events...")
 	reducer = TopXEvents(inputs, "Time", AbstractResult.EXCLUSIVE, 3)
 	reduced = reducer.processData()
 	return reduced
 
 def drawGraph(results, inclusive):
-	print "drawing charts..."
+	print("drawing charts...")
 	for metric in results.get(0).getMetrics():
 		grapher = DrawGraph(results)
 		metrics = HashSet()
@@ -65,11 +65,11 @@
 			grapher.setYAxisLabel("Exclusive " + metric + " (seconds)")
 
 		grapher.processData()
-	print "...done."
+	print("...done.")
 
 	return
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 trials = load()
 results = ArrayList()
@@ -82,4 +82,4 @@
 extracted = getTop3(results)
 drawGraph(extracted, False)
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/params.py	(original)
--- b/tools/src/perfexplorer/etc/params.py	(refactored)
@@ -11,38 +11,38 @@
 inTrial = "lu.A.4"
 
 def load():
-	print "loading data..."
+	print("loading data...")
 	Utilities.setSession(config)
 	trial1 = Utilities.getTrial(inApp, inExp, inTrial)
 	result = TrialResult(trial1)
-	print "...done."
+	print("...done.")
 	return result
 
 def first(input):
 	# get the iteration inclusive totals
 
-	print "searching for iteration events (no classpath)..."
+	print("searching for iteration events (no classpath)...")
 	events = ArrayList()
 	for event in input.getEvents():
 		#if event.find("Iteration") >= 0 and input.getEventGroupName(event).find("TAU_PHASE") < 0:
 		if event.find("MPI_Send") >= 0 and event.find("message size") >= 0:
 			events.add(event)
-	print "...done."
+	print("...done.")
 
-	print "extracting phases..."
+	print("extracting phases...")
 	extractor = ExtractEventOperation(input, events)
 	extracted = extractor.processData().get(0)
-	print "...done."
+	print("...done.")
 
 	return extracted
 
 def second(extracted):
-	print "getting stats..."
+	print("getting stats...")
 	dostats = BasicStatisticsOperation(extracted, False)
 	stats = dostats.processData()
-	print "...done."
+	print("...done.")
 
-	print "drawing charts..."
+	print("drawing charts...")
 	for metric in stats.get(0).getMetrics():
 		grapher = DrawMMMGraph(stats)
 		metrics = HashSet()
@@ -59,14 +59,14 @@
 		grapher.setYAxisLabel("Exclusive " + metric);
 		# grapher.setLogYAxis(True)
 		grapher.processData()
-	print "...done."
+	print("...done.")
 
 	return
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 loaded = load()
 extracted = first(loaded)
 second(extracted)
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/phases.py	(original)
--- b/tools/src/perfexplorer/etc/phases.py	(refactored)
@@ -11,37 +11,37 @@
 inTrial = "lu.A.4"
 
 def load():
-	print "loading data..."
+	print("loading data...")
 	Utilities.setSession(config)
 	trial1 = Utilities.getTrial(inApp, inExp, inTrial)
 	result = TrialResult(trial1)
-	print "...done."
+	print("...done.")
 	return result
 
 def first(input):
 	# get the iteration inclusive totals
 
-	print "searching for iteration events (no classpath)..."
+	print("searching for iteration events (no classpath)...")
 	events = ArrayList()
 	for event in input.getEvents():
 		if event.find("Iteration") >= 0 and event.find("=>") < 0 and event.find("**") < 0:
 			events.add(event)
-	print "...done."
+	print("...done.")
 
-	print "extracting phases..."
+	print("extracting phases...")
 	extractor = ExtractEventOperation(input, events)
 	extracted = extractor.processData().get(0)
-	print "...done."
+	print("...done.")
 
 	return extracted
 
 def second(extracted):
-	print "getting stats..."
+	print("getting stats...")
 	dostats = BasicStatisticsOperation(extracted, False)
 	stats = dostats.processData()
-	print "...done."
+	print("...done.")
 
-	print "drawing charts..."
+	print("drawing charts...")
 	for metric in stats.get(0).getMetrics():
 		grapher = DrawMMMGraph(stats)
 		metrics = HashSet()
@@ -58,14 +58,14 @@
 		grapher.setYAxisLabel("Inclusive " + metric);
 		# grapher.setLogYAxis(True)
 		grapher.processData()
-	print "...done."
+	print("...done.")
 
 	return
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 loaded = load()
 extracted = first(loaded)
 second(extracted)
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/pptest.py	(original)
--- b/tools/src/perfexplorer/etc/pptest.py	(refactored)
@@ -2,7 +2,7 @@
 from edu.uoregon.tau.perfexplorer.common import TransformationType
 from edu.uoregon.tau.perfexplorer.common import AnalysisType
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 pe = ScriptFacade("/Users/khuck/.ParaProf/perfdmf.cfg")
 pe.doSomething()
@@ -41,4 +41,4 @@
 
 pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/regressionTest.py	(original)
--- b/tools/src/perfexplorer/etc/regressionTest.py	(refactored)
@@ -21,32 +21,32 @@
 inTrial = ""
 
 def load():
-	print "loading data..."
+	print("loading data...")
 	parameterMap = PerfExplorerModel.getModel().getScriptParameters()
 	keys = parameterMap.keySet()
 	for key in keys:
-		print key, parameterMap.get(key)
+		print(key, parameterMap.get(key))
 	config = parameterMap.get("config")
 # 	inApp = parameterMap.get("app")
 # 	inExp = parameterMap.get("exp")
 	Utilities.setSession(config)
 	trials = Utilities.getTrialsForExperiment(inApp, inExp)
-	print "...done."
+	print("...done.")
 	return trials
 
 def extractMain(inputs):
 	events = ArrayList()
 	events.add(inputs.get(0).getMainEvent())
 
-	print "extracting main event..."
+	print("extracting main event...")
 	extractor = ExtractEventOperation(inputs, events)
 	extracted = extractor.processData()
-	print "...done."
+	print("...done.")
 
 	return extracted
 
 def getTop1(inputs):
-	print "extracting top events..."
+	print("extracting top events...")
 	reducer = TopXEvents(inputs, "Time", AbstractResult.EXCLUSIVE, 5)
 #	reducer = TopXPercentEvents(inputs, "Time", AbstractResult.EXCLUSIVE, 5.0)
 	reduced = reducer.processData()
@@ -54,7 +54,7 @@
 	return reduced
 
 def drawGraph(results, inclusive):
-	print "drawing charts..."
+	print("drawing charts...")
 	for metric in results.get(0).getMetrics():
 		grapher = DrawGraph(results)
 		metrics = HashSet()
@@ -79,11 +79,11 @@
 			grapher.drawChartToFile(outFile1)
 		else:
 			grapher.drawChartToFile(outFile2)
-	print "...done."
+	print("...done.")
 
 	return
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 trials = load()
 results = ArrayList()
@@ -99,6 +99,6 @@
 pe.exit()
 
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
 pe = ScriptFacade()
 pe.exit()
--- a/tools/src/perfexplorer/etc/rules.py	(original)
--- b/tools/src/perfexplorer/etc/rules.py	(refactored)
@@ -60,11 +60,11 @@
 	pe.runComparisonRules(baseline, comparison)
 
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 pe = ScriptFacade()
 gyro(pe)
 
 pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/scalability.py	(original)
--- b/tools/src/perfexplorer/etc/scalability.py	(refactored)
@@ -12,38 +12,38 @@
 inTrial = ""
 
 def load():
-	print "loading data..."
+	print("loading data...")
 	parameterMap = PerfExplorerModel.getModel().getScriptParameters()
 	keys = parameterMap.keySet()
 	for key in keys:
-		print key, parameterMap.get(key)
+		print(key, parameterMap.get(key))
 	config = parameterMap.get("config")
 	inApp = parameterMap.get("app")
 	inExp = parameterMap.get("exp")
 	Utilities.setSession(config)
 	trials = Utilities.getTrialsForExperiment(inApp, inExp)
-	print "...done."
+	print("...done.")
 	return trials
 
 def extractMain(inputs):
 	events = ArrayList()
 	events.add(inputs.get(0).getMainEvent())
 
-	print "extracting main event..."
+	print("extracting main event...")
 	extractor = ExtractEventOperation(inputs, events)
 	extracted = extractor.processData()
-	print "...done."
+	print("...done.")
 
 	return extracted
 
 def getTop8(inputs):
-	print "extracting top 8 events..."
+	print("extracting top 8 events...")
 	reducer = TopXEvents(inputs, "Time", AbstractResult.EXCLUSIVE, 8)
 	reduced = reducer.processData()
 	return reduced
 
 def drawGraph(results, inclusive):
-	print "drawing charts..."
+	print("drawing charts...")
 	for metric in results.get(0).getMetrics():
 		grapher = DrawGraph(results)
 		metrics = HashSet()
@@ -63,11 +63,11 @@
 			grapher.setValueType(AbstractResult.EXCLUSIVE)
 			grapher.setYAxisLabel("Exclusive " + metric + " (seconds)")
 		grapher.processData()
-	print "...done."
+	print("...done.")
 
 	return
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 trials = load()
 results = ArrayList()
@@ -80,4 +80,4 @@
 extracted = getTop8(results)
 drawGraph(extracted, False)
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/selecttrialtest.py	(original)
--- b/tools/src/perfexplorer/etc/selecttrialtest.py	(refactored)
@@ -2,7 +2,7 @@
 from edu.uoregon.tau.perfexplorer.common import TransformationType
 from edu.uoregon.tau.perfexplorer.common import AnalysisType
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 pe = ScriptFacade("/home/khuck/.ParaProf/perfdmf.cfg")
 pe.doSomething()
@@ -11,8 +11,8 @@
 criteria = "trial.node_count > 32 and experiment.id = 80"
 trials = pe.getTrialList(criteria)
 for t in trials:
-	print t.getName()," ",t.getExperimentID()
+	print(t.getName()," ",t.getExperimentID())
 
 pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/etc/simple.py	(original)
--- b/tools/src/perfexplorer/etc/simple.py	(refactored)
@@ -18,7 +18,7 @@
 	returnEvents = {}
 	events = pe.getEventList(trial, metricIndex)
 	while events.hasNext():
-		event = events.next()
+		event = next(events)
 		# print event.getName()
 		returnEvents[event.getName()] = event.getMeanSummary()
 	return returnEvents
@@ -26,7 +26,7 @@
 def findMain(events, metric):
 	inclusive = 0.0
 	main = {}
-	for key in events.keys():
+	for key in list(events.keys()):
 		data = events[key]
 		if data.getInclusive() > inclusive:
 			inclusive = data.getInclusive()
@@ -53,7 +53,7 @@
 def pairwiseEvent(baseEvents, otherEvents, i, j, filter):
 	faster = {}
 	slower = {}
-	for event in baseEvents.keys():
+	for event in list(baseEvents.keys()):
 		# print event
 		baseValues = baseEvents[event]
 		otherValues = otherEvents[event]
@@ -64,37 +64,37 @@
 		else:
 			slower[event] = abs(diff)
 	results = {}
-	items = faster.items()
+	items = list(faster.items())
 	items.sort()
 	results["faster"] = items
-	items = slower.items()
+	items = list(slower.items())
 	items.sort()
 	results["slower"] = items
 	return results
 
 def mainReport(baseMain, otherMain, baseName, otherName):
 	if baseMain["inclusive"] > otherMain["inclusive"]:
-		print "\nBaseline trial is relatively slower than second trial.\n"
+		print("\nBaseline trial is relatively slower than second trial.\n")
 		percentage = (baseMain["inclusive"] - otherMain["inclusive"]) / otherMain["inclusive"]
 		fasterSlower = -1
 	elif baseMain["inclusive"] < otherMain["inclusive"]:
-		print "\nBaseline trial is relatively faster than second trial.\n"
+		print("\nBaseline trial is relatively faster than second trial.\n")
 		percentage = (otherMain["inclusive"] - baseMain["inclusive"]) / baseMain["inclusive"]
 		fasterSlower = 1
 	else:
-		print "\nBaseline trial and second trial have the same execution time."
+		print("\nBaseline trial and second trial have the same execution time.")
 		fasterSlower = 0
 		percentage = 0.0
 	# print "\t", baseName, baseMain["name"], ":", baseMain["inclusive"], "seconds\n", 
 	# print "\t", otherName, otherMain["name"], ":", otherMain["inclusive"], "seconds\n", 
-	print "\t", baseName, ":", baseMain["inclusive"]/1000000, "seconds\n", 
-	print "\t", otherName, ":", otherMain["inclusive"]/1000000, "seconds\n", 
+	print("\t", baseName, ":", baseMain["inclusive"]/1000000, "seconds\n", end=' ') 
+	print("\t", otherName, ":", otherMain["inclusive"]/1000000, "seconds\n", end=' ') 
 	if fasterSlower < 0:
-		print "\t Relative Difference: ", percentage*100, "% slower\n"
+		print("\t Relative Difference: ", percentage*100, "% slower\n")
 	elif fasterSlower > 0:
-		print "\t Relative Difference: ", percentage*100, "% faster\n"
-	else:
-		print "\t Relative Difference: ", percentage*100, "%\n"
+		print("\t Relative Difference: ", percentage*100, "% faster\n")
+	else:
+		print("\t Relative Difference: ", percentage*100, "%\n")
 	return fasterSlower
 
 def showSignificantTimeEvents(diffs, type, significant):
@@ -107,7 +107,7 @@
 			break
 		# don't show insignificant differences
 		if event[1] > 1000000:
-			print "\t", event[0], ":", event[1]/1000000, "seconds", type, "than baseline"
+			print("\t", event[0], ":", event[1]/1000000, "seconds", type, "than baseline")
 			significant.append(event[0])
 			shown += 1
 		x += 1
@@ -129,7 +129,7 @@
 			break
 		# don't show insignificant differences
 		if event[1] > 1000000:
-			print "\t", event[0], ":", event[1]/1000000, "million", type, "than baseline"
+			print("\t", event[0], ":", event[1]/1000000, "million", type, "than baseline")
 			shown += 1
 		x += 1
 	return shown
@@ -175,7 +175,7 @@
 	if baseMain["name"] == otherMain["name"]:
 		fasterSlower = mainReport(baseMain, otherMain, baseTrial.getName(), otherTrial.getName())
 	else:
-		print "Main events do not match: ", baseMain["name"], ", ", otherMain["name"]
+		print("Main events do not match: ", baseMain["name"], ", ", otherMain["name"])
 		return
 
 	# compare the events for metric i
@@ -183,11 +183,11 @@
 
 	# tell the user the significant differences
 	significant = []
-	print "Significant", baseMetrics[baseTime], "differences between trials:\n"
+	print("Significant", baseMetrics[baseTime], "differences between trials:\n")
 	shown = showSignificantTimeEvents(diffs, "faster", significant)
 	shown += showSignificantTimeEvents(diffs, "slower", significant)
 	if shown == 0:
-		print "\t None.\n"
+		print("\t None.\n")
 
 	# significant is now populated with the names of events that are significant.
 	# iterate through the metrics to locate possible causes for the time difference.
@@ -197,20 +197,20 @@
 		if x != baseTime:
 			y = metricMap[x]
 			diffs = pairwiseEvent(baseEvents, otherEvents, x, y, significant)
-			print "\nSignificant", baseMetrics[x], "differences between trials:\n"
+			print("\nSignificant", baseMetrics[x], "differences between trials:\n")
 			shown = showSignificantEvents(diffs, "faster")
 			shown += showSignificantEvents(diffs, "slower")
 			if shown == 0:
-				print "\t None.\n"
+				print("\t None.\n")
 		x += 1
 	
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 pe = ScriptFacade()
 DoAnalysis(pe)
 
-print "\n"
-print "---------------- JPython test script end -------------"
+print("\n")
+print("---------------- JPython test script end -------------")
 
 pe.exit()
 
--- a/tools/src/perfexplorer/etc/simplegraphs.py	(original)
--- b/tools/src/perfexplorer/etc/simplegraphs.py	(refactored)
@@ -24,7 +24,7 @@
 	pe.setChartYAxisName("avg(interval_mean_summary.exclusive)", metric + " (million)")
 	pe.doGeneralChart()
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 pe = ScriptFacade()
 TotalExecutionTime1(pe, "P_WALL_CLOCK_TIME")
@@ -34,6 +34,6 @@
 TotalExecutionTime2(pe, "PAPI_FP_INS")
 TotalExecutionTime2(pe, "PAPI_L1_TCM")
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
 
 
--- a/tools/src/perfexplorer/etc/test.py	(original)
--- b/tools/src/perfexplorer/etc/test.py	(refactored)
@@ -2,10 +2,10 @@
 from edu.uoregon.tau.perfexplorer.common import TransformationType
 from edu.uoregon.tau.perfexplorer.common import AnalysisType
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 x = 2 + 5
-print x
+print(x)
 
 pe = ScriptFacade()
 pe.doSomething()
@@ -33,4 +33,4 @@
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/examples/ApexClassification/elMedico.py	(original)
--- b/tools/src/perfexplorer/examples/ApexClassification/elMedico.py	(refactored)
@@ -16,7 +16,7 @@
 	parameterMap = PerfExplorerModel.getModel().getScriptParameters()
 	keys = parameterMap.keySet()
 	for key in keys:
-		print key, parameterMap.get(key)
+		print(key, parameterMap.get(key))
 	mode = parameterMap.get("mode")
 	inputData = parameterMap.get("inputData")
 	classifierFilename = parameterMap.get("classifierFilename")
@@ -31,13 +31,13 @@
 	wrapper.setClassifierType(WekaClassifierWrapper.J48)
 	wrapper.buildClassifier()
 	end = time.clock()
-	print end - start, " seconds to build classifier"
+	print(end - start, " seconds to build classifier")
 	start = time.clock()
-	print wrapper.crossValidateModel(10);
+	print(wrapper.crossValidateModel(10));
 	end = time.clock()
-	print end - start, " seconds to validate classifier"
+	print(end - start, " seconds to validate classifier")
 	WekaClassifierWrapper.writeClassifier(classifierFilename, wrapper)
-	print classifierFilename, "created."
+	print(classifierFilename, "created.")
 
 def testClassifier():
 	global inputData
@@ -48,20 +48,20 @@
 	#	print className
 
 def main(argv):
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 
 	getParameters()
 
 	if mode == "build":
-		print "building classifier"
+		print("building classifier")
 		buildClassifier()
 	else:
-		print "using classifier"
+		print("using classifier")
 		testClassifier()
 
-	print "...done."
+	print("...done.")
 	
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main(sys.argv[1:])
--- a/tools/src/perfexplorer/examples/ClassBreakdown/classAggregation.py	(original)
--- b/tools/src/perfexplorer/examples/ClassBreakdown/classAggregation.py	(refactored)
@@ -169,9 +169,9 @@
 	tmp = parameterMap.get("tauData")
 	if tmp != None:
 		tauData = tmp
-		print "Performance data: " + tauData
-	else:
-		print "TAU profile data path not specified... using current directory of profile.x.x.x files."
+		print("Performance data: " + tauData)
+	else:
+		print("TAU profile data path not specified... using current directory of profile.x.x.x files.")
 
 def loadFile(fileName):
 	# load the trial
@@ -189,27 +189,27 @@
 	return input
 
 def dumpResult(ebd):
-	print ebd.fullName
-	print "type: " + ebd.type
-	print "returnType: " + ebd.returnType
+	print(ebd.fullName)
+	print("type: " + ebd.type)
+	print("returnType: " + ebd.returnType)
 	if ebd.reference:
-		print "reference: True"
-	else:
-		print "reference: False"
-	print "namespace: " + ebd.nameSpace
-	print "className: " + ebd.className
-	print "classTemplates: " + ebd.classTemplates
-	print "method: " + ebd.method
-	print "methodTemplate: " + ebd.methodTemplates
-	print "arguments: " + ebd.arguments
+		print("reference: True")
+	else:
+		print("reference: False")
+	print("namespace: " + ebd.nameSpace)
+	print("className: " + ebd.className)
+	print("classTemplates: " + ebd.classTemplates)
+	print("method: " + ebd.method)
+	print("methodTemplate: " + ebd.methodTemplates)
+	print("arguments: " + ebd.arguments)
 	if ebd.const:
-		print "const: True"
-	else:
-		print "const: False"
-	print "file: " + ebd.file
-	print "line: " + ebd.line
-	print "inclusive: ", ebd.inclusive
-	print "exclusive: ", ebd.exclusive
+		print("const: True")
+	else:
+		print("const: False")
+	print("file: " + ebd.file)
+	print("line: " + ebd.line)
+	print("inclusive: ", ebd.inclusive)
+	print("exclusive: ", ebd.exclusive)
 
 def checkParents(ebd, full, ebds):
 	# iterate over the callpath events
@@ -234,7 +234,7 @@
 	# Also, Multiple methods could have different templated instances.
 
 	methods = dict()
-	for event,ebd in ebds.items():
+	for event,ebd in list(ebds.items()):
 		if ebd.className == className:
 			value = 0.0
 			if ebd.type == "UNWIND":
@@ -254,18 +254,18 @@
 	showmax=5 # set to 0 to show all methods
 	for m in sorted(methods, key=methods.get, reverse=True):
 		if showmax > 0:
-			print "\tMethod '%s' : %f" % (m,methods[m]/1000000)
+			print("\tMethod '%s' : %f" % (m,methods[m]/1000000))
 		else:
 			othervalue = othervalue + methods[m]
 		showmax = showmax - 1
 	if showmax < 0:
-		print "\tAll other methods : %f" % (othervalue/1000000)
+		print("\tAll other methods : %f" % (othervalue/1000000))
 
 def main():
 	global filename
 	global tauData
 	global doInclusive
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# get the parameters
 	getParameters()
 	# load the data
@@ -281,17 +281,17 @@
 	mainEvent = result.getMainEvent()
 	
 	# then, extract those events from the actual data
-	print "Extracting non-callpath data..."
+	print("Extracting non-callpath data...")
 	flatten = ExtractNonCallpathEventOperation(result)
 	flat = flatten.processData().get(0)
 
-	print "Computing statistics..."
+	print("Computing statistics...")
 	statmaker = BasicStatisticsOperation(flat, False)
 	statmaker.setIncludeNull(False)
 	stats = statmaker.processData().get(BasicStatisticsOperation.MEAN)
 
 	# get the callpath events
-	print "Extracting callpath data..."
+	print("Extracting callpath data...")
 	fullen = ExtractCallpathEventOperation(result)
 	full = fullen.processData().get(0)
 
@@ -316,7 +316,7 @@
 			ebds[event] = ebd
 
 	classes = dict()
-	for event,ebd in ebds.items():
+	for event,ebd in list(ebds.items()):
 		value = 0
 		if ebd.type == "UNWIND":
 			value = checkParents(ebd,full,ebds)
@@ -332,17 +332,17 @@
 	for c in sorted(classes, key=classes.get, reverse=True):
 		#if len(c) > 0:
 		if showmax > 0:
-			print "\nClass '%s' : %f" % (c,classes[c]/1000000)
+			print("\nClass '%s' : %f" % (c,classes[c]/1000000))
 			showmax = showmax - 1
 			showChildren(ebds,c,full)
 		else:
 			othervalue = othervalue + classes[c]
 	# get the application total from the original profile, thread 0. It is the true application main.
-	print "\nAll other classes : %f, application total : %f" % (othervalue/1000000, result.getInclusive(0,mainEvent,metric)/1000000)
-	print "(inclusive aggregation of unwound samples and means without NULLs can add up to more than application total)"
-	print "\nMetric:", metric, "/ 1,000,000"
-
-	print "---------------- JPython test script end -------------"
+	print("\nAll other classes : %f, application total : %f" % (othervalue/1000000, result.getInclusive(0,mainEvent,metric)/1000000))
+	print("(inclusive aggregation of unwound samples and means without NULLs can add up to more than application total)")
+	print("\nMetric:", metric, "/ 1,000,000")
+
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/examples/ClassLightweights/classAggregation.py	(original)
--- b/tools/src/perfexplorer/examples/ClassLightweights/classAggregation.py	(refactored)
@@ -172,17 +172,17 @@
 	tmp = parameterMap.get("tauData")
 	if tmp != None:
 		tauData = tmp
-		print "Performance data: " + tauData
-	else:
-		print "TAU profile data path not specified... using current directory of profile.x.x.x files."
+		print("Performance data: " + tauData)
+	else:
+		print("TAU profile data path not specified... using current directory of profile.x.x.x files.")
 	tmp = parameterMap.get("threshold1")
 	if tmp != None:
 		threshold = float(tmp)
-	print "Max per call threshold: %f" % (threshold)
+	print("Max per call threshold: %f" % (threshold))
 	tmp = parameterMap.get("threshold2")
 	if tmp != None:
 		percentClass = float(tmp)
-	print "Min percent of class: %f" % (percentClass)
+	print("Min percent of class: %f" % (percentClass))
 
 def loadFile(fileName):
 	# load the trial
@@ -202,27 +202,27 @@
 def dumpResult(ebd):
 	global stats
 	global metric
-	print ebd.fullName
-	print "type: " + ebd.type
-	print "returnType: " + ebd.returnType
+	print(ebd.fullName)
+	print("type: " + ebd.type)
+	print("returnType: " + ebd.returnType)
 	if ebd.reference:
-		print "reference: True"
-	else:
-		print "reference: False"
-	print "namespace: " + ebd.nameSpace
-	print "className: " + ebd.className
-	print "classTemplates: " + ebd.classTemplates
-	print "method: " + ebd.method
-	print "methodTemplate: " + ebd.methodTemplates
-	print "arguments: " + ebd.arguments
+		print("reference: True")
+	else:
+		print("reference: False")
+	print("namespace: " + ebd.nameSpace)
+	print("className: " + ebd.className)
+	print("classTemplates: " + ebd.classTemplates)
+	print("method: " + ebd.method)
+	print("methodTemplate: " + ebd.methodTemplates)
+	print("arguments: " + ebd.arguments)
 	if ebd.const:
-		print "const: True"
-	else:
-		print "const: False"
-	print "file: " + ebd.file
-	print "line: " + ebd.line
-	print "inclusive: ", stats.getInclusive(0,ebd.fullName,metric)
-	print "exclusive: ", stats.getExclusive(0,ebd.fullName,metric)
+		print("const: True")
+	else:
+		print("const: False")
+	print("file: " + ebd.file)
+	print("line: " + ebd.line)
+	print("inclusive: ", stats.getInclusive(0,ebd.fullName,metric))
+	print("exclusive: ", stats.getExclusive(0,ebd.fullName,metric))
 
 def checkParents(ebd, full, ebds):
 	global stats
@@ -254,7 +254,7 @@
 
 	methods = dict()
 	methodcalls = dict()
-	for event,ebd in ebds.items():
+	for event,ebd in list(ebds.items()):
 		if ebd.className == className:
 			value = 0.0
 			calls = 0
@@ -284,7 +284,7 @@
 		if classTotal > 0:
 			perclass = methods[m] / classTotal
 		if percall < threshold and perclass > percentClass:
-			print "\tMethod '%s' : total = %.2e, calls = %.2e, percall = %.2f, %%class = %.2f%%" % (m,methods[m],methodcalls[m],percall,perclass)
+			print("\tMethod '%s' : total = %.2e, calls = %.2e, percall = %.2f, %%class = %.2f%%" % (m,methods[m],methodcalls[m],percall,perclass))
 
 def main():
 	global filename
@@ -293,7 +293,7 @@
 	global stats
 	global metric
 	global threshold
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# get the parameters
 	getParameters()
 	# load the data
@@ -315,29 +315,29 @@
 			metrics = result.getMetrics().toArray()
 			metric = metrics[0]
 
-	print "Using metric:", metric
+	print("Using metric:", metric)
 	type = result.EXCLUSIVE
 	mainEvent = result.getMainEvent()
 	
 	# then, extract those events from the actual data
-	print "Extracting non-callpath data...",
+	print("Extracting non-callpath data...", end=' ')
 	flatten = ExtractNonCallpathEventOperation(result)
 	flat = flatten.processData().get(0)
-	print "done."
-
-	print "Computing statistics...",
+	print("done.")
+
+	print("Computing statistics...", end=' ')
 	statmaker = BasicStatisticsOperation(flat, False)
 	statmaker.setIncludeNull(False)
 	stats = statmaker.processData().get(BasicStatisticsOperation.MEAN)
-	print "done."
+	print("done.")
 
 	# get the callpath events
-	print "Extracting callpath data...",
+	print("Extracting callpath data...", end=' ')
 	fullen = ExtractCallpathEventOperation(result)
 	full = fullen.processData().get(0)
-	print "done."
-
-	print "Iterating over methods...",
+	print("done.")
+
+	print("Iterating over methods...", end=' ')
     # Iterate over all methods, and parse out the class for each method
 	ebds = dict()
 	for event in flat.getEvents():
@@ -355,15 +355,15 @@
 		elif event != ".TAU application":
 			ebd = EventBreakdown(event)
 			ebds[event] = ebd
-	print "done."
+	print("done.")
 
 	# iterate over the parsed events, and aggreate them by class
 	classes = dict()
 	progress = 0.0
-	print "Aggregating by class...",
-	for event,ebd in ebds.items():
+	print("Aggregating by class...", end=' ')
+	for event,ebd in list(ebds.items()):
 		progress = progress + 1.0
-		print "\rAggregating by class... %.2f%% (%d of %d methods)" % ((progress / len(ebds))*100.0,progress,len(ebds)),
+		print("\rAggregating by class... %.2f%% (%d of %d methods)" % ((progress / len(ebds))*100.0,progress,len(ebds)), end=' ')
 		value = 0
 		if ebd.type == "UNWIND":
 			value = checkParents(ebd,full,ebds)
@@ -373,7 +373,7 @@
 			classes[ebd.className] = classes[ebd.className] + value
 		else:
 			classes[ebd.className] = value
-	print "done. %d classes found." % (len(classes))
+	print("done. %d classes found." % (len(classes)))
 
 	appTotal = result.getInclusive(0,mainEvent,metric) / 100.0 # for scaling to percent
 	othervalue = 0
@@ -381,17 +381,17 @@
 	for c in sorted(classes, key=classes.get, reverse=True):
 		#if len(c) > 0:
 		if showmax > 0:
-			print "\nClass '%s' : total = %.2e, %% application = %.2f%%" % (c,classes[c],classes[c]/appTotal)
+			print("\nClass '%s' : total = %.2e, %% application = %.2f%%" % (c,classes[c],classes[c]/appTotal))
 			showmax = showmax - 1
 			showChildren(ebds,c,full,classes[c]/100.0) # for scaling to percent
 		else:
 			othervalue = othervalue + classes[c]
 	# get the application total from the original profile, thread 0. It is the true application main.
-	print "\nAll other classes : %.2e, application total : %.2e" % (othervalue, appTotal * 100.0) # scale it back
-	print "(inclusive aggregation of unwound samples and means without NULLs can add up to more than application total)"
-	print "\nMetric:", metric
-
-	print "---------------- JPython test script end -------------"
+	print("\nAll other classes : %.2e, application total : %.2e" % (othervalue, appTotal * 100.0)) # scale it back
+	print("(inclusive aggregation of unwound samples and means without NULLs can add up to more than application total)")
+	print("\nMetric:", metric)
+
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/examples/ClusterAndDifference/clusterTest.py	(original)
--- b/tools/src/perfexplorer/examples/ClusterAndDifference/clusterTest.py	(refactored)
@@ -9,9 +9,9 @@
 	tmp = parameterMap.get("tauData")
 	if tmp != None:
 		tauData = tmp
-		print "Performance data: " + tauData
+		print("Performance data: " + tauData)
 	else:
-		print "TAU profile data path not specified... using current directory of profile.x.x.x files."
+		print("TAU profile data path not specified... using current directory of profile.x.x.x files.")
 
 def loadFile(fileName):
 	# load the trial
@@ -37,8 +37,8 @@
 	baseline = extracted.get(0)
 	comparison = extracted.get(1)
 
-	print "Baseline: ", baselineName
-	print "Comparison: ", comparisonName
+	print("Baseline: ", baselineName)
+	print("Comparison: ", comparisonName)
 
 	# get the stats
 	statMakerBaseline = BasicStatisticsOperation(baseline)
@@ -57,19 +57,19 @@
 
 		max = 10
 		if type == AbstractResult.EXCLUSIVE:
-			print "\nExclusive:\n"
+			print("\nExclusive:\n")
 		elif type == AbstractResult.INCLUSIVE:
-			print "\nInclusive:\n"
+			print("\nInclusive:\n")
 			max = 20
 		else:
-			print "\nNumber of Calls:\n"
+			print("\nNumber of Calls:\n")
 
 		# get the top 10?
 		topXmaker = TopXEvents(diffs, baseline.getTimeMetric(), type, max)
 		top10 = topXmaker.processData().get(0)
 
-		print "B_Time  C_Time  D_Time  %_Diff  Event"
-		print "------  ------  ------  ------  ------"
+		print("B_Time  C_Time  D_Time  %_Diff  Event")
+		print("------  ------  ------  ------  ------")
 		for thread in top10.getThreads():
 			for event in top10.getEvents():
 				for metric in top10.getMetrics():
@@ -82,14 +82,14 @@
 						diff = diff * 0.000001
 					if baselineVal > comparisonVal:
 						diff = diff * -1.0
-					print "%.2f\t%.2f\t%.2f\t%.2f\t%s" % (baselineVal, comparisonVal, diff, (diff/baselineVal)*100.0, event)
+					print("%.2f\t%.2f\t%.2f\t%.2f\t%s" % (baselineVal, comparisonVal, diff, (diff/baselineVal)*100.0, event))
 
 	return
 
 def main():
 	global filename
-	print "--------------- JPython test script start ------------"
-	print "doing cluster test"
+	print("--------------- JPython test script start ------------")
+	print("doing cluster test")
 	# get the parameters
 	getParameters()
 	# load the data
@@ -127,7 +127,7 @@
 	# cluster the data 
 	clusterer = DBSCANOperation(reduced, metric, type, 1.0)
 	clusterResult = clusterer.processData()
-	print "Estimated value for k:", str(clusterResult.get(0).getThreads().size())
+	print("Estimated value for k:", str(clusterResult.get(0).getThreads().size()))
 	clusterIDs = clusterResult.get(4)
 
 	# split the trial into the clusters
@@ -145,7 +145,7 @@
 		
 
 
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/examples/ClusterAndDifference/difference.py	(original)
--- b/tools/src/perfexplorer/examples/ClusterAndDifference/difference.py	(refactored)
@@ -39,8 +39,8 @@
 	baseline = extracted.get(0)
 	comparison = extracted.get(1)
 
-	print "Baseline: ", baselineName
-	print "Comparison: ", comparisonName
+	print("Baseline: ", baselineName)
+	print("Comparison: ", comparisonName)
 
 	# get the stats
 	statMakerBaseline = BasicStatisticsOperation(baseline)
@@ -59,19 +59,19 @@
 
 		max = 10
 		if type == AbstractResult.EXCLUSIVE:
-			print "\nExclusive:\n"
+			print("\nExclusive:\n")
 		elif type == AbstractResult.INCLUSIVE:
-			print "\nInclusive:\n"
+			print("\nInclusive:\n")
 			max = 20
 		else:
-			print "\nNumber of Calls:\n"
+			print("\nNumber of Calls:\n")
 
 		# get the top 10?
 		topXmaker = TopXEvents(diffs, baseline.getTimeMetric(), type, max)
 		top10 = topXmaker.processData().get(0)
 
-		print "B_Time  C_Time  D_Time  %_Diff  Event"
-		print "------  ------  ------  ------  ------"
+		print("B_Time  C_Time  D_Time  %_Diff  Event")
+		print("------  ------  ------  ------  ------")
 		for thread in top10.getThreads():
 			for event in top10.getEvents():
 				for metric in top10.getMetrics():
@@ -84,16 +84,16 @@
 						diff = diff * 0.000001
 					if baselineVal > comparisonVal:
 						diff = diff * -1.0
-					print "%.2f\t%.2f\t%.2f\t%.2f\t%s" % (baselineVal, comparisonVal, diff, (diff/baselineVal)*100.0, event)
+					print("%.2f\t%.2f\t%.2f\t%.2f\t%s" % (baselineVal, comparisonVal, diff, (diff/baselineVal)*100.0, event))
 
 	return
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 
 	diffs()
 
-	print "\n---------------- JPython test script end -------------"
+	print("\n---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/examples/ClusterAndLoadBalance/clusterTest.py	(original)
--- b/tools/src/perfexplorer/examples/ClusterAndLoadBalance/clusterTest.py	(refactored)
@@ -17,9 +17,9 @@
 	tmp = parameterMap.get("tauData")
 	if tmp != None:
 		tauData = tmp
-		print "Performance data: " + tauData
+		print("Performance data: " + tauData)
 	else:
-		print "TAU profile data path not specified... using current directory of profile.x.x.x files."
+		print("TAU profile data path not specified... using current directory of profile.x.x.x files.")
 
 def loadFile(fileName):
 	# load the trial
@@ -34,8 +34,8 @@
 
 def main():
 	global filename
-	print "--------------- JPython test script start ------------"
-	print "doing cluster test"
+	print("--------------- JPython test script start ------------")
+	print("doing cluster test")
 	# get the parameters
 	getParameters()
 	# load the data
@@ -71,7 +71,7 @@
 	clusterResult = clusterer.processData()
 	k = str(clusterResult.get(0).getThreads().size())
 	clusters = ArrayList()
-	print "Estimated value for k:", k
+	print("Estimated value for k:", k)
 	if k > 0:
 		clusterIDs = clusterResult.get(4)
 
@@ -81,7 +81,7 @@
 	else:
 		clusters.put(result)
 
-	print "\nCluster\t Procs\t Type\t\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX"
+	print("\nCluster\t Procs\t Type\t\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX")
 	clusterID = 0
 
 	for trial in clusters:
@@ -112,10 +112,10 @@
 		stddev = stddevs.getExclusive(thread, event, metric)
 		ratio = ratios.getExclusive(thread, event, metric)
 
-		print "%d\t %d\t %s\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % (clusterID, trial.getThreads().size(), event, mean*100, max*100, min*100, stddev*100, ratio*100)
+		print("%d\t %d\t %s\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % (clusterID, trial.getThreads().size(), event, mean*100, max*100, min*100, stddev*100, ratio*100))
 		clusterID = clusterID + 1
 
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/examples/ClusterAndMicroLoadImbalance/clusterTest.py	(original)
--- b/tools/src/perfexplorer/examples/ClusterAndMicroLoadImbalance/clusterTest.py	(refactored)
@@ -20,16 +20,16 @@
 	tmp = parameterMap.get("tauData")
 	if tmp != None:
 		tauData = tmp
-		print "Performance data: " + tauData
-	else:
-		print "TAU profile data path not specified... using current directory of profile.x.x.x files."
+		print("Performance data: " + tauData)
+	else:
+		print("TAU profile data path not specified... using current directory of profile.x.x.x files.")
 
 	tmp = parameterMap.get("prefix")
 	if tmp != None:
 		iterationPrefix = tmp
-		print "Iteration Prefix: " + iterationPrefix
-	else:
-		print "Iteration Prefix not specified... using", iterationPrefix
+		print("Iteration Prefix: " + iterationPrefix)
+	else:
+		print("Iteration Prefix not specified... using", iterationPrefix)
 
 def loadFile(fileName):
 	# load the trial
@@ -72,7 +72,7 @@
 	stddev = stddevs.getExclusive(thread, event, metric)
 	ratio = ratios.getExclusive(thread, event, metric)
 
-	print "%d\t %d\t %s\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % (clusterID, trial.getThreads().size(), event, mean*100, max*100, min*100, stddev*100, ratio*100)
+	print("%d\t %d\t %s\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % (clusterID, trial.getThreads().size(), event, mean*100, max*100, min*100, stddev*100, ratio*100))
 	clusterID = clusterID + 1
 	return clusterID
 
@@ -108,9 +108,9 @@
 	#print mean, max, min, stddev, ratio
 
 	if callpath:
-		print "%s\t %d\t %ls\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % (mainEvent, trial.getThreads().size(), event, mean*100, max*100, min*100, stddev*100, ratio*100)
-	else:
-		print "%d\t %s\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % (trial.getThreads().size(), event, mean*100, max*100, min*100, stddev*100, ratio*100)
+		print("%s\t %d\t %ls\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % (mainEvent, trial.getThreads().size(), event, mean*100, max*100, min*100, stddev*100, ratio*100))
+	else:
+		print("%d\t %s\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % (trial.getThreads().size(), event, mean*100, max*100, min*100, stddev*100, ratio*100))
 
 	return mean, max, min, stddev
 
@@ -127,8 +127,8 @@
 def main():
 	global filename
 	global iterationPrefix
-	print "--------------- JPython test script start ------------"
-	print "doing cluster test"
+	print("--------------- JPython test script start ------------")
+	print("doing cluster test")
 	# get the parameters
 	getParameters()
 	# load the data
@@ -145,7 +145,7 @@
 	extracted = extractor.processData().get(0)
 	
 	# split communication and computation
-	print "splitting communication and computation"
+	print("splitting communication and computation")
 	splitter = SplitCommunicationComputationOperation(extracted)
 	outputs = splitter.processData()
 	computation = outputs.get(SplitCommunicationComputationOperation.COMPUTATION)
@@ -153,33 +153,33 @@
 	#computation = result
 
 	# do some basic statistics first
-	print "doing stats"
+	print("doing stats")
 	stats = BasicStatisticsOperation(computation)
 	means = stats.processData().get(BasicStatisticsOperation.MEAN)
 
 	# then, using the stats, find the top X event names
-	print "getting top X events"
+	print("getting top X events")
 	reducer = TopXEvents(means, metric, type, 10)
 	reduced = reducer.processData().get(0)
 
 	# then, extract those events from the actual data
-	print "extracting events"
+	print("extracting events")
 	tmpEvents = ArrayList(reduced.getEvents())
 	reducer = ExtractEventOperation(computation, tmpEvents)
 	reduced = reducer.processData().get(0)
 
 	# cluster the data 
-	print "clustering data"
+	print("clustering data")
 	clusterer = DBSCANOperation(reduced, metric, type, 1.0)
 	clusterResult = clusterer.processData()
 	k = str(clusterResult.get(0).getThreads().size())
 	clusters = ArrayList()
-	print "Estimated value for k:", k
+	print("Estimated value for k:", k)
 	if k > 0:
 		clusterIDs = clusterResult.get(4)
 
 		# split the trial into the clusters
-		print "splitting clusters into", k, "trials"
+		print("splitting clusters into", k, "trials")
 		splitter = SplitTrialClusters(result, clusterResult)
 		splitter.setIncludeNoisePoints(True)
 		clusters = splitter.processData()
@@ -187,7 +187,7 @@
 		clusters.put(result)
 
 	clusterID = -1
-	print "\nCluster\t Procs\t Type\t\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX"
+	print("\nCluster\t Procs\t Type\t\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX")
 	clusterID = doLoadImbalance(result, clusterID)
 
 	for trial in clusters:
@@ -202,7 +202,7 @@
 			
 	clusterID = 0
 	for trial in clusters:
-		print "\n\nSplitting phases in cluster", clusterID
+		print("\n\nSplitting phases in cluster", clusterID)
 		splitter = SplitTrialPhasesOperation(trial, iterationPrefix)
 		phases = splitter.processData()
 		#print phases.size()
@@ -212,7 +212,7 @@
 		totalStddev = 0.0
 		totalRatio = 0.0
 
-		print "LoopID\t\t Procs\t Type\t\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX"
+		print("LoopID\t\t Procs\t Type\t\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX")
 		for phase in phases:
 			#print "main event:", phase.getMainEvent()
 			#for event in phase.getEvents():
@@ -228,10 +228,10 @@
 		avgRatio = avgMean / avgMax
 
 		event = LoadImbalanceOperation.KERNEL_COMPUTATION
-		print "%s\t\t %d\t %ls\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % ("Average", trial.getThreads().size(), event, avgMean*100, avgMax*100, avgMin*100, avgStddev*100, avgRatio*100)
+		print("%s\t\t %d\t %ls\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % ("Average", trial.getThreads().size(), event, avgMean*100, avgMax*100, avgMin*100, avgStddev*100, avgRatio*100))
 		clusterID = clusterID + 1
 	
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/examples/ClusterAndMicroLoadImbalance/clusterTestActual.py	(original)
--- b/tools/src/perfexplorer/examples/ClusterAndMicroLoadImbalance/clusterTestActual.py	(refactored)
@@ -21,16 +21,16 @@
 	tmp = parameterMap.get("tauData")
 	if tmp != None:
 		tauData = tmp
-		print "Performance data: " + tauData
-	else:
-		print "TAU profile data path not specified... using current directory of profile.x.x.x files."
+		print("Performance data: " + tauData)
+	else:
+		print("TAU profile data path not specified... using current directory of profile.x.x.x files.")
 
 	tmp = parameterMap.get("prefix")
 	if tmp != None:
 		iterationPrefix = tmp
-		print "Iteration Prefix: " + iterationPrefix
-	else:
-		print "Iteration Prefix not specified... using", iterationPrefix
+		print("Iteration Prefix: " + iterationPrefix)
+	else:
+		print("Iteration Prefix not specified... using", iterationPrefix)
 
 def loadFile(fileName):
 	# load the trial
@@ -79,7 +79,7 @@
 	ratio = ratios.getExclusive(thread, event, metric)
 
 	inclusive = masterMeans.getInclusive(0, mainEventLong, metric) * conversion
-	print "%d\t %d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.2f\t" % (clusterID, trial.getThreads().size(), inclusive, event, mean, max, min, stddev, ratio)
+	print("%d\t %d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.2f\t" % (clusterID, trial.getThreads().size(), inclusive, event, mean, max, min, stddev, ratio))
 	clusterID = clusterID + 1
 	return clusterID
 
@@ -122,7 +122,7 @@
 	inclusive = masterMeans.getInclusive(0, mainEventLong, metric) * conversion
 
 	if numphases < 100:
-		print "%s\t %d\t %.2f\t %ls\t %.2f\t %.2f\t %.2f\t %.2f\t %.2f\t" % (mainEvent, trial.getThreads().size(), inclusive, event, mean, max, min, stddev, ratio)
+		print("%s\t %d\t %.2f\t %ls\t %.2f\t %.2f\t %.2f\t %.2f\t %.2f\t" % (mainEvent, trial.getThreads().size(), inclusive, event, mean, max, min, stddev, ratio))
 
 	return mean, max, min, stddev, inclusive
 
@@ -140,8 +140,8 @@
 	global filename
 	global iterationPrefix
 	global masterMeans
-	print "--------------- JPython test script start ------------"
-	print "doing cluster test"
+	print("--------------- JPython test script start ------------")
+	print("doing cluster test")
 	# get the parameters
 	getParameters()
 	# load the data
@@ -158,13 +158,13 @@
 	extracted = extractor.processData().get(0)
 
 	extracted.setIgnoreWarnings(True)
-	print "Getting basic statistics..."
+	print("Getting basic statistics...")
 	statter = BasicStatisticsOperation(extracted)
 	masterStats = statter.processData()
 	masterMeans = masterStats.get(BasicStatisticsOperation.MEAN)
 	
 	# split communication and computation
-	print "splitting communication and computation"
+	print("splitting communication and computation")
 	splitter = SplitCommunicationComputationOperation(extracted)
 	outputs = splitter.processData()
 	computation = outputs.get(SplitCommunicationComputationOperation.COMPUTATION)
@@ -172,33 +172,33 @@
 	#computation = result
 
 	# do some basic statistics first
-	print "doing stats"
+	print("doing stats")
 	stats = BasicStatisticsOperation(computation)
 	means = stats.processData().get(BasicStatisticsOperation.MEAN)
 
 	# then, using the stats, find the top X event names
-	print "getting top X events"
+	print("getting top X events")
 	reducer = TopXEvents(means, metric, type, 10)
 	reduced = reducer.processData().get(0)
 
 	# then, extract those events from the actual data
-	print "extracting events"
+	print("extracting events")
 	tmpEvents = ArrayList(reduced.getEvents())
 	reducer = ExtractEventOperation(computation, tmpEvents)
 	reduced = reducer.processData().get(0)
 
 	# cluster the data 
-	print "clustering data"
+	print("clustering data")
 	clusterer = DBSCANOperation(reduced, metric, type, 1.0)
 	clusterResult = clusterer.processData()
 	k = str(clusterResult.get(0).getThreads().size())
 	clusters = ArrayList()
-	print "Estimated value for k:", k
+	print("Estimated value for k:", k)
 	if k > 0:
 		clusterIDs = clusterResult.get(4)
 
 		# split the trial into the clusters
-		print "splitting clusters into", k, "trials"
+		print("splitting clusters into", k, "trials")
 		splitter = SplitTrialClusters(result, clusterResult)
 		splitter.setIncludeNoisePoints(True)
 		clusters = splitter.processData()
@@ -206,7 +206,7 @@
 		clusters.put(result)
 
 	clusterID = -1
-	print "\nCluster\t Procs\t Incl.\t Type\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX"
+	print("\nCluster\t Procs\t Incl.\t Type\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX")
 	clusterID = doLoadImbalance(result, clusterID)
 
 	for trial in clusters:
@@ -226,7 +226,7 @@
 		#masterStats = statter.processData()
 		#masterMeans = masterStats.get(BasicStatisticsOperation.MEAN)
 
-		print "\n\nSplitting phases in cluster", clusterID
+		print("\n\nSplitting phases in cluster", clusterID)
 		splitter = SplitTrialPhasesOperation(trial, iterationPrefix)
 		phases = splitter.processData()
 		#print phases.size()
@@ -239,7 +239,7 @@
 		totalStddev = 0.0
 		totalRatio = 0.0
 
-		print "LoopID\t\t Procs\t Incl.\t Type\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX"
+		print("LoopID\t\t Procs\t Incl.\t Type\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX")
 		for phase in phases:
 			#print "main event:", phase.getMainEvent()
 			#for event in phase.getEvents():
@@ -262,10 +262,10 @@
 
 		#event = LoadImbalanceOperation.KERNEL_COMPUTATION
 		event = LoadImbalanceOperation.COMPUTATION
-		print "%s\t\t %d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.2f\t" % ("Average", trial.getThreads().size(), avgInclusive, event, avgMean, avgMax, avgMin, avgStddev, avgRatio)
+		print("%s\t\t %d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.2f\t" % ("Average", trial.getThreads().size(), avgInclusive, event, avgMean, avgMax, avgMin, avgStddev, avgRatio))
 		clusterID = clusterID + 1
 	
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/examples/ClusterAndMicroLoadImbalance/newClusterTestActual.py	(original)
--- b/tools/src/perfexplorer/examples/ClusterAndMicroLoadImbalance/newClusterTestActual.py	(refactored)
@@ -57,16 +57,16 @@
 	tmp = parameterMap.get("tauData")
 	if tmp != None:
 		tauData = tmp
-		print "Performance data: " + tauData
-	else:
-		print "TAU profile data path not specified... using current directory of profile.x.x.x files."
+		print("Performance data: " + tauData)
+	else:
+		print("TAU profile data path not specified... using current directory of profile.x.x.x files.")
 
 	tmp = parameterMap.get("prefix")
 	if tmp != None:
 		iterationPrefix = tmp
-		print "Iteration Prefix: " + iterationPrefix
-	else:
-		print "Iteration Prefix not specified... using", iterationPrefix
+		print("Iteration Prefix: " + iterationPrefix)
+	else:
+		print("Iteration Prefix not specified... using", iterationPrefix)
 
 def loadFile(fileName):
 	global gprof
@@ -142,10 +142,10 @@
 		return 0, 0, 0, 0, 0, 0
 	if callpath:
 		if numPhases < 100:
-			print "%s\t %d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.4f\t %.4f" % (trunc(mainEvent, max_pos=15), threads, inclusive, event, mean, max, min, stddev, max/inclusive, ratio)
+			print("%s\t %d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.4f\t %.4f" % (trunc(mainEvent, max_pos=15), threads, inclusive, event, mean, max, min, stddev, max/inclusive, ratio))
 		#print "%s\t %d\t %s\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % (mainEvent, trial.getThreads().size(), event, mean*100, 100, 100, 100, 100)
 	else:
-		print "%d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.4f\t %.4f" % (threads, inclusive, event, mean, max, min, stddev, max/inclusive, ratio)
+		print("%d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.4f\t %.4f" % (threads, inclusive, event, mean, max, min, stddev, max/inclusive, ratio))
 
 	splits = loadBalance.get(LoadImbalanceOperation.COMPUTATION_SPLITS)
 	for thread in splits.getThreads():
@@ -175,7 +175,7 @@
 	global vectorT_i
 	global vectorT
 
-	print "Getting basic statistics..."
+	print("Getting basic statistics...")
 	trial.setIgnoreWarnings(True)
 	statter = BasicStatisticsOperation(trial)
 	masterStats = statter.processData()
@@ -196,7 +196,7 @@
 	#print "Procs\t Incl.\t Type\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX"
 	#computeLoadBalance(trial, False, 1)
 
-	print
+	print()
 
 	splitter = SplitTrialPhasesOperation(trial, iterationPrefix)
 	phases = splitter.processData()
@@ -210,8 +210,8 @@
 	totalStddev = 0.0
 	totalRatio = 0.0
 
-	print "LoopID\t\t Procs\t Incl.\t  Type\t\t AVG\t MAX\t MIN\t STDEV\t CommEff AVG/MAX"
-	print "------------------------------------------------------------------------------------------------"
+	print("LoopID\t\t Procs\t Incl.\t  Type\t\t AVG\t MAX\t MIN\t STDEV\t CommEff AVG/MAX")
+	print("------------------------------------------------------------------------------------------------")
 	for phase in phases:
 		mean, max, min, stddev, inclusive, commEff = computeLoadBalance(phase, True, phases.size())
 		if mean == max == min == stddev == 0:
@@ -256,44 +256,44 @@
 
 	event = LoadImbalanceOperation.COMPUTATION
 	#print "%s\t\t %d\t %ls\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % ("Average", trial.getThreads().size(), event, avgMean*100, avgMax*100, avgMin*100, avgStddev*100, avgRatio*100)
-	print "------------------------------------------------------------------------------------------------"
-	print "%s\t\t %d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.2f\t %.2f" % ("Totals", trial.getThreads().size(), totalInclusive, event, totalMean, totalMax, totalMin, math.sqrt(totalStddev), totalCommEff, totalMean / totalMax)
-	print "%s\t\t %d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.4f\t %.4f" % ("Average", trial.getThreads().size(), avgInclusive, event, avgMean, avgMax, avgMin, avgStddev, avgCommEff, avgRatio)
+	print("------------------------------------------------------------------------------------------------")
+	print("%s\t\t %d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.2f\t %.2f" % ("Totals", trial.getThreads().size(), totalInclusive, event, totalMean, totalMax, totalMin, math.sqrt(totalStddev), totalCommEff, totalMean / totalMax))
+	print("%s\t\t %d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.4f\t %.4f" % ("Average", trial.getThreads().size(), avgInclusive, event, avgMean, avgMax, avgMin, avgStddev, avgCommEff, avgRatio))
 
 	# the total time spent in the loop.  Essentially, for each
 	# iteration of the loop, get the total time for each process.  Accumulate
 	# that vector over the whole loop.  The process with the longest time spent
 	# computing (aggregated over all iterations) is the T.
-	print "\nT:\t\t", T  
+	print("\nT:\t\t", T)  
 	# the total time spent computing, collapsed.  Essentially, for each
 	# iteration of the loop, get the computing time for each process.  Accumulate
 	# that vector over the whole loop.  The process with the longest time spent
 	# computing (aggregated over all iterations) is the max(T_i).  
-	print "max(T_i):\t", maxT_i
-	print "avg(T_i):\t", avgT_i
-	print "maxEff:\t\t", maxEff
-	print "CommEff:\t", commEff, "(should be same as maxEff)"
+	print("max(T_i):\t", maxT_i)
+	print("avg(T_i):\t", avgT_i)
+	print("maxEff:\t\t", maxEff)
+	print("CommEff:\t", commEff, "(should be same as maxEff)")
 	# the load balance for the loop.  This is the sum of all efficiencies for
 	# all processes, divided by the number of processes times the maxiumum
 	# efficiency.  This can be (and is) simplified, by summing the mean
 	# computing times, and dividing by the max computing times.
-	print "avgEff:\t\t", avgEff
-	print "LB:\t\t", LB
+	print("avgEff:\t\t", avgEff)
+	print("LB:\t\t", LB)
 
 	# the total time spent computing in the loop, serialized.  Essentially, for each
 	# iteration of the loop, get the max computing time in that loop.  Add
 	# those together.  Because of overlapping iterations, this can be larger
 	# than the actual time in the loop.  If there were
 	# no time spent in communication, this is how long the loop should take.
-	print "T ideal:\t", totalMax
+	print("T ideal:\t", totalMax)
 	# the micro load balance is the process with the highest computation time
 	# divided by the ideal total loop execution time.
-	print "microLB:\t", maxT_i / totalMax
+	print("microLB:\t", maxT_i / totalMax)
 	# the transfer term is the total time spent in the ideal loop divided by
 	# the actual time spent in the loop.
-	print "Transfer:\t", totalMax / T
+	print("Transfer:\t", totalMax / T)
 	# finally, compute the efficiency.  == LB * microLB * Transfer * IPC
-	print "n:\t\t", LB * (maxT_i / totalMax) * (totalMax / T) * 1.0, "\n"
+	print("n:\t\t", LB * (maxT_i / totalMax) * (totalMax / T) * 1.0, "\n")
 	
 
 def main():
@@ -304,8 +304,8 @@
 	global vectorT_i
 	global vectorT
 
-	print "--------------- JPython test script start ------------"
-	print "--- Looking for load imbalances --- "
+	print("--------------- JPython test script start ------------")
+	print("--- Looking for load imbalances --- ")
 
 	# get the parameters
 	getParameters()
@@ -328,37 +328,37 @@
 	extracted.setIgnoreWarnings(True)
 
 	# split communication and computation
-	print "splitting communication and computation"
+	print("splitting communication and computation")
 	splitter = SplitCommunicationComputationOperation(extracted)
 	outputs = splitter.processData()
 	computation = outputs.get(SplitCommunicationComputationOperation.COMPUTATION)
 
 	# do some basic statistics first
-	print "doing stats"
+	print("doing stats")
 	simplestats = BasicStatisticsOperation(computation)
 	simplemeans = simplestats.processData().get(BasicStatisticsOperation.MEAN)
 
 	# get top 10 events
-	print "getting top X events"
+	print("getting top X events")
 	reducer = TopXEvents(simplemeans, metric, type, 10)
 	reduced = reducer.processData().get(0)
-	print "extracting events"
+	print("extracting events")
 	tmpEvents = ArrayList(reduced.getEvents())
 	reducer = ExtractEventOperation(computation, tmpEvents)
 	reduced = reducer.processData().get(0)
 
 	# cluster
-	print "clustering data"
+	print("clustering data")
 	clusterer = DBSCANOperation(reduced, metric, type, 1.0)
 	clusterResult = clusterer.processData()
 	k = str(clusterResult.get(0).getThreads().size())
 	clusters = ArrayList()
-	print "Estimated value for k:", k
+	print("Estimated value for k:", k)
 	if k > 0:
 		clusterIDs = clusterResult.get(4)
 
 		# split the trial into the clusters
-		print "splitting clusters into", k, "trials"
+		print("splitting clusters into", k, "trials")
 		splitter = SplitTrialClusters(result, clusterResult)
 		splitter.setIncludeNoisePoints(True)
 		clusters = splitter.processData()
@@ -373,7 +373,7 @@
 	for trial in clusters:
 		processCluster(trial, result)
 
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/examples/ClusterAndTopX/clusterTest.py	(original)
--- b/tools/src/perfexplorer/examples/ClusterAndTopX/clusterTest.py	(refactored)
@@ -15,9 +15,9 @@
 	tmp = parameterMap.get("tauData")
 	if tmp != None:
 		tauData = tmp
-		print "Performance data: " + tauData
+		print("Performance data: " + tauData)
 	else:
-		print "TAU profile data path not specified... using current directory of profile.x.x.x files."
+		print("TAU profile data path not specified... using current directory of profile.x.x.x files.")
 	tmp = parameterMap.get("threshold")
 	if tmp != None:
 		threshold = float(tmp)
@@ -25,8 +25,8 @@
 	if tmp != None:
 		callsCutoff = float(tmp)
 
-	print "Max Functions Threshold:\t", threshold
-	print "Max Calls Threshold:\t", callsCutoff
+	print("Max Functions Threshold:\t", threshold)
+	print("Max Calls Threshold:\t", callsCutoff)
 
 def loadFile(fileName):
 	# load the trial
@@ -48,8 +48,8 @@
 	global tauData
 	global threshold
 	global callsCutoff
-	print "--------------- JPython test script start ------------"
-	print "doing cluster test"
+	print("--------------- JPython test script start ------------")
+	print("doing cluster test")
 	# get the parameters
 	getParameters()
 	# load the data
@@ -83,7 +83,7 @@
 	# cluster the data 
 	clusterer = DBSCANOperation(reduced, metric, type, 1.0)
 	clusterResult = clusterer.processData()
-	print "Estimated value for k:", str(clusterResult.get(0).getThreads().size())
+	print("Estimated value for k:", str(clusterResult.get(0).getThreads().size()))
 	clusterIDs = clusterResult.get(4)
 
 	# split the trial into the clusters
@@ -98,14 +98,14 @@
 	for input in clusters:
 
 		# extract the non-callpath data
-		print "Extracting non-callpath data..."
+		print("Extracting non-callpath data...")
 		input.setIgnoreWarnings(True)
 		extractor = ExtractNonCallpathEventOperation(input)
 		extracted = extractor.processData().get(0)
 
 		# extract computation code (remove MPI)
 		myEvents = ArrayList()
-		print "Filtering out MPI calls..."
+		print("Filtering out MPI calls...")
 		#print "And functions called less than 1000 times..."
 		for event in extracted.getEvents():
 			if not event.startswith("MPI_"):
@@ -115,14 +115,14 @@
 		extracted = extractor.processData().get(0)
 
 		# generate statistics
-		print "Generating stats..."
+		print("Generating stats...")
 		doStats = BasicStatisticsOperation(extracted, False)
 		mean = doStats.processData().get(BasicStatisticsOperation.MEAN)
 
 		for type in AbstractResult.EXCLUSIVE, AbstractResult.INCLUSIVE:
 
 			# get the top X events
-			print "Extracting top events..."
+			print("Extracting top events...")
 			mean.setIgnoreWarnings(True)
 			topper = TopXEvents(mean, mean.getTimeMetric(), type, threshold)
 			topped = topper.processData().get(0)
@@ -143,9 +143,9 @@
 				calls = topped.getCalls(0,event)
 				if calls < callsCutoff:
 					if calls == 0.0:
-						print "%00.2f%%\t %d\t %0.5f%%\t %s" % (percentage, calls, 0.0, shortEvent)
+						print("%00.2f%%\t %d\t %0.5f%%\t %s" % (percentage, calls, 0.0, shortEvent))
 					else:
-						print "%00.2f%%\t %d\t %0.5f%%\t %s" % (percentage, calls, percentage / float(calls), shortEvent)
+						print("%00.2f%%\t %d\t %0.5f%%\t %s" % (percentage, calls, percentage / float(calls), shortEvent))
 	
 					functionSet.add(shortEvent)
 	myFile = open(functions, 'w')
@@ -153,7 +153,7 @@
 		myFile.write(shortEvent + "\n")
 	myFile.close()
 
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/examples/Correlation/autotuning.py	(original)
--- b/tools/src/perfexplorer/examples/Correlation/autotuning.py	(refactored)
@@ -45,7 +45,7 @@
 	grapher.processData()
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	global tauData
 	global prefix
@@ -68,7 +68,7 @@
 
 	# draw the graph
 	drawGraph(extracted)
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
     main()
--- a/tools/src/perfexplorer/examples/Correlation/phases.py	(original)
--- b/tools/src/perfexplorer/examples/Correlation/phases.py	(refactored)
@@ -19,16 +19,16 @@
 	tmp = parameterMap.get("tauData")
 	if tmp != None:
 		tauData = tmp
-		print "Performance data: " + tauData
+		print("Performance data: " + tauData)
 	else:
-		print "TAU profile data path not specified... using current directory of profile.x.x.x files."
+		print("TAU profile data path not specified... using current directory of profile.x.x.x files.")
 
 	tmp = parameterMap.get("prefix")
 	if tmp != None:
 		prefix = tmp
 	else:
-		print "Prefix not specified. Using default."
-	print "Prefix: " + prefix
+		print("Prefix not specified. Using default.")
+	print("Prefix: " + prefix)
 
 
 def loadFile(fileName):
@@ -45,7 +45,7 @@
 	return input
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	global tauData
 	global prefix
@@ -70,9 +70,9 @@
 
 	corr = CorrelationOperation(extracted)
 	mycorr = corr.processData().get(0)
-	print mycorr.getCorrelation()
+	print(mycorr.getCorrelation())
 
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
     main()
--- a/tools/src/perfexplorer/examples/DBSCANOperation/clusterTest.py	(original)
--- b/tools/src/perfexplorer/examples/DBSCANOperation/clusterTest.py	(refactored)
@@ -11,9 +11,9 @@
 	tmp = parameterMap.get("tauData")
 	if tmp != None:
 		tauData = tmp
-		print "Performance data: " + tauData
+		print("Performance data: " + tauData)
 	else:
-		print "TAU profile data path not specified... using current directory of profile.x.x.x files."
+		print("TAU profile data path not specified... using current directory of profile.x.x.x files.")
 
 def loadFile(fileName):
 	# load the trial
@@ -28,8 +28,8 @@
 
 def main():
 	global filename
-	print "--------------- JPython test script start ------------"
-	print "doing cluster test"
+	print("--------------- JPython test script start ------------")
+	print("doing cluster test")
 	# get the parameters
 	getParameters()
 	# load the data
@@ -63,8 +63,8 @@
 	# cluster the data - on calls!
 	clusterer = DBSCANOperation(reduced, metric, type, 1.0)
 	clusterResult = clusterer.processData()
-	print "Estimated value for k:", str(clusterResult.get(0).getThreads().size())
-	print "---------------- JPython test script end -------------"
+	print("Estimated value for k:", str(clusterResult.get(0).getThreads().size()))
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/examples/DeleteTrials/super.py	(original)
--- b/tools/src/perfexplorer/examples/DeleteTrials/super.py	(refactored)
@@ -21,10 +21,10 @@
 			continue
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	inputs = deleteFromDB()
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
     main()
--- a/tools/src/perfexplorer/examples/DrawGraph/graph.py	(original)
--- b/tools/src/perfexplorer/examples/DrawGraph/graph.py	(refactored)
@@ -63,7 +63,7 @@
 	grapher.processData()
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	inputs = loadFromFiles()
 
@@ -76,7 +76,7 @@
 	extracted = extractor.processData()
 
 	drawGraph(extracted)
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
     main()
--- a/tools/src/perfexplorer/examples/ExportData/export.py	(original)
--- b/tools/src/perfexplorer/examples/ExportData/export.py	(refactored)
@@ -74,10 +74,10 @@
 			f.write(str(means.getExclusive(0,event,metric)))
 			f.write('\"\n')
 	f.close()
-	print "Data written to export.csv"
+	print("Data written to export.csv")
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	inputs = loadFromFiles()
 
@@ -85,7 +85,7 @@
 	extracted = extract(inputs)
 
 	export(extracted)
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/examples/ExtractChildrenOperation/topXexclusive.py	(original)
--- b/tools/src/perfexplorer/examples/ExtractChildrenOperation/topXexclusive.py	(refactored)
@@ -25,21 +25,21 @@
 	tmp = parameterMap.get("tauData")
 	if tmp != None:
 		tauData = tmp
-		print "Performance data: " + tauData
+		print("Performance data: " + tauData)
 	else:
-		print "TAU profile data path not specified... using current directory of profile.x.x.x files."
+		print("TAU profile data path not specified... using current directory of profile.x.x.x files.")
 	tmp = parameterMap.get("fileName")
 	if tmp != None:
 		functions = tmp
-		print "Output filename: " + functions
+		print("Output filename: " + functions)
 	else:
-		print "Output filename not specified... using " + functions
+		print("Output filename not specified... using " + functions)
 	tmp = parameterMap.get("threshold")
 	if tmp != None:
 		threshold = int(tmp)
-		print "Threshold: " + str(threshold)
+		print("Threshold: " + str(threshold))
 	else:
-		print "Threshold not specified... using " + str(threshold)
+		print("Threshold not specified... using " + str(threshold))
 
 def loadFile(fileName):
 	global gprof
@@ -64,7 +64,7 @@
 	global threshold
 	global gprof
 
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 
 	# get the parameters
 	getParameters()
@@ -73,14 +73,14 @@
 	input = loadFile(tauData)
 
 	# extract the non-callpath data
-	print "Extracting non-callpath data..."
+	print("Extracting non-callpath data...")
 	input.setIgnoreWarnings(True)
 	extractor = ExtractNonCallpathEventOperation(input)
 	extracted = extractor.processData().get(0)
 
 	# extract computation code (remove MPI)
 	myEvents = ArrayList()
-	print "Filtering out MPI calls..."
+	print("Filtering out MPI calls...")
 	for event in extracted.getEvents():
 		if not event.startswith("MPI_"):
 			myEvents.add(event)
@@ -88,7 +88,7 @@
 	extracted = extractor.processData().get(0)
 
 	# generate statistics
-	print "Generating stats..."
+	print("Generating stats...")
 	doStats = BasicStatisticsOperation(extracted, False) 
 	mean = doStats.processData().get(BasicStatisticsOperation.MEAN)
 
@@ -97,7 +97,7 @@
 
 	for type in [AbstractResult.EXCLUSIVE, AbstractResult.INCLUSIVE]:
 		# get the top X events
-		print "Extracting top events..."
+		print("Extracting top events...")
 		mean.setIgnoreWarnings(True)
 		topper = TopXEvents(mean, mean.getTimeMetric(), type, threshold) 
 		topped = topper.processData().get(0)
@@ -113,12 +113,12 @@
 			# fix TAU names
 			else:
 				shortEvent = Utilities.shortenEventName(event)
-			print "%00.2f%%\t %d\t %s" % (topped.getDataPoint(0,event,topped.getTimeMetric(), type) / mean.getInclusive(0,mean.getMainEvent(),mean.getTimeMetric()) * 100.0, mean.getCalls(0,event), shortEvent)
+			print("%00.2f%%\t %d\t %s" % (topped.getDataPoint(0,event,topped.getTimeMetric(), type) / mean.getInclusive(0,mean.getMainEvent(),mean.getTimeMetric()) * 100.0, mean.getCalls(0,event), shortEvent))
 			myFile.write(shortEvent + "\n")
 
 	myFile.close()
 
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/examples/ExtractChildrenOperation/topXofParent.py	(original)
--- b/tools/src/perfexplorer/examples/ExtractChildrenOperation/topXofParent.py	(refactored)
@@ -25,27 +25,27 @@
 	tmp = parameterMap.get("tauData")
 	if tmp != None:
 		tauData = tmp
-		print "Performance data: " + tauData
+		print("Performance data: " + tauData)
 	else:
-		print "TAU profile data path not specified... using current directory of profile.x.x.x files."
+		print("TAU profile data path not specified... using current directory of profile.x.x.x files.")
 	tmp = parameterMap.get("fileName")
 	if tmp != None:
 		functions = tmp
-		print "Output filename: " + functions
+		print("Output filename: " + functions)
 	else:
-		print "Output filename not specified... using " + functions
+		print("Output filename not specified... using " + functions)
 	tmp = parameterMap.get("threshold")
 	if tmp != None:
 		threshold = int(tmp)
-		print "Threshold: " + str(threshold)
+		print("Threshold: " + str(threshold))
 	else:
-		print "Threshold not specified... using " + str(threshold)
+		print("Threshold not specified... using " + str(threshold))
 	tmp = parameterMap.get("parent")
 	if tmp != None:
 		parent = tmp
-		print "Parent function: " + functions
+		print("Parent function: " + functions)
 	else:
-		print "Parent not specified... exiting. "
+		print("Parent not specified... exiting. ")
 		System.exit(1)
 
 def loadFile(fileName):
@@ -69,7 +69,7 @@
 	global threshold
 	global gprof
 
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 
 	# get the parameters
 	getParameters()
@@ -78,14 +78,14 @@
 	input = loadFile(tauData)
 
 	# extract the non-callpath data
-	print "Extracting children of", parent, "..."
+	print("Extracting children of", parent, "...")
 	input.setIgnoreWarnings(True)
 	extractor = ExtractChildrenOperation(input, parent)
 	extracted = extractor.processData().get(0)
 
 	# extract computation code (remove MPI)
 	myEvents = ArrayList()
-	print "Filtering out MPI calls..."
+	print("Filtering out MPI calls...")
 	for event in extracted.getEvents():
 		if not event.startswith("MPI_"):
 			myEvents.add(event)
@@ -93,7 +93,7 @@
 	extracted = extractor.processData().get(0)
 
 	# generate statistics
-	print "Generating stats..."
+	print("Generating stats...")
 	doStats = BasicStatisticsOperation(extracted, False) 
 	mean = doStats.processData().get(BasicStatisticsOperation.MEAN)
 	doStats = BasicStatisticsOperation(input, False) 
@@ -101,7 +101,7 @@
 	meanTotal = fullMean.getInclusive(0,fullMean.getMainEvent(),fullMean.getTimeMetric())
 
 	# get the top X events
-	print "Extracting top events by INCLUSIVE value..."
+	print("Extracting top events by INCLUSIVE value...")
 	mean.setIgnoreWarnings(True)
 	topper = TopXEvents(mean, mean.getTimeMetric(), AbstractResult.INCLUSIVE, threshold) 
 	topped = topper.processData().get(0)
@@ -126,11 +126,11 @@
 		# fix TAU names
 		else:
 			shortEvent = Utilities.shortenEventName(event)
-		print "%00.2f%%\t %s" % (topped.getInclusive(0,event,topped.getTimeMetric()) / meanTotal * 100.0, event)
+		print("%00.2f%%\t %s" % (topped.getInclusive(0,event,topped.getTimeMetric()) / meanTotal * 100.0, event))
 		myFile.write(shortEvent + "\n")
 	myFile.close()
 
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/examples/GetTrialsFromDatabase/graph.py	(original)
--- b/tools/src/perfexplorer/examples/GetTrialsFromDatabase/graph.py	(refactored)
@@ -45,12 +45,12 @@
 	grapher.processData()
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	inputs = loadFromDB()
 
 	drawGraph(inputs)
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
     main()
--- a/tools/src/perfexplorer/examples/GetTrialsFromDatabase/graph2.py	(original)
--- b/tools/src/perfexplorer/examples/GetTrialsFromDatabase/graph2.py	(refactored)
@@ -50,12 +50,12 @@
 	grapher.processData()
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	inputs = loadFromDB()
 
 	drawGraph(inputs)
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
     main()
--- a/tools/src/perfexplorer/examples/GetTrialsFromDatabase/super.py	(original)
--- b/tools/src/perfexplorer/examples/GetTrialsFromDatabase/super.py	(refactored)
@@ -58,7 +58,7 @@
 	grapher.processData()
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	inputs = loadFromDB()
 
@@ -70,7 +70,7 @@
 	"""
 
 	drawGraph(inputs)
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
     main()
--- a/tools/src/perfexplorer/examples/GetTrialsFromDatabase/super2.py	(original)
--- b/tools/src/perfexplorer/examples/GetTrialsFromDatabase/super2.py	(refactored)
@@ -20,7 +20,7 @@
 	metrics = ArrayList()
 	metrics.add("WALL_CLOCK_TIME")
 	baseline = TrialMeanResult(trials.get(0), None, None, False)
-	print baseline.getOriginalThreads()
+	print(baseline.getOriginalThreads())
 	extractor = TopXEvents(baseline, metrics.get(0), AbstractResult.INCLUSIVE, 1)
 	topx = extractor.processData().get(0)
 	inputs = ArrayList()
@@ -57,12 +57,12 @@
 	grapher.processData()
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	inputs = loadFromDB()
 
 	drawGraph(inputs)
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
     main()
--- a/tools/src/perfexplorer/examples/HardwareCounterBasicAnalysis/getTopX.py	(original)
--- b/tools/src/perfexplorer/examples/HardwareCounterBasicAnalysis/getTopX.py	(refactored)
@@ -19,7 +19,7 @@
 	# extract computation code (remove MPI)
 	if filterMPI:
 		myEvents = ArrayList()
-		print "Filtering out MPI calls..."
+		print("Filtering out MPI calls...")
 		for event in inTrial.getEvents():
 			if not event.startswith("MPI_"):
 				myEvents.add(event)
@@ -30,7 +30,7 @@
 	myEvents = ArrayList()
 
 	# get the top X events
-	print "Extracting top events..."
+	print("Extracting top events...")
 	extracted.setIgnoreWarnings(True)
 	if metric is None:
 		metric = extracted.getTimeMetric()
@@ -44,6 +44,6 @@
 		if tmp > 0:
 			exclusivePercent = topped.getDataPoint(0,event,metric, timerType) / tmp * 100.0
 		if (exclusivePercent > 1.0):
-			print "%00.2f%%\t %d\t %s" % (exclusivePercent, extracted.getCalls(0,event), shortEvent)
+			print("%00.2f%%\t %d\t %s" % (exclusivePercent, extracted.getCalls(0,event), shortEvent))
 			myEvents.add(event)
 	return myEvents
--- a/tools/src/perfexplorer/examples/HardwareCounterBasicAnalysis/parsetrial.py	(original)
--- b/tools/src/perfexplorer/examples/HardwareCounterBasicAnalysis/parsetrial.py	(refactored)
@@ -6,10 +6,10 @@
 	Utilities.setSession("local")
 	files = []
 	files.append(inputData)
-	print "Parsing files:", files, "..."
+	print("Parsing files:", files, "...")
 	trial = DataSourceResult(DataSourceResult.PPK, files, False)
 	trial.setIgnoreWarnings(True)
-	print "Computing stats..."
+	print("Computing stats...")
 	stats = BasicStatisticsOperation(trial)
 	mean = stats.processData().get(BasicStatisticsOperation.MEAN)
 	extractor = ExtractNonCallpathEventOperation(mean)
--- a/tools/src/perfexplorer/examples/HardwareCounterBasicAnalysis/process.py	(original)
--- b/tools/src/perfexplorer/examples/HardwareCounterBasicAnalysis/process.py	(refactored)
@@ -60,17 +60,17 @@
 	inTrial.setIgnoreWarnings(True)
 
 	mainEvent = inTrial.getMainEvent()
-	print "Main Event:", mainEvent
+	print("Main Event:", mainEvent)
 
 	#metadata = TrialThreadMetadata(inTrial)
 	#for name in metadata.getFields():
 	#	print name, ":", metadata.getNameValue(0,name)
 
 	# cpuMHz = metadata.getNameValue(0,"CPU MHz")
-	print "Using CPU MHz", cpuMHz
+	print("Using CPU MHz", cpuMHz)
 
 	for metric in inTrial.getMetrics():
-		print "Found Metric:", metric
+		print("Found Metric:", metric)
 
 	return inTrial
 
@@ -78,7 +78,7 @@
 	global cpuMHz
 	global mainEvent
 	# derive the Cycles 
-	print "Computing Cycles from TIME..."
+	print("Computing Cycles from TIME...")
 	deriver = ScaleMetricOperation(inTrial, cpuMHz, "TIME", DeriveMetricOperation.MULTIPLY)
 	deriver.setNewName("PAPI_TOT_CYC")
 	tmp = deriver.processData();
@@ -86,12 +86,12 @@
 	merger = MergeTrialsOperation(tmp)
 	merged = merger.processData().get(0)
 
-	print "Computing Cycles per Instruction..."
+	print("Computing Cycles per Instruction...")
 	deriver  = DeriveMetricOperation(merged, "PAPI_TOT_CYC", "PAPI_TOT_INS", DeriveMetricOperation.DIVIDE)
 	deriver.setNewName("TOT_CYC/TOT_INS")
 	tmp = deriver.processData()
 
-	print "Computing FLOPs per Instruction..."
+	print("Computing FLOPs per Instruction...")
 	deriver  = DeriveMetricOperation(merged, "PAPI_FP_INS", "PAPI_TOT_INS", DeriveMetricOperation.DIVIDE)
 	deriver.setNewName("FP_INS/TOT_INS")
 	tmp2 = deriver.processData().get(0)
@@ -99,12 +99,12 @@
 	deriver.setNewName("% FP_INS ")
 	tmp.add(deriver.processData().get(0))
 
-	print "Computing Branch Mispredictions per Instruction..."
+	print("Computing Branch Mispredictions per Instruction...")
 	deriver  = DeriveMetricOperation(merged, "PAPI_BR_MSP", "PAPI_TOT_INS", DeriveMetricOperation.DIVIDE)
 	deriver.setNewName("BR_MSP/TOT_INS")
 	tmp.add(deriver.processData().get(0))
 
-	print "Computing Cache Misses per Instruction..."
+	print("Computing Cache Misses per Instruction...")
 	deriver  = DeriveMetricOperation(merged, "PAPI_" + cacheMissMetric, "PAPI_TOT_INS", DeriveMetricOperation.DIVIDE)
 	deriver.setNewName(cacheMissMetric + "/TOT_INS")
 	tmp.add(deriver.processData().get(0))
@@ -112,7 +112,7 @@
 	merged = merger.processData().get(0)
 
 	for metric in merged.getMetrics():
-		print "Found Metric:", metric, merged.getInclusive(0,mainEvent,metric)
+		print("Found Metric:", metric, merged.getInclusive(0,mainEvent,metric))
 
 	return merged
 
@@ -122,14 +122,14 @@
 	global mainEvent
 	for metric in derived.getMetrics():
 		mainValue = derived.getInclusive(0,mainEvent,metric)
-		print "\n===", metric, "( ", mainValue, ") ==="
+		print("\n===", metric, "( ", mainValue, ") ===")
 		for event in events:
 			shortName = Utilities.shortenEventName(event)
 			eventValue = derived.getExclusive(0,event,metric)
 			tmp = 1.0
 			if mainValue > 0:
 				tmp = eventValue/mainValue
-			print "%s\t%0.3f\t%00.2f%%" % (shortName, eventValue, (tmp * 100.0))
+			print("%s\t%0.3f\t%00.2f%%" % (shortName, eventValue, (tmp * 100.0)))
 
 #########################################################################################
 
@@ -142,7 +142,7 @@
 	fact = FactWrapper("Overall", "CPI Stack", cpiStack)
 	handle = ruleHarness.assertObject(fact)
 	fact.setFactHandle(handle)
-	print verbose
+	print(verbose)
 	if verbose == "yes":
 		factDebug = FactWrapper("Dump CPI", "CPI Stack", cpiStack)
 		handleDebug = ruleHarness.assertObject(factDebug)
@@ -156,63 +156,63 @@
 	global mainEvent
 	index = 1
 	for event in events:
-		print index, Utilities.shortenEventName(event)
+		print(index, Utilities.shortenEventName(event))
 		index = index + 1
-	print ""
+	print("")
 
 	index = 1
-	print "Timer",
+	print("Timer", end=' ')
 	for metric in raw.getMetrics():
-		print "\t", metric,
-	print ""
+		print("\t", metric, end=' ')
+	print("")
 	for event in events:
-		print index, "\t",
+		print(index, "\t", end=' ')
 		for metric in raw.getMetrics():
 			value = raw.getExclusive(0,event,metric) / raw.getInclusive(0,mainEvent,metric)
 			if value < 0.1:
-				print " %0.2f %%\t\t" % ((value * 100.0)),
+				print(" %0.2f %%\t\t" % ((value * 100.0)), end=' ')
 			else:
-				print "%0.2f %%\t\t" % ((value * 100.0)),
+				print("%0.2f %%\t\t" % ((value * 100.0)), end=' ')
 		index = index + 1
-		print ""
-	print ""
-
-	print "Timer",
+		print("")
+	print("")
+
+	print("Timer", end=' ')
 	for metric in derived.getMetrics():
-		print "\t", metric,
-	print ""
+		print("\t", metric, end=' ')
+	print("")
 
 	index = 1
 	for event in events:
-		print index, "\t",
+		print(index, "\t", end=' ')
 		for metric in derived.getMetrics():
 			value = derived.getExclusive(0,event,metric)
 			if "%" in metric:
 				if value < 10.0:
-					print " %0.2f %%\t\t" % (value),
+					print(" %0.2f %%\t\t" % (value), end=' ')
 				else:
-					print "%0.2f %%\t\t" % (value),
+					print("%0.2f %%\t\t" % (value), end=' ')
 			else:
-				print "%0.5f\t\t" % (value),
+				print("%0.5f\t\t" % (value), end=' ')
 		index = index + 1
-		print ""
-
-	print "Avg.\t",
+		print("")
+
+	print("Avg.\t", end=' ')
 	for metric in derived.getMetrics():
 		value = derived.getInclusive(0,mainEvent,metric)
 		if "%" in metric:
 			if value < 10.0:
-				print " %0.2f %%\t\t" % (value),
+				print(" %0.2f %%\t\t" % (value), end=' ')
 			else:
-				print "%0.2f %%\t\t" % (value),
+				print("%0.2f %%\t\t" % (value), end=' ')
 		else:
-			print "%0.5f\t\t" % (value),
-	print "\n"
+			print("%0.5f\t\t" % (value), end=' ')
+	print("\n")
 
 #########################################################################################
 
 def main(argv):
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	getParameters()
 	global fractionThreshold
 	inTrial = initialize(inputData)
@@ -221,15 +221,15 @@
 	derived = computeDerivedMetrics(inTrial)
 	dump(inTrial, derived, topXevents)
 	checkRatios(derived, topXevents)
-	print "\n--- Examining Time Top Events ---"
+	print("\n--- Examining Time Top Events ---")
 	topXevents = getTopX.getTopX(inTrial, 10, AbstractResult.EXCLUSIVE, "TIME", False)
-	print "\n--- Examining", cacheMissMetric, "Top Events ---"
+	print("\n--- Examining", cacheMissMetric, "Top Events ---")
 	topXevents = getTopX.getTopX(inTrial, 10, AbstractResult.EXCLUSIVE, "PAPI_" + cacheMissMetric)
-	print "\n--- Examining BR MSP Top Events ---"
+	print("\n--- Examining BR MSP Top Events ---")
 	topXevents = getTopX.getTopX(inTrial, 10, AbstractResult.EXCLUSIVE, "PAPI_BR_MSP")
-	print "\n--- Examining FP INS Top Events ---"
+	print("\n--- Examining FP INS Top Events ---")
 	topXevents = getTopX.getTopX(inTrial, 10, AbstractResult.EXCLUSIVE, "PAPI_FP_INS")
-	print "\n---------------- JPython test script end -------------"
+	print("\n---------------- JPython test script end -------------")
 
 #########################################################################################
 
--- a/tools/src/perfexplorer/examples/HardwareCounterBasicAnalysis/samples.py	(original)
--- b/tools/src/perfexplorer/examples/HardwareCounterBasicAnalysis/samples.py	(refactored)
@@ -10,7 +10,7 @@
 def preProcessSamples(inTrial):
 	# keep the main timer
 	mainEvent = inTrial.getMainEvent()
-	print "Pre-processing Samples..."
+	print("Pre-processing Samples...")
 	haveSamples = False
 	aggregators = ArrayList()
 	newEvents = DefaultResult(inTrial)
--- a/tools/src/perfexplorer/examples/HeatMapSamples/heatmap.py	(original)
--- b/tools/src/perfexplorer/examples/HeatMapSamples/heatmap.py	(refactored)
@@ -42,7 +42,7 @@
 	Utilities.setSession("local")
 	files = []
 	files.append(inputData)
-	print "Parsing files:", files, "..."
+	print("Parsing files:", files, "...")
 	trial = DataSourceResult(DataSourceResult.PPK, files, False)
 	mainEvent = trial.getMainEvent()
 	trial.setIgnoreWarnings(True)
@@ -58,7 +58,7 @@
 	# extract computation code (remove MPI)
 	if filterMPI:
 		myEvents = ArrayList()
-		print "Filtering out MPI calls..."
+		print("Filtering out MPI calls...")
 		for event in inTrial.getEvents():
 			if not event.startswith("MPI_"):
 				myEvents.add(event)
@@ -69,7 +69,7 @@
 	myEvents = ArrayList()
 
 	# get the top X events
-	print "Extracting top events..."
+	print("Extracting top events...")
 	extracted.setIgnoreWarnings(True)
 	if metric is None:
 		metric = extracted.getTimeMetric()
@@ -80,7 +80,7 @@
 		shortEvent = Utilities.shortenEventName(event)
 		exclusivePercent = topped.getDataPoint(0,event,metric, timerType) / extracted.getInclusive(0,extracted.getMainEvent(),metric) * 100.0
 		if (exclusivePercent > 1.0):
-			print "%00.2f%%\t %d\t %s" % (exclusivePercent, extracted.getCalls(0,event), shortEvent)
+			print("%00.2f%%\t %d\t %s" % (exclusivePercent, extracted.getCalls(0,event), shortEvent))
 			myEvents.add(event)
 	return myEvents
 #########################################################################################
@@ -90,7 +90,7 @@
 	parameterMap = PerfExplorerModel.getModel().getScriptParameters()
 	keys = parameterMap.keySet()
 	for key in keys:
-		print key, parameterMap.get(key)
+		print(key, parameterMap.get(key))
 	inputData = parameterMap.get("inputData")
 
 #########################################################################################
@@ -98,15 +98,15 @@
 def initialize(inputData):
 	global cpuMHz
 	global mainEvent
-	print "Parsing: ", inputData
+	print("Parsing: ", inputData)
 	inTrial = parsetrial(inputData)
 	inTrial.setIgnoreWarnings(True)
 
 	#mainEvent = inTrial.getMainEvent()
-	print "Main Event:", mainEvent
+	print("Main Event:", mainEvent)
 
 	for metric in inTrial.getMetrics():
-		print "Found Metric:", metric
+		print("Found Metric:", metric)
 
 	return inTrial
 
@@ -114,7 +114,7 @@
 	global cpuMHz
 	global mainEvent
 	# derive the Cycles 
-	print "Computing Cycles from TIME..."
+	print("Computing Cycles from TIME...")
 	deriver = ScaleMetricOperation(inTrial, cpuMHz, "TIME", DeriveMetricOperation.MULTIPLY)
 	deriver.setNewName("PAPI_TOT_CYC")
 	tmp = deriver.processData();
@@ -122,12 +122,12 @@
 	merger = MergeTrialsOperation(tmp)
 	merged = merger.processData().get(0)
 
-	print "Computing Cycles per Instruction..."
+	print("Computing Cycles per Instruction...")
 	deriver  = DeriveMetricOperation(merged, "PAPI_TOT_CYC", "PAPI_TOT_INS", DeriveMetricOperation.DIVIDE)
 	deriver.setNewName("TOT_CYC/TOT_INS")
 	tmp = deriver.processData()
 
-	print "Computing FLOPs per Instruction..."
+	print("Computing FLOPs per Instruction...")
 	deriver  = DeriveMetricOperation(merged, "PAPI_FP_INS", "PAPI_TOT_INS", DeriveMetricOperation.DIVIDE)
 	deriver.setNewName("FP_INS/TOT_INS")
 	tmp2 = deriver.processData().get(0)
@@ -140,7 +140,7 @@
 	#deriver.setNewName("BR_MSP/TOT_INS")
 	#tmp.add(deriver.processData().get(0))
 
-	print "Computing Cache Misses per Instruction..."
+	print("Computing Cache Misses per Instruction...")
 	deriver  = DeriveMetricOperation(merged, "PAPI_L1_TCM", "PAPI_TOT_INS", DeriveMetricOperation.DIVIDE)
 	deriver.setNewName("L1_TCM/TOT_INS")
 	tmp.add(deriver.processData().get(0))
@@ -148,7 +148,7 @@
 	merged = merger.processData().get(0)
 
 	for metric in merged.getMetrics():
-		print "Found Metric:", metric, merged.getInclusive(0,mainEvent,metric)
+		print("Found Metric:", metric, merged.getInclusive(0,mainEvent,metric))
 
 	return merged
 
@@ -158,11 +158,11 @@
 	global mainEvent
 	for metric in derived.getMetrics():
 		mainValue = derived.getInclusive(0,mainEvent,metric)
-		print "===", metric, "( ", mainValue, ") ==="
+		print("===", metric, "( ", mainValue, ") ===")
 		for event in events:
 			shortName = Utilities.shortenEventName(event)
 			eventValue = derived.getExclusive(0,event,metric)
-			print "%s\t%0.3f\t%00.2f%%" % (shortName, eventValue, ((eventValue / mainValue) * 100.0))
+			print("%s\t%0.3f\t%00.2f%%" % (shortName, eventValue, ((eventValue / mainValue) * 100.0)))
 
 #########################################################################################
 
@@ -170,77 +170,77 @@
 	global mainEvent
 	index = 1
 	for event in events:
-		print index, Utilities.shortenEventName(event)
+		print(index, Utilities.shortenEventName(event))
 		index = index + 1
-	print ""
+	print("")
 
 	index = 1
-	print "Timer",
+	print("Timer", end=' ')
 	for metric in raw.getMetrics():
-		print "\t", metric,
-	print ""
+		print("\t", metric, end=' ')
+	print("")
 	for event in events:
-		print index, "\t",
+		print(index, "\t", end=' ')
 		for metric in raw.getMetrics():
 			value = raw.getExclusive(0,event,metric) / raw.getInclusive(0,mainEvent,metric)
 			if value < 0.1:
-				print " %0.2f %%\t\t" % ((value * 100.0)),
+				print(" %0.2f %%\t\t" % ((value * 100.0)), end=' ')
 			else:
-				print "%0.2f %%\t\t" % ((value * 100.0)),
+				print("%0.2f %%\t\t" % ((value * 100.0)), end=' ')
 		index = index + 1
-		print ""
-	print ""
-
-	print "Timer",
+		print("")
+	print("")
+
+	print("Timer", end=' ')
 	for metric in derived.getMetrics():
-		print "\t", metric,
-	print ""
+		print("\t", metric, end=' ')
+	print("")
 
 	index = 1
 	for event in events:
-		print index, "\t",
+		print(index, "\t", end=' ')
 		for metric in derived.getMetrics():
 			value = derived.getExclusive(0,event,metric)
 			if "%" in metric:
 				if value < 10.0:
-					print " %0.2f %%\t\t" % (value),
+					print(" %0.2f %%\t\t" % (value), end=' ')
 				else:
-					print "%0.2f %%\t\t" % (value),
+					print("%0.2f %%\t\t" % (value), end=' ')
 			else:
-				print "%0.5f\t\t" % (value),
+				print("%0.5f\t\t" % (value), end=' ')
 		index = index + 1
-		print ""
-
-	print "Avg.\t",
+		print("")
+
+	print("Avg.\t", end=' ')
 	for metric in derived.getMetrics():
 		value = derived.getInclusive(0,mainEvent,metric)
 		if "%" in metric:
 			if value < 10.0:
-				print " %0.2f %%\t\t" % (value),
+				print(" %0.2f %%\t\t" % (value), end=' ')
 			else:
-				print "%0.2f %%\t\t" % (value),
+				print("%0.2f %%\t\t" % (value), end=' ')
 		else:
-			print "%0.5f\t\t" % (value),
-	print "\n"
+			print("%0.5f\t\t" % (value), end=' ')
+	print("\n")
 
 #########################################################################################
 
 def main(argv):
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	getParameters()
 	global fractionThreshold
 	global inputData
 	inTrial = initialize(inputData)
-	print "Making basic stats..."
+	print("Making basic stats...")
 	statmaker = BasicStatisticsOperation(inTrial)
 	stats = statmaker.processData().get(BasicStatisticsOperation.MEAN)
-	print "Extracting Flat Profile..."
+	print("Extracting Flat Profile...")
 	extractor = ExtractNonCallpathEventOperation(stats)
 	flat = extractor.processData().get(0)
-	print "Extracting Callpath Profile..."
+	print("Extracting Callpath Profile...")
 	extractor = ExtractCallpathEventOperation(stats)
 	callpath = extractor.processData().get(0)
-	print "Finding CONTEXT events..."
+	print("Finding CONTEXT events...")
 	contexts = ArrayList()
 	samples = ArrayList()
 	for event in flat.getEvents():
@@ -264,7 +264,7 @@
 	gp.write('set ylabel "SAMPLES"\n')
 	gp.write('set tic scale 0\n')
 	gp.write('set palette rgbformulae 22,13,10\n')
-	print "contexts:", contexts.size()
+	print("contexts:", contexts.size())
 	gp.write("set xtics (")
 	for i in range(contexts.size()):
 		if i > 0:
@@ -272,7 +272,7 @@
 		a = Utilities.shortenEventName(contexts[i]).replace("[CONTEXT] ","")
 		gp.write("\"%s\" %d" % (a, i))
 	gp.write(") rotate by 45 right\n\n")
-	print "samples:", samples.size()
+	print("samples:", samples.size())
 	gp.write("set ytics (")
 	for i in range(samples.size()):
 		if i > 0:
--- a/tools/src/perfexplorer/examples/LoadImbalance/loadImbalanceCauses.py	(original)
--- b/tools/src/perfexplorer/examples/LoadImbalance/loadImbalanceCauses.py	(refactored)
@@ -17,16 +17,16 @@
 	tmp = parameterMap.get("tauData")
 	if tmp != None:
 		tauData = tmp
-		print "Performance data: " + tauData
+		print("Performance data: " + tauData)
 	else:
-		print "TAU profile data path not specified... using current directory of profile.x.x.x files."
+		print("TAU profile data path not specified... using current directory of profile.x.x.x files.")
 
 	tmp = parameterMap.get("rules")
 	if tmp != None:
 		ruleFile = tmp
 	else:
-		print "Rule file not specified. Using default."
-	print "Rules: " + ruleFile
+		print("Rule file not specified. Using default.")
+	print("Rules: " + ruleFile)
 
 
 def loadFile(fileName):
@@ -47,18 +47,18 @@
 def main():
 	global tauData
 	global ruleFile
-	print "--------------- JPython test script start ------------"
-	print "--- Looking for load imbalances --- "
+	print("--------------- JPython test script start ------------")
+	print("--- Looking for load imbalances --- ")
 
 	# get the parameters
 	getParameters()
 
 	# create a rulebase for processing
-	print "Loading Rules..."
+	print("Loading Rules...")
 	ruleHarness = RuleHarness.useGlobalRules(ruleFile)
 
 	# load the trial
-	print "loading the data..."
+	print("loading the data...")
 
 	# load the data
 	trial = loadFile(tauData)
@@ -78,7 +78,7 @@
 	maxs = stats.get(BasicStatisticsOperation.MAX)
 	totals = stats.get(BasicStatisticsOperation.TOTAL)
 	mainEvent = means.getMainEvent()
-	print "Main Event: ", mainEvent
+	print("Main Event: ", mainEvent)
 
 	# get the ratio between average and max
 	ratioMaker = RatioOperation(means, maxs)
@@ -89,7 +89,7 @@
 	for event in ratios.getEvents():
 		for metric in ratios.getMetrics():
 			MeanEventFact.evaluateLoadBalance(means, ratios, event, metric)
-	print
+	print()
 
 	# add the callpath event names to the facts in the rulebase.
 
@@ -103,7 +103,7 @@
 	# process the rules
 	RuleHarness.getInstance().processRules()
 
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 
 if __name__ == "__main__":
--- a/tools/src/perfexplorer/examples/LoadImbalance/loadimbalance.py	(original)
--- b/tools/src/perfexplorer/examples/LoadImbalance/loadimbalance.py	(refactored)
@@ -29,11 +29,11 @@
 
 ###################################################################
 
-print "--------------- JPython test script start ------------"
-print "--- Looking for load imbalances --- "
+print("--------------- JPython test script start ------------")
+print("--- Looking for load imbalances --- ")
 
 # load the trial
-print "loading the data..."
+print("loading the data...")
 
 Utilities.setSession("local")
 trials = ArrayList()
@@ -42,7 +42,7 @@
 	files.append(str(i) + ".ppk")
 	trials.add(DataSourceResult(DataSourceResult.PPK, files, False))
 
-print "Procs\t Type\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX"
+print("Procs\t Type\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX")
 
 ratioList = ArrayList()
 meanList = ArrayList()
@@ -79,7 +79,7 @@
 	stddev = stddevs.getExclusive(thread, event, metric)
 	ratio = ratios.getExclusive(thread, event, metric)
 
-	print "%d\t %s\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % (trial.getThreads().size(), event, mean*100, max*100, min*100, stddev*100, ratio*100)
+	print("%d\t %s\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % (trial.getThreads().size(), event, mean*100, max*100, min*100, stddev*100, ratio*100))
 
 	ratioList.add(ratios)
 	meanList.add(means)
@@ -87,7 +87,7 @@
 	minList.add(mins)
 	stddevList.add(stddevs)
 
-print
+print()
 
 # graph the ratios, showing the inefficiency as the app scales
 
@@ -97,4 +97,4 @@
 drawit(meanList, "Mean (AVG), 1.0 is better", "Mean")
 drawit(ratioList, "Load Balance (AVG/MAX), 1.0 is better", "Load Balance")
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/examples/MergedExperimentsChart/graph.py	(original)
--- b/tools/src/perfexplorer/examples/MergedExperimentsChart/graph.py	(refactored)
@@ -74,7 +74,7 @@
 	grapher.processData()
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	#inputs = loadFromFiles()
 	inputs = loadFromDB()
@@ -104,7 +104,7 @@
                 			before.putInclusive(thread, event + " : blocksize 10", metric, after.getInclusive(thread, event, metric))
 
 	drawGraph(extracted)
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
     main()
--- a/tools/src/perfexplorer/examples/MetadataCorrelation/correlate.py	(original)
--- b/tools/src/perfexplorer/examples/MetadataCorrelation/correlate.py	(refactored)
@@ -21,9 +21,9 @@
 	tmp = parameterMap.get("tauData")
 	if tmp != None:
 		tauData = tmp
-		print "Performance data: " + tauData
+		print("Performance data: " + tauData)
 	else:
-		print "TAU profile data path not specified... using current directory of profile.x.x.x files."
+		print("TAU profile data path not specified... using current directory of profile.x.x.x files.")
 
 def loadFile(fileName):
 	# load the trial
@@ -111,7 +111,7 @@
 	neighbors.close()
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	global tauData
 	global path
@@ -156,7 +156,7 @@
 
 	dumpData(inputData, metadata)
 
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/examples/MicroLoadImbalance/loadimbalanceTime.py	(original)
--- b/tools/src/perfexplorer/examples/MicroLoadImbalance/loadimbalanceTime.py	(refactored)
@@ -30,18 +30,18 @@
 
 ###################################################################
 
-print "--------------- JPython test script start ------------"
-print "--- Looking for load imbalances --- "
+print("--------------- JPython test script start ------------")
+print("--- Looking for load imbalances --- ")
 
 # load the trial
-print "loading the data..."
+print("loading the data...")
 
 Utilities.setSession("local")
 files = []
 files.append("justtime.ppk")
 trial = DataSourceResult(DataSourceResult.PPK, files, False)
 
-print "\nProcs\t Type\t\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX"
+print("\nProcs\t Type\t\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX")
 
 trial.setIgnoreWarnings(True)
 
@@ -149,23 +149,23 @@
 min = mins.getExclusive(thread, event, metric)
 stddev = stddevs.getExclusive(thread, event, metric)
 ratio = ratios.getExclusive(thread, event, metric)
-print "%d\t %s\t\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%" % (trial.getThreads().size(), event, mean*100, max*100, min*100, stddev*100, ratio*100)
+print("%d\t %s\t\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%" % (trial.getThreads().size(), event, mean*100, max*100, min*100, stddev*100, ratio*100))
 event = kernNonMPI
 mean = means.getExclusive(thread, event, metric)
 max = maxs.getExclusive(thread, event, metric)
 min = mins.getExclusive(thread, event, metric)
 stddev = stddevs.getExclusive(thread, event, metric)
 ratio = ratios.getExclusive(thread, event, metric)
-print "%d\t %s\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\n" % (trial.getThreads().size(), event, mean*100, max*100, min*100, stddev*100, ratio*100)
-print "Communication Efficiency (kernel only):\t%.3f" % max
-print "Load Balance (kernel only):\t\t%.3f" % ratio
+print("%d\t %s\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\n" % (trial.getThreads().size(), event, mean*100, max*100, min*100, stddev*100, ratio*100))
+print("Communication Efficiency (kernel only):\t%.3f" % max)
+print("Load Balance (kernel only):\t\t%.3f" % ratio)
 #print "Average IPC (kernel only):\t\t%.10f" % kernAvgIPC
-print "Total Instructions(kernel only):\t%.3f" % kernAvgInstructions
-
-print "\nNext Step: Computing Micro Load Imbalance.\n"
-
-
-print "Searching for loop events..."
+print("Total Instructions(kernel only):\t%.3f" % kernAvgInstructions)
+
+print("\nNext Step: Computing Micro Load Imbalance.\n")
+
+
+print("Searching for loop events...")
 # get a list of the loop names
 metric = "TIME"
 loopPrefix = "loop ["
@@ -175,12 +175,12 @@
 	if event.find(loopPrefix) > -1:
 		loopNames.add(event)
 
-print "Extracting callpath events..."
+print("Extracting callpath events...")
 # extract the callpath events
 extractor = ExtractCallpathEventOperation(trial)
 extracted = extractor.processData().get(0)
 
-print "Generating Statistics..."
+print("Generating Statistics...")
 statMaker = BasicStatisticsOperation(extracted, False)
 stats = statMaker.processData()
 stddevs = stats.get(BasicStatisticsOperation.STDDEV)
@@ -189,8 +189,8 @@
 maxs = stats.get(BasicStatisticsOperation.MAX)
 mins = stats.get(BasicStatisticsOperation.MIN)
 
-print "Iterating over main loop..."
-print "Loop ID:\t RealCommEff\t uLB\t\t CommEff"
+print("Iterating over main loop...")
+print("Loop ID:\t RealCommEff\t uLB\t\t CommEff")
 # iterate over the iterations
 totalLoopTimeIdeal = 0
 totalLoopTime = 0
@@ -214,7 +214,7 @@
 	realCommEff = loopTimeIdeal / loopTime
 	uLB = loopTimeIdeal / maxTi
 	commEff = realCommEff * uLB
-	print "%s:\t %.5f\t %.5f\t %.5f" % (loopName, realCommEff, uLB, commEff)
+	print("%s:\t %.5f\t %.5f\t %.5f" % (loopName, realCommEff, uLB, commEff))
 	totalLoopTimeIdeal = totalLoopTimeIdeal + loopTimeIdeal
 	totalLoopTime = totalLoopTime + loopTime
 	totalMaxTi = totalMaxTi + maxTi
@@ -224,7 +224,7 @@
 uLB = totalLoopTimeIdeal / totalMaxTi
 #uLB = totalMaxTi / totalLoopTimeIdeal
 commEff = realCommEff * uLB
-print "\n\nLoop ID:\t RealCommEff\t uLB\t\t CommEff"
-print "Total: \t\t %.5f\t %.5f\t %.5f\n" % (realCommEff, uLB, commEff)
+print("\n\nLoop ID:\t RealCommEff\t uLB\t\t CommEff")
+print("Total: \t\t %.5f\t %.5f\t %.5f\n" % (realCommEff, uLB, commEff))
 			
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/examples/MicroLoadImbalance/microLoadImbalance.py	(original)
--- b/tools/src/perfexplorer/examples/MicroLoadImbalance/microLoadImbalance.py	(refactored)
@@ -20,9 +20,9 @@
 	tmp = parameterMap.get("tauData")
 	if tmp != None:
 		tauData = tmp
-		print "Performance data: " + tauData
+		print("Performance data: " + tauData)
 	else:
-		print "TAU profile data path not specified... using current directory of profile.x.x.x files."
+		print("TAU profile data path not specified... using current directory of profile.x.x.x files.")
 
 def loadFile(fileName):
 	global gprof
@@ -82,10 +82,10 @@
 		#print mean, max, min, stddev, ratio
 
 	if callpath:
-		print "%s\t %d\t %ls\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % (mainEvent, trial.getThreads().size(), event, mean*100, max*100, min*100, stddev*100, ratio*100)
+		print("%s\t %d\t %ls\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % (mainEvent, trial.getThreads().size(), event, mean*100, max*100, min*100, stddev*100, ratio*100))
 		#print "%s\t %d\t %s\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % (mainEvent, trial.getThreads().size(), event, mean*100, 100, 100, 100, 100)
 	else:
-		print "%d\t %s\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % (trial.getThreads().size(), event, mean*100, max*100, min*100, stddev*100, ratio*100)
+		print("%d\t %s\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % (trial.getThreads().size(), event, mean*100, max*100, min*100, stddev*100, ratio*100))
 
 	return mean, max, min, stddev
 
@@ -105,8 +105,8 @@
 def main():
 	global tauData
 
-	print "--------------- JPython test script start ------------"
-	print "--- Looking for load imbalances --- "
+	print("--------------- JPython test script start ------------")
+	print("--- Looking for load imbalances --- ")
 
 	# get the parameters
 	getParameters()
@@ -114,10 +114,10 @@
 	# load the data
 	trial = loadFile(tauData)
 
-	print "Procs\t Type\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX"
+	print("Procs\t Type\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX")
 	computeLoadBalance(trial, False)
 
-	print
+	print()
 
 	#for phaseName in ["int main", "Iteration"]:
 	for phaseName in ["Iteration"]:
@@ -131,7 +131,7 @@
 		totalStddev = 0.0
 		totalRatio = 0.0
 
-		print "LoopID\t\t Procs\t Type\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX"
+		print("LoopID\t\t Procs\t Type\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX")
 		for phase in phases:
 			mean, max, min, stddev = computeLoadBalance(phase, True)
 			if mean == max == min == stddev == 0:
@@ -147,9 +147,9 @@
 
 		#event = LoadImbalanceOperation.KERNEL_COMPUTATION
 		event = LoadImbalanceOperation.COMPUTATION
-		print "%s\t\t %d\t %ls\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % ("Average", trial.getThreads().size(), event, avgMean*100, avgMax*100, avgMin*100, avgStddev*100, avgRatio*100)
+		print("%s\t\t %d\t %ls\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % ("Average", trial.getThreads().size(), event, avgMean*100, avgMax*100, avgMin*100, avgStddev*100, avgRatio*100))
 	
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/examples/MicroLoadImbalance/microLoadImbalanceActual.py	(original)
--- b/tools/src/perfexplorer/examples/MicroLoadImbalance/microLoadImbalanceActual.py	(refactored)
@@ -57,16 +57,16 @@
 	tmp = parameterMap.get("tauData")
 	if tmp != None:
 		tauData = tmp
-		print "Performance data: " + tauData
+		print("Performance data: " + tauData)
 	else:
-		print "TAU profile data path not specified... using current directory of profile.x.x.x files."
+		print("TAU profile data path not specified... using current directory of profile.x.x.x files.")
 
 	tmp = parameterMap.get("prefix")
 	if tmp != None:
 		iterationPrefix = tmp
-		print "Iteration Prefix: " + iterationPrefix
+		print("Iteration Prefix: " + iterationPrefix)
 	else:
-		print "Iteration Prefix not specified... using", iterationPrefix
+		print("Iteration Prefix not specified... using", iterationPrefix)
 
 def loadFile(fileName):
 	global gprof
@@ -140,10 +140,10 @@
 	threads = trial.getThreads().size()
 	if callpath:
 		if numPhases < 100:
-			print "%s\t %d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.4f\t %.4f" % (trunc(mainEvent, max_pos=10), threads, inclusive, event, mean, max, min, stddev, max/inclusive, ratio)
+			print("%s\t %d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.4f\t %.4f" % (trunc(mainEvent, max_pos=10), threads, inclusive, event, mean, max, min, stddev, max/inclusive, ratio))
 		#print "%s\t %d\t %s\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % (mainEvent, trial.getThreads().size(), event, mean*100, 100, 100, 100, 100)
 	else:
-		print "%d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.4f\t %.4f" % (threads, inclusive, event, mean, max, min, stddev, max/inclusive, ratio)
+		print("%d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.4f\t %.4f" % (threads, inclusive, event, mean, max, min, stddev, max/inclusive, ratio))
 
 	splits = loadBalance.get(LoadImbalanceOperation.COMPUTATION_SPLITS)
 	for thread in splits.getThreads():
@@ -173,8 +173,8 @@
 	global vectorT_i
 	global vectorT
 
-	print "--------------- JPython test script start ------------"
-	print "--- Looking for load imbalances --- "
+	print("--------------- JPython test script start ------------")
+	print("--- Looking for load imbalances --- ")
 
 	# get the parameters
 	getParameters()
@@ -182,7 +182,7 @@
 	# load the data
 	trial = loadFile(tauData)
 	trial.setIgnoreWarnings(True)
-	print "Getting basic statistics..."
+	print("Getting basic statistics...")
 	statter = BasicStatisticsOperation(trial)
 	masterStats = statter.processData()
 	masterMeans = masterStats.get(BasicStatisticsOperation.MEAN)
@@ -199,7 +199,7 @@
 	#print "Procs\t Incl.\t Type\t\t AVG\t MAX\t MIN\t STDEV\t AVG/MAX"
 	#computeLoadBalance(trial, False, 1)
 
-	print
+	print()
 
 	splitter = SplitTrialPhasesOperation(trial, iterationPrefix)
 	phases = splitter.processData()
@@ -213,8 +213,8 @@
 	totalStddev = 0.0
 	totalRatio = 0.0
 
-	print "LoopID\t\t Procs\t Incl.\t  Type\t\t AVG\t MAX\t MIN\t STDEV\t CommEff AVG/MAX"
-	print "------------------------------------------------------------------------------------------------"
+	print("LoopID\t\t Procs\t Incl.\t  Type\t\t AVG\t MAX\t MIN\t STDEV\t CommEff AVG/MAX")
+	print("------------------------------------------------------------------------------------------------")
 	for phase in phases:
 		mean, max, min, stddev, inclusive, commEff = computeLoadBalance(phase, True, phases.size())
 		if mean == max == min == stddev == 0:
@@ -259,46 +259,46 @@
 
 	event = LoadImbalanceOperation.COMPUTATION
 	#print "%s\t\t %d\t %ls\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t %.2f%%\t" % ("Average", trial.getThreads().size(), event, avgMean*100, avgMax*100, avgMin*100, avgStddev*100, avgRatio*100)
-	print "------------------------------------------------------------------------------------------------"
-	print "%s\t\t %d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.2f\t %.2f" % ("Totals", trial.getThreads().size(), totalInclusive, event, totalMean, totalMax, totalMin, math.sqrt(totalStddev), totalCommEff, totalMean / totalMax)
-	print "%s\t\t %d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.4f\t %.4f" % ("Average", trial.getThreads().size(), avgInclusive, event, avgMean, avgMax, avgMin, avgStddev, avgCommEff, avgRatio)
+	print("------------------------------------------------------------------------------------------------")
+	print("%s\t\t %d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.2f\t %.2f" % ("Totals", trial.getThreads().size(), totalInclusive, event, totalMean, totalMax, totalMin, math.sqrt(totalStddev), totalCommEff, totalMean / totalMax))
+	print("%s\t\t %d\t %.2f\t %s\t %.2f\t %.2f\t %.2f\t %.2f\t %.4f\t %.4f" % ("Average", trial.getThreads().size(), avgInclusive, event, avgMean, avgMax, avgMin, avgStddev, avgCommEff, avgRatio))
 
 	# the total time spent in the loop.  Essentially, for each
 	# iteration of the loop, get the total time for each process.  Accumulate
 	# that vector over the whole loop.  The process with the longest time spent
 	# computing (aggregated over all iterations) is the T.
-	print "\nT:\t\t", T  
+	print("\nT:\t\t", T)  
 	# the total time spent computing, collapsed.  Essentially, for each
 	# iteration of the loop, get the computing time for each process.  Accumulate
 	# that vector over the whole loop.  The process with the longest time spent
 	# computing (aggregated over all iterations) is the max(T_i).  
-	print "max(T_i):\t", maxT_i
-	print "avg(T_i):\t", avgT_i
-	print "maxEff:\t\t", maxEff
-	print "CommEff:\t", commEff, "(should be same as maxEff)"
+	print("max(T_i):\t", maxT_i)
+	print("avg(T_i):\t", avgT_i)
+	print("maxEff:\t\t", maxEff)
+	print("CommEff:\t", commEff, "(should be same as maxEff)")
 	# the load balance for the loop.  This is the sum of all efficiencies for
 	# all processes, divided by the number of processes times the maxiumum
 	# efficiency.  This can be (and is) simplified, by summing the mean
 	# computing times, and dividing by the max computing times.
-	print "avgEff:\t\t", avgEff
-	print "LB:\t\t", LB
+	print("avgEff:\t\t", avgEff)
+	print("LB:\t\t", LB)
 
 	# the total time spent computing in the loop, serialized.  Essentially, for each
 	# iteration of the loop, get the max computing time in that loop.  Add
 	# those together.  Because of overlapping iterations, this can be larger
 	# than the actual time in the loop.  If there were
 	# no time spent in communication, this is how long the loop should take.
-	print "T ideal:\t", totalMax
+	print("T ideal:\t", totalMax)
 	# the micro load balance is the process with the highest computation time
 	# divided by the ideal total loop execution time.
-	print "microLB:\t", maxT_i / totalMax
+	print("microLB:\t", maxT_i / totalMax)
 	# the transfer term is the total time spent in the ideal loop divided by
 	# the actual time spent in the loop.
-	print "Transfer:\t", totalMax / T
+	print("Transfer:\t", totalMax / T)
 	# finally, compute the efficiency.  == LB * microLB * Transfer * IPC
-	print "n:\t\t", LB * (maxT_i / totalMax) * (totalMax / T) * 1.0, "\n"
+	print("n:\t\t", LB * (maxT_i / totalMax) * (totalMax / T) * 1.0, "\n")
 	
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/examples/PhaseComparison/autotuning.py	(original)
--- b/tools/src/perfexplorer/examples/PhaseComparison/autotuning.py	(refactored)
@@ -45,7 +45,7 @@
 	grapher.processData()
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	global tauData
 	global prefix
@@ -68,7 +68,7 @@
 
 	# draw the graph
 	drawGraph(extracted)
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
     main()
--- a/tools/src/perfexplorer/examples/PhaseComparison/phases.py	(original)
--- b/tools/src/perfexplorer/examples/PhaseComparison/phases.py	(refactored)
@@ -19,16 +19,16 @@
 	tmp = parameterMap.get("tauData")
 	if tmp != None:
 		tauData = tmp
-		print "Performance data: " + tauData
+		print("Performance data: " + tauData)
 	else:
-		print "TAU profile data path not specified... using current directory of profile.x.x.x files."
+		print("TAU profile data path not specified... using current directory of profile.x.x.x files.")
 
 	tmp = parameterMap.get("prefix")
 	if tmp != None:
 		prefix = tmp
 	else:
-		print "Prefix not specified. Using default."
-	print "Prefix: " + prefix
+		print("Prefix not specified. Using default.")
+	print("Prefix: " + prefix)
 
 
 def loadFile(fileName):
@@ -71,7 +71,7 @@
 	grapher.processData()
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	global tauData
 	global prefix
@@ -95,7 +95,7 @@
 
 	# draw the graph
 	drawGraph(extracted)
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
     main()
--- a/tools/src/perfexplorer/examples/Power5CPIStack/processCPI.py	(original)
--- b/tools/src/perfexplorer/examples/Power5CPIStack/processCPI.py	(refactored)
@@ -131,7 +131,7 @@
 	numFunctions=0
 	numClusters=1
 
-	print "Parsing cluster info from: ", info
+	print("Parsing cluster info from: ", info)
 	i = open(info, 'r')
 
 	names=[]
@@ -165,7 +165,7 @@
 			for j in range(1,len(tokens)):
 				if tokens[j] == "nan" or tokens[j] == "-nan":
 					if percentDurations[j-1] >= localThreshold:
-						print "! WARNING ! 'nan' encountered for ", tokens[0].strip("\""), "- results are not trustworthy for cluster", j-1
+						print("! WARNING ! 'nan' encountered for ", tokens[0].strip("\""), "- results are not trustworthy for cluster", j-1)
 					counts.append(0)
 				else:
 					counts.append(int(tokens[j]))
@@ -178,7 +178,7 @@
 		if percentDurations[p] < tmpVal:
 			maxClusters=p
 			break
-	print "threshold = " + str(threshold) + "%   maxClusters = " + str(maxClusters-1)
+	print("threshold = " + str(threshold) + "%   maxClusters = " + str(maxClusters-1))
 
 	return names, densities, totalDurations, averageDurations, percentDurations, counters, maxClusters
 
@@ -196,7 +196,7 @@
 	numFunctions=0
 	numClusters=1
 
-	print "Parsing benchmark info from: ", info
+	print("Parsing benchmark info from: ", info)
 	i = open(info, 'r')
 
 	names=["NOISE"]
@@ -228,20 +228,20 @@
 			maxClusters = maxClusters + 1
 	i.close()
 
-	print "threshold = " + str(threshold) + "%   maxClusters = " + str(maxClusters)
+	print("threshold = " + str(threshold) + "%   maxClusters = " + str(maxClusters))
 
 	return names, densities, totalDurations, averageDurations, percentDurations, counters, maxClusters
 
 #########################################################################################
 
 def handleNone(dictionary, name, index):
-	if name in dictionary.keys():
+	if name in list(dictionary.keys()):
 		return dictionary[name][index]
 	else:
 		return 0
 
 def handleNone1(dictionary, name, index):
-	if name in dictionary.keys():
+	if name in list(dictionary.keys()):
 		if dictionary[name][index] > 0.0:
 			return dictionary[name][index]
 		else:
@@ -387,7 +387,7 @@
 	fact = FactWrapper("Overall", "CPI Stack", cpiStack)
 	handle = ruleHarness.assertObject(fact)
 	fact.setFactHandle(handle)
-	print verbose
+	print(verbose)
 	if verbose == "yes":
 		factDebug = FactWrapper("Dump CPI", "CPI Stack", cpiStack)
 		handleDebug = ruleHarness.assertObject(factDebug)
@@ -399,16 +399,16 @@
 #########################################################################################
 
 def main(argv):
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	getParameters()
 	global fractionThreshold
 	names, densities, totalDurations, averageDurations, percentDurations, counters, maxClusters = parseCounters(inputData, fractionThreshold)
 	# cpiStack = makeTestStack()
 	for i in range(1,maxClusters):
-		print "\n>>>>>>>>>>>>>>>> Analyzing Stalls for Cluster", i, "<<<<<<<<<<<<<<<<\n"
+		print("\n>>>>>>>>>>>>>>>> Analyzing Stalls for Cluster", i, "<<<<<<<<<<<<<<<<\n")
 		cpiStack = computeCPIStats(names, percentDurations, counters, i)
 		processRules(cpiStack)
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 #########################################################################################
 
--- a/tools/src/perfexplorer/examples/PowerCapEffect/cap.py	(original)
--- b/tools/src/perfexplorer/examples/PowerCapEffect/cap.py	(refactored)
@@ -73,13 +73,13 @@
 	return inputs
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	for app in ["amg2013","CoMD-mpi","lulesh"]:
 		inputs = loadFromDB(app)
 		inputs = aggregateMPI(inputs)
 		drawGraph(inputs,app)
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
     main()
--- a/tools/src/perfexplorer/examples/SaveNewMetric/savemetric.py	(original)
--- b/tools/src/perfexplorer/examples/SaveNewMetric/savemetric.py	(refactored)
@@ -10,7 +10,7 @@
 def loadFromDB():
 	Utilities.setSession("postgres-test")
 	trial = Utilities.getTrialByName("threads").get(0)
-	print trial.getName()
+	print(trial.getName())
 	return trial
 
 def derive(trial):	
@@ -29,16 +29,16 @@
 	saver.processData()
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	trial = loadFromDB()
 
 	# create a derived metric
 	derived = derive(TrialResult(trial))
-	print derived.get(0).getMetrics()
+	print(derived.get(0).getMetrics())
 #	Utilities.saveMetric(trial,derived.get(0).getMetrics())
 	save(derived)
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/examples/StackedBarChart/graph.py	(original)
--- b/tools/src/perfexplorer/examples/StackedBarChart/graph.py	(refactored)
@@ -64,7 +64,7 @@
 	grapher.drawChartToFile("./testing.eps")
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	inputs = loadFromFiles()
 
@@ -77,7 +77,7 @@
 	extracted = extractor.processData()
 
 	drawGraph(extracted)
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
     main()
--- a/tools/src/perfexplorer/examples/StackedBarChart/graph_stacked_chart.py	(original)
--- b/tools/src/perfexplorer/examples/StackedBarChart/graph_stacked_chart.py	(refactored)
@@ -205,7 +205,7 @@
 """
 
 def main(inputs,title):
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	# inputs = loadFromFiles()
 	# inputs = loadFromDB2()
@@ -259,7 +259,7 @@
 
 	# drawAreaGraph(extracted, title)
 	drawBarGraph(extracted, title, True)
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
     inputs = loadFromFiles()
--- a/tools/src/perfexplorer/examples/StackedBarChart/kevin.py	(original)
--- b/tools/src/perfexplorer/examples/StackedBarChart/kevin.py	(refactored)
@@ -207,7 +207,7 @@
 """
 
 def main(inputs,title):
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	# inputs = loadFromFiles()
 	# inputs = loadFromDB2()
@@ -261,7 +261,7 @@
 
 	# drawAreaGraph(extracted, title)
 	drawBarGraph(extracted, title, True)
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
     inputs = loadFromFiles()
--- a/tools/src/perfexplorer/examples/Sunburst/dump.py	(original)
--- b/tools/src/perfexplorer/examples/Sunburst/dump.py	(refactored)
@@ -29,7 +29,7 @@
 
 def dumpNode(myfile,node,parent,parentPath,result,metric):
 	comma = False
-	for key, value in node.iteritems():
+	for key, value in node.items():
 		currentPath = key
 		if parentPath != "":
 			currentPath = parentPath + " => " + key
@@ -62,7 +62,7 @@
 
 def dumpIcicleNode(myfile,node,parent,parentPath,result,metric):
 	comma = False
-	for key, value in node.iteritems():
+	for key, value in node.items():
 		currentPath = key
 		if parentPath != "":
 			currentPath = parentPath + " => " + key
@@ -82,7 +82,7 @@
 		comma = True
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	t = 0
 	raw = loadFromFiles()
@@ -114,7 +114,7 @@
 	dumpIcicleNode(mydata2,tree,"","",result,metric)
 	mydata2.close()
 
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/examples/TimerBreakdown/graph.py	(original)
--- b/tools/src/perfexplorer/examples/TimerBreakdown/graph.py	(refactored)
@@ -149,7 +149,7 @@
 """
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	#inputs = loadFromFiles()
 	inputs = loadFromDB()
@@ -203,7 +203,7 @@
 
 	drawAreaGraph(extracted)
 	drawBarGraph(extracted, True)
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
     main()
--- a/tools/src/perfexplorer/examples/TimerBreakdown/graph2ndLevel.py	(original)
--- b/tools/src/perfexplorer/examples/TimerBreakdown/graph2ndLevel.py	(refactored)
@@ -123,7 +123,7 @@
 """
 
 def main():
-	print "--------------- JPython test script start ------------"
+	print("--------------- JPython test script start ------------")
 	# load the data
 	#inputs = loadFromFiles()
 	inputs = loadFromDB()
@@ -168,7 +168,7 @@
 		index = index + 1
 	drawAreaGraph(extracted)
 	drawBarGraph(extracted, True)
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
     main()
--- a/tools/src/perfexplorer/openuh/ClustorGraph.py	(original)
--- b/tools/src/perfexplorer/openuh/ClustorGraph.py	(refactored)
@@ -33,7 +33,7 @@
 
 
 def main():
-        print "--------------- JPython test script start ------------"
+        print("--------------- JPython test script start ------------")
         inputs = load("Application","Experiment","Trial")
 
         grapher = DrawMetadataGraph(inputs)
@@ -43,7 +43,7 @@
         #grapher.setYAxisLabel("")
         grapher.processData()
 
-        print "---------------- JPython test script end -------------"
+        print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
     main()
--- a/tools/src/perfexplorer/openuh/commandLine.py	(original)
--- b/tools/src/perfexplorer/openuh/commandLine.py	(refactored)
@@ -11,7 +11,7 @@
 
 ###################################################################
 
-print "---------------- JPython test script begin -----------"
+print("---------------- JPython test script begin -----------")
 
 # create a rulebase for processing
 #ruleHarness = RuleHarness.useGlobalRules("openuh/OpenUHRules.drl")
@@ -31,12 +31,12 @@
 top10er = TopXEvents(derived, newMetric, AbstractResult.EXCLUSIVE, 10)
 top10 = top10er.processData().get(0)
 
-print "Top 10 events with high stall/cycle ratios:"
+print("Top 10 events with high stall/cycle ratios:")
 for event in top10er.getSortedEventNames():
-	print "\t", event, derived.getInclusive(0, event, newMetric)
+	print("\t", event, derived.getInclusive(0, event, newMetric))
 	#MeanEventFact.compareEventToMain(derived, mainEvent, derived, event)
 
 # process the rules
 #RuleHarness.getInstance().processRules()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/openuh/compareMemoryStalls.py	(original)
--- b/tools/src/perfexplorer/openuh/compareMemoryStalls.py	(refactored)
@@ -165,7 +165,7 @@
 
 def processTrial(trial):
 	# extract the non-callpath events from the trial
-	print "extracting non-callpath..."
+	print("extracting non-callpath...")
 	extractor = ExtractNonCallpathEventOperation(trial)
 	extracted = extractor.processData().get(0)
 
@@ -174,17 +174,17 @@
 	# extracted = extractor.processData().get(0)
 
 	# get basic statistics
-	print "computing mean..."
+	print("computing mean...")
 	statMaker = BasicStatisticsOperation(extracted, True)
 	stats = statMaker.processData()
 	means = stats.get(BasicStatisticsOperation.MEAN)
 
 	# get main event
 	mainEvent = means.getMainEvent()
-	print "Main Event: ", mainEvent
+	print("Main Event: ", mainEvent)
 
 	# calculate all derived metrics
-	print "Deriving memory stall metrics..."
+	print("Deriving memory stall metrics...")
 	derived, PowerPerProc = getMemoryModel(means)
 
 	return derived
@@ -211,11 +211,11 @@
 	global Total
 	global TotalRatio
 
-	print "--------------- JPython test script start ------------"
-	print "--- Calculating Memory Stall Causes --- "
+	print("--------------- JPython test script start ------------")
+	print("--- Calculating Memory Stall Causes --- ")
 
 	# load the trial
-	print "loading the data..."
+	print("loading the data...")
 	Utilities.setSession("openuh")
 	# load just the average values across all threads, input: app_name, exp_name, trial_name
 	trial = TrialResult(Utilities.getTrial("Fluid Dynamic - Unoptimized OpenMP", "rib 90", "1_16"))
@@ -231,20 +231,20 @@
 	top10er = TopXEvents(diff, diff.getTimeMetric(), AbstractResult.EXCLUSIVE, 10)
 	top10 = top10er.processData().get(0);
 	for event in top10.getEvents():
-		print
-		print event, "L1 hits: ", L1Hits, diff.getInclusive(0, event, L1Hits)
-		print event, "L2 hits: ", L2Hits, diff.getInclusive(0, event, L2Hits)
-		print event, "L3 hits: ", L3Hits, diff.getInclusive(0, event, L3Hits)
-		print event, "TLB Penalty: ", TLBPenalty, diff.getInclusive(0, event, TLBPenalty)
-		print event, "Local Memory Hits: ", LocalMemoryHits, diff.getInclusive(0, event, LocalMemoryHits)
-		print event, "Remote Memory Hits: ", RemoteMemoryHits, diff.getInclusive(0, event, RemoteMemoryHits)
-		print event, "Total: ", Total, diff.getInclusive(0, event, Total)
-		print event, "Total Ratio: ", TotalRatio, diff.getInclusive(0, event, TotalRatio)
-		print event, "local/remote ratio: ", RatioMemoryAccesses, diff.getInclusive(0, event, RatioMemoryAccesses)
-		print
-
-
-	print "---------------- JPython test script end -------------"
+		print()
+		print(event, "L1 hits: ", L1Hits, diff.getInclusive(0, event, L1Hits))
+		print(event, "L2 hits: ", L2Hits, diff.getInclusive(0, event, L2Hits))
+		print(event, "L3 hits: ", L3Hits, diff.getInclusive(0, event, L3Hits))
+		print(event, "TLB Penalty: ", TLBPenalty, diff.getInclusive(0, event, TLBPenalty))
+		print(event, "Local Memory Hits: ", LocalMemoryHits, diff.getInclusive(0, event, LocalMemoryHits))
+		print(event, "Remote Memory Hits: ", RemoteMemoryHits, diff.getInclusive(0, event, RemoteMemoryHits))
+		print(event, "Total: ", Total, diff.getInclusive(0, event, Total))
+		print(event, "Total Ratio: ", TotalRatio, diff.getInclusive(0, event, TotalRatio))
+		print(event, "local/remote ratio: ", RatioMemoryAccesses, diff.getInclusive(0, event, RatioMemoryAccesses))
+		print()
+
+
+	print("---------------- JPython test script end -------------")
 
 	
 if __name__ == "__main__":
--- a/tools/src/perfexplorer/openuh/comparePower.py	(original)
--- b/tools/src/perfexplorer/openuh/comparePower.py	(refactored)
@@ -132,38 +132,38 @@
 	global Joules
 	global PPJ
 	
-	print "--------------- JPython test script start ------------"
-	print "--- Calculating Power Models --- "
+	print("--------------- JPython test script start ------------")
+	print("--- Calculating Power Models --- ")
 
 	# create a rulebase for processing
 	#print "Loading Rules..."
 	#ruleHarness = RuleHarness.useGlobalRules("openuh/OpenUHRules.drl")
 
 	# load the trial
-	print "loading the data..."
+	print("loading the data...")
 
 	# check to see if the user has selected a trial
 	Utilities.setSession("openuh")
 	trial = TrialResult(Utilities.getTrial("Fluid Dynamic Energy/Power", trialName, "1_1"))
 
 	# extract the non-callpath events from the trial
-	print "extracting non-callpath..."
+	print("extracting non-callpath...")
 	extractor = ExtractNonCallpathEventOperation(trial)
 	extracted = extractor.processData().get(0)
 
 	# get basic statistics
-	print "computing mean..."
+	print("computing mean...")
 	statMaker = BasicStatisticsOperation(extracted, False)
 	stats = statMaker.processData()
 	means = stats.get(BasicStatisticsOperation.MEAN)
 
 	# get main event
 	mainEvent = means.getMainEvent()
-	print "Main Event: ", mainEvent
+	print("Main Event: ", mainEvent)
 
 	# calculate all derived metrics
-	print
-	print "Deriving power metric..."
+	print()
+	print("Deriving power metric...")
 	derived, PowerPerProc = getPowerModel(means)
 
 	# get the top 10 events
@@ -174,81 +174,81 @@
 	thread = 0
 
 	# iterate over events, output inefficiency derived metric
-	print
+	print()
 	#print "Top 10 Average", PowerPerProc, "values per thread for this trial:"
 	#for event in top10er.getSortedEventNames():
 		#print event, derived.getExclusive(thread, event, PowerPerProc)
-	print
+	print()
 	#print mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, PowerPerProc)
-	print
+	print()
 
 	# compute the energy consumed by each event
-	print "Computing joules consumed..."
+	print("Computing joules consumed...")
 	derived, EnergyPerProc = getEnergy(derived, PowerPerProc)
 	Joules = EnergyPerProc
 
 	# iterate over events, output inefficiency derived metric
-	print
+	print()
 	#print "Top 10 Average", EnergyPerProc, "values per thread for this trial:"
 	#for event in top10er.getSortedEventNames():
 		#print event, derived.getExclusive(thread, event, EnergyPerProc)
-	print
+	print()
 	#print mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, EnergyPerProc)
-	print
+	print()
 
 	# compute the floating point operations per joule per event
-	print "Computing FP_OPS/joule..."
+	print("Computing FP_OPS/joule...")
 	derived, FlopsPerJoule = getFlopsPerJoule(derived, EnergyPerProc)
 	PPJ = FlopsPerJoule
 
 	# iterate over events, output inefficiency derived metric
-	print
+	print()
 	#print "Top 10 Average", FlopsPerJoule, "values per thread for this trial:"
 	#for event in top10er.getSortedEventNames():
 		#print event, derived.getExclusive(thread, event, FlopsPerJoule)
-	print
+	print()
 	#print mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, FlopsPerJoule)
-	print
+	print()
 
 	# compute the floating point operations per joule per event
-	print "Computing Instructions Per Cycle..."
+	print("Computing Instructions Per Cycle...")
 	derived, IPC = getIPC(derived)
 
 	# iterate over events, output inefficiency derived metric
-	print
+	print()
 	#print "Top 10 Average", IPC, "values per thread for this trial:"
 	#for event in top10er.getSortedEventNames():
 		#print event, derived.getExclusive(thread, event, IPC)
-	print
+	print()
 	#print mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, IPC)
-	print
+	print()
 
 	# compute the floating point operations per joule per event
-	print "Computing Issued Per Cycle..."
+	print("Computing Issued Per Cycle...")
 	derived, issuedPerCycle = getIssuedPerCycle(derived)
 
 	# iterate over events, output inefficiency derived metric
-	print
+	print()
 	#print "Top 10 Average", issuedPerCycle, "values per thread for this trial:"
 	#for event in top10er.getSortedEventNames():
 		#print event, derived.getExclusive(thread, event, issuedPerCycle)
-	print
+	print()
 
 	#print mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, issuedPerCycle)
-	print
+	print()
 
 	#print "Time to completion..."
-	print
+	print()
 	#for event in top10er.getSortedEventNames():
 		#print event, derived.getExclusive(thread, event, derived.getTimeMetric())/1000000
-	print
+	print()
 
 	#print mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, derived.getTimeMetric())/1000000
 
 	# process the rules
 	#RuleHarness.getInstance().processRules()
 
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 	return derived
 
 if __name__ == "__main__":
@@ -261,13 +261,13 @@
 	top20er = TopXEvents(first, first.getTimeMetric(), AbstractResult.EXCLUSIVE, 20)
 	top20 = top20er.processData().get(0)
 
-	print "Joules"
+	print("Joules")
 	for event in top20.getEvents():
 		if difference.getExclusive(0, event, Joules) < 0.0:
-			print event, difference.getExclusive(0, event, Joules), first.getExclusive(0, event, Joules), second.getExclusive(0, event, Joules)
-
-	print 
-	print "Performance Per Joule"
+			print(event, difference.getExclusive(0, event, Joules), first.getExclusive(0, event, Joules), second.getExclusive(0, event, Joules))
+
+	print() 
+	print("Performance Per Joule")
 	for event in top20.getEvents():
 		if difference.getExclusive(0, event, PPJ) > 0.0:
-			print event, difference.getExclusive(0, event, PPJ) , first.getExclusive(0, event, PPJ) , second.getExclusive(0, event, PPJ)
+			print(event, difference.getExclusive(0, event, PPJ) , first.getExclusive(0, event, PPJ) , second.getExclusive(0, event, PPJ))
--- a/tools/src/perfexplorer/openuh/demoScript.py	(original)
--- b/tools/src/perfexplorer/openuh/demoScript.py	(refactored)
@@ -14,7 +14,7 @@
 
 ###################################################################
 
-print "---------------- JPython test script begin -----------"
+print("---------------- JPython test script begin -----------")
 
 # create a rulebase for processing
 ruleHarness = RuleHarness.useGlobalRules("openuh/OpenUHRules.drl")
@@ -30,9 +30,9 @@
 
 for event in derived.getEvents():
 	MeanEventFact.compareEventToMain(derived, mainEvent, derived, event)
-print
+print()
 
 # process the rules
 RuleHarness.getInstance().processRules()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/openuh/inefficiency.py	(original)
--- b/tools/src/perfexplorer/openuh/inefficiency.py	(refactored)
@@ -27,7 +27,7 @@
 	merged = None
 	newName = None
 	if (derivor.exists()):
-		print "Exists: ", newName
+		print("Exists: ", newName)
 		merged = input
 		newName = derivor.getNewName()
 	else:
@@ -41,7 +41,7 @@
 		# saver = SaveResultOperation(derived)
 		# saver.setForceOverwrite(False)
 		# saver.processData()
-	print "new metric: ", newName
+	print("new metric: ", newName)
 	return merged, newName
 
 ###################################################################
@@ -67,15 +67,15 @@
 
 ###################################################################
 
-print "--------------- JPython test script start ------------"
-print "--- Calculating inefficiency --- "
+print("--------------- JPython test script start ------------")
+print("--- Calculating inefficiency --- ")
 
 # create a rulebase for processing
 #print "Loading Rules..."
 ruleHarness = RuleHarness.useGlobalRules("openuh/OpenUHRules.drl")
 
 # load the trial
-print "loading the data..."
+print("loading the data...")
 
 # choose the right database configuration - a string which matches the end of the jdbc connection,
 # such as "perfdmf" to match "jdbc:derby:/Users/khuck/src/tau2/apple/lib/perfdmf"
@@ -87,19 +87,19 @@
 trial = TrialResult(Utilities.getTrial("Fluid Dynamic - Unoptimized OpenMP", "rib 90", "Original OpenMP 1_16"))
 
 # extract the non-callpath events from the trial
-print "extracting"
+print("extracting")
 extractor = ExtractNonCallpathEventOperation(trial)
 extracted = extractor.processData().get(0)
 
 # get basic statistics
-print "stats"
+print("stats")
 statMaker = BasicStatisticsOperation(extracted, False)
 stats = statMaker.processData()
 means = stats.get(BasicStatisticsOperation.MEAN)
 
 # get main event
 mainEvent = means.getMainEvent()
-print "Main Event: ", mainEvent
+print("Main Event: ", mainEvent)
 
 # calculate all derived metrics
 derived, inefficiency1, inefficiency2 = getInefficiency(means)
@@ -112,9 +112,9 @@
 for event in derived.getEvents():
 	#print event, derived.getExclusive(thread, event, inefficiency1), derived.getInclusive(thread, event, inefficiency1)
 	MeanEventFact.compareEventToMain(derived, mainEvent, derived, event)
-print
+print()
 
 # process the rules
 RuleHarness.getInstance().processRules()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/openuh/loadimbalance.bsc.py	(original)
--- b/tools/src/perfexplorer/openuh/loadimbalance.bsc.py	(refactored)
@@ -9,15 +9,15 @@
 
 ###################################################################
 
-print "--------------- JPython test script start ------------"
-print "--- Looking for load imbalances --- "
+print("--------------- JPython test script start ------------")
+print("--- Looking for load imbalances --- ")
 
 # create a rulebase for processing
-print "Loading Rules..."
+print("Loading Rules...")
 ruleHarness = RuleHarness.useGlobalRules("/home/khuck/tau2/tools/src/perfexplorer/openuh/BSCRules.drl")
 
 # load the trial
-print "loading the data..."
+print("loading the data...")
 
 # choose the right database configuration - 
 # a string which matches the end of the jdbc connection,
@@ -41,7 +41,7 @@
 means = stats.get(BasicStatisticsOperation.MEAN)
 totals = stats.get(BasicStatisticsOperation.TOTAL)
 mainEvent = means.getMainEvent()
-print "Main Event: ", mainEvent
+print("Main Event: ", mainEvent)
 
 # get the ratio between stddev and total
 ratioMaker = RatioOperation(stddev, means)
@@ -52,7 +52,7 @@
 for event in ratios.getEvents():
 	for metric in ratios.getMetrics():
 		MeanEventFact.evaluateLoadBalance(means, ratios, event, metric)
-print
+print()
 
 # add the callpath event names to the facts in the rulebase.
 
@@ -66,4 +66,4 @@
 # process the rules
 RuleHarness.getInstance().processRules()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/openuh/loadimbalance.py	(original)
--- b/tools/src/perfexplorer/openuh/loadimbalance.py	(refactored)
@@ -22,15 +22,15 @@
 
 ###################################################################
 
-print "--------------- JPython test script start ------------"
-print "--- Looking for load imbalances --- "
+print("--------------- JPython test script start ------------")
+print("--- Looking for load imbalances --- ")
 
 # create a rulebase for processing
-print "Loading Rules..."
+print("Loading Rules...")
 ruleHarness = RuleHarness.useGlobalRules("openuh/OpenUHRules.drl")
 
 # load the trial
-print "loading the data..."
+print("loading the data...")
 
 # choose the right database configuration - a string which matches the end of the jdbc connection,
 # such as "perfdmf" to match "jdbc:derby:/Users/khuck/src/tau2/apple/lib/perfdmf"
@@ -55,7 +55,7 @@
 means = stats.get(BasicStatisticsOperation.MEAN)
 totals = stats.get(BasicStatisticsOperation.TOTAL)
 mainEvent = means.getMainEvent()
-print "Main Event: ", mainEvent
+print("Main Event: ", mainEvent)
 
 # get the ratio between stddev and total
 ratioMaker = RatioOperation(stddev, means)
@@ -69,7 +69,7 @@
 	#for metric in ratios.getMetrics():
 	#print event, totals.getInclusive(thread, event, metric), means.getInclusive(thread, event, metric), stddev.getInclusive(thread, event, metric), ratios.getInclusive(thread, event, metric)
 	MeanEventFact.evaluateLoadBalance(means, ratios, event, metric)
-print
+print()
 
 # add the callpath event names to the facts in the rulebase.
 
@@ -83,4 +83,4 @@
 # process the rules
 RuleHarness.getInstance().processRules()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/openuh/memoryStalls.py	(original)
--- b/tools/src/perfexplorer/openuh/memoryStalls.py	(refactored)
@@ -159,24 +159,24 @@
 	global Total
 	global TotalRatio
 	
-	print "--------------- JPython test script start ------------"
-	print "--- Calculating Memory Stall Causes --- "
+	print("--------------- JPython test script start ------------")
+	print("--- Calculating Memory Stall Causes --- ")
 
 	# create a rulebase for processing
-	print "Loading Rules..."
+	print("Loading Rules...")
 	ruleHarness = RuleHarness.useGlobalRules("openuh/OpenUHRules.drl")
 
 	# load the trial
-	print "loading the data..."
+	print("loading the data...")
 
 	# check to see if the user has selected a trial
 	tmp = Utilities.getCurrentTrial()
 	if tmp != None:
 		trial = TrialResult(tmp)
-		print 
+		print() 
 	else:
 		# remove these two lines to bypass this and use the default trial
-		print "No trial selected - script exiting"
+		print("No trial selected - script exiting")
 		return
 
 		# choose the right database configuration - a string which matches the end of the jdbc connection,
@@ -187,61 +187,61 @@
 		#trial = TrialResult(Utilities.getTrial("Fluid Dynamic - Unoptimized", "rib 45", "1_8"))
 
 	# extract the non-callpath events from the trial
-	print "extracting non-callpath..."
+	print("extracting non-callpath...")
 	extractor = ExtractNonCallpathEventOperation(trial)
 	extracted = extractor.processData().get(0)
 
 	# get basic statistics
-	print "computing mean..."
+	print("computing mean...")
 	statMaker = BasicStatisticsOperation(extracted, True)
 	stats = statMaker.processData()
 	means = stats.get(BasicStatisticsOperation.MEAN)
 
 	# get main event
 	mainEvent = means.getMainEvent()
-	print "Main Event: ", mainEvent
+	print("Main Event: ", mainEvent)
 
 	# calculate all derived metrics
-	print "Deriving memory stall metrics..."
+	print("Deriving memory stall metrics...")
 	derived, PowerPerProc = getMemoryModel(means)
 
 	# iterate over events, output inefficiency derived metric
 	for event in derived.getEvents():
 		MeanEventFact.compareEventToMain(derived, mainEvent, derived, event)
-	print
-	print
+	print()
+	print()
 
 	# output the top 10
 	top10er = TopXEvents(derived, derived.getTimeMetric(), AbstractResult.EXCLUSIVE, 10)
 	top10 = top10er.processData().get(0);
 	for event in top10.getEvents():
-		print
+		print()
 		if event == mainEvent:
-			print event, "L1 hits: ", L1Hits, derived.getInclusive(0, event, L1Hits)
-			print event, "L2 hits: ", L2Hits, derived.getInclusive(0, event, L2Hits)
-			print event, "L3 hits: ", L3Hits, derived.getInclusive(0, event, L3Hits)
-			print event, "TLB Penalty: ", TLBPenalty, derived.getInclusive(0, event, TLBPenalty)
-			print event, "Local Memory Hits: ", LocalMemoryHits, derived.getInclusive(0, event, LocalMemoryHits)
-			print event, "Remote Memory Hits: ", RemoteMemoryHits, derived.getInclusive(0, event, RemoteMemoryHits)
-			print event, "Total: ", Total, derived.getInclusive(0, event, Total)
-			print event, "Total Ratio: ", TotalRatio, derived.getInclusive(0, event, TotalRatio)
-			print event, "local/remote ratio: ", RatioMemoryAccesses, derived.getInclusive(0, event, RatioMemoryAccesses)
+			print(event, "L1 hits: ", L1Hits, derived.getInclusive(0, event, L1Hits))
+			print(event, "L2 hits: ", L2Hits, derived.getInclusive(0, event, L2Hits))
+			print(event, "L3 hits: ", L3Hits, derived.getInclusive(0, event, L3Hits))
+			print(event, "TLB Penalty: ", TLBPenalty, derived.getInclusive(0, event, TLBPenalty))
+			print(event, "Local Memory Hits: ", LocalMemoryHits, derived.getInclusive(0, event, LocalMemoryHits))
+			print(event, "Remote Memory Hits: ", RemoteMemoryHits, derived.getInclusive(0, event, RemoteMemoryHits))
+			print(event, "Total: ", Total, derived.getInclusive(0, event, Total))
+			print(event, "Total Ratio: ", TotalRatio, derived.getInclusive(0, event, TotalRatio))
+			print(event, "local/remote ratio: ", RatioMemoryAccesses, derived.getInclusive(0, event, RatioMemoryAccesses))
 		else:
-			print event, "L1 hits: ", L1Hits, derived.getExclusive(0, event, L1Hits)
-			print event, "L2 hits: ", L2Hits, derived.getExclusive(0, event, L2Hits)
-			print event, "L3 hits: ", L3Hits, derived.getExclusive(0, event, L3Hits)
-			print event, "TLB Penalty: ", TLBPenalty, derived.getExclusive(0, event, TLBPenalty)
-			print event, "Local Memory Hits: ", LocalMemoryHits, derived.getExclusive(0, event, LocalMemoryHits)
-			print event, "Remote Memory Hits: ", RemoteMemoryHits, derived.getExclusive(0, event, RemoteMemoryHits)
-			print event, "Total: ", Total, derived.getExclusive(0, event, Total)
-			print event, "Total Ratio: ", TotalRatio, derived.getExclusive(0, event, TotalRatio)
-			print event, "local/remote ratio: ", RatioMemoryAccesses, derived.getExclusive(0, event, RatioMemoryAccesses)
-		print
+			print(event, "L1 hits: ", L1Hits, derived.getExclusive(0, event, L1Hits))
+			print(event, "L2 hits: ", L2Hits, derived.getExclusive(0, event, L2Hits))
+			print(event, "L3 hits: ", L3Hits, derived.getExclusive(0, event, L3Hits))
+			print(event, "TLB Penalty: ", TLBPenalty, derived.getExclusive(0, event, TLBPenalty))
+			print(event, "Local Memory Hits: ", LocalMemoryHits, derived.getExclusive(0, event, LocalMemoryHits))
+			print(event, "Remote Memory Hits: ", RemoteMemoryHits, derived.getExclusive(0, event, RemoteMemoryHits))
+			print(event, "Total: ", Total, derived.getExclusive(0, event, Total))
+			print(event, "Total Ratio: ", TotalRatio, derived.getExclusive(0, event, TotalRatio))
+			print(event, "local/remote ratio: ", RatioMemoryAccesses, derived.getExclusive(0, event, RatioMemoryAccesses))
+		print()
 
 	# process the rules
 	RuleHarness.getInstance().processRules()
 
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/openuh/powerModels.py	(original)
--- b/tools/src/perfexplorer/openuh/powerModels.py	(refactored)
@@ -127,24 +127,24 @@
 	global True
 	global False
 	
-	print "--------------- JPython test script start ------------"
-	print "--- Calculating Power Models --- "
+	print("--------------- JPython test script start ------------")
+	print("--- Calculating Power Models --- ")
 
 	# create a rulebase for processing
 	#print "Loading Rules..."
 	#ruleHarness = RuleHarness.useGlobalRules("openuh/OpenUHRules.drl")
 
 	# load the trial
-	print "loading the data..."
+	print("loading the data...")
 
 	# check to see if the user has selected a trial
 	tmp = Utilities.getCurrentTrial()
 	if tmp != None:
 		trial = TrialResult(tmp)
-		print 
+		print() 
 	else:
 		# remove these two lines to bypass this and use the default trial
-		print "No trial selected - script exiting"
+		print("No trial selected - script exiting")
 		return
 
 		Utilities.setSession("openuh")
@@ -154,7 +154,7 @@
 		#trial = TrialResult(Utilities.getTrial("Fluid Dynamic - Unoptimized", "rib 45", "1_8"))
 
 	# extract the non-callpath events from the trial
-	print "extracting non-callpath..."
+	print("extracting non-callpath...")
 	extractor = ExtractNonCallpathEventOperation(trial)
 	extracted = extractor.processData().get(0)
 
@@ -163,17 +163,17 @@
 	# extracted = extractor.processData().get(0)
 
 	# get basic statistics
-	print "computing mean..."
+	print("computing mean...")
 	statMaker = BasicStatisticsOperation(extracted, True)
 	stats = statMaker.processData()
 	means = stats.get(BasicStatisticsOperation.MEAN)
 
 	# get main event
 	mainEvent = means.getMainEvent()
-	print "Main Event: ", mainEvent
+	print("Main Event: ", mainEvent)
 
 	# calculate all derived metrics
-	print "Deriving power metrics..."
+	print("Deriving power metrics...")
 	derived, PowerPerProc = getPowerModel(means)
 
 	# get the top 10 "power dense" events
@@ -184,15 +184,15 @@
 	thread = 0
 
 	# iterate over events, output inefficiency derived metric
-	print "Top 10 Average", PowerPerProc, "values per thread for this trial:"
+	print("Top 10 Average", PowerPerProc, "values per thread for this trial:")
 	for event in top10er.getSortedEventNames():
-		print event, top10.getExclusive(thread, event, PowerPerProc)
-	print
-	print mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, PowerPerProc)
-	print
+		print(event, top10.getExclusive(thread, event, PowerPerProc))
+	print()
+	print(mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, PowerPerProc))
+	print()
 
 	# compute the energy consumed by each event
-	print "Computing joules consumed..."
+	print("Computing joules consumed...")
 	derived, EnergyPerProc = getEnergy(derived, PowerPerProc)
 
 	# get the top 10 "power dense" events
@@ -200,19 +200,19 @@
 	top10 = top10er.processData().get(0)
 
 	# iterate over events, output inefficiency derived metric
-	print "Top 10 Average", EnergyPerProc, "values per thread for this trial:"
+	print("Top 10 Average", EnergyPerProc, "values per thread for this trial:")
 	for event in top10er.getSortedEventNames():
-		print event, top10.getExclusive(thread, event, EnergyPerProc)
+		print(event, top10.getExclusive(thread, event, EnergyPerProc))
 		#print event, top10.getExclusive(thread, event, "LINUX_TIMERS")
 		#print event, top10.getExclusive(thread, event, "(LINUX_TIMERS*1.0E-6)")
-	print
-	print mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, EnergyPerProc)
+	print()
+	print(mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, EnergyPerProc))
 	#print mainEvent, derived.getExclusive(thread, event, "LINUX_TIMERS")
 	#print mainEvent, derived.getExclusive(thread, event, "(LINUX_TIMERS*1.0E-6)")
-	print
+	print()
 
 	# compute the floating point operations per joule per event
-	print "Computing FP_OPS/joule..."
+	print("Computing FP_OPS/joule...")
 	derived, FlopsPerJoule = getFlopsPerJoule(derived, EnergyPerProc)
 
 	# get the top 10 "power dense" events
@@ -220,17 +220,17 @@
 	top10 = top10er.processData().get(0)
 
 	# iterate over events, output inefficiency derived metric
-	print "Top 10 Average", FlopsPerJoule, "values per thread for this trial:"
+	print("Top 10 Average", FlopsPerJoule, "values per thread for this trial:")
 	for event in top10er.getSortedEventNames():
-		print event, top10.getExclusive(thread, event, FlopsPerJoule)
-	print
-	print mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, FlopsPerJoule)
-	print
+		print(event, top10.getExclusive(thread, event, FlopsPerJoule))
+	print()
+	print(mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, FlopsPerJoule))
+	print()
 
 	# process the rules
 	#RuleHarness.getInstance().processRules()
 
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/openuh/powerOpt.py	(original)
--- b/tools/src/perfexplorer/openuh/powerOpt.py	(refactored)
@@ -127,44 +127,44 @@
 	global True
 	global False
 	
-	print "--------------- JPython test script start ------------"
-	print "--- Calculating Power Models --- "
+	print("--------------- JPython test script start ------------")
+	print("--- Calculating Power Models --- ")
 
 	# create a rulebase for processing
 	#print "Loading Rules..."
 	#ruleHarness = RuleHarness.useGlobalRules("openuh/OpenUHRules.drl")
 
 	# load the trial
-	print "loading the data..."
+	print("loading the data...")
 
 	# check to see if the user has selected a trial
 	tmp = Utilities.getCurrentTrial()
 	if tmp != None:
 		trial = TrialResult(tmp)
-		print 
+		print() 
 	else:
 		# remove these two lines to bypass this and use the default trial
-		print "No trial selected - script exiting"
+		print("No trial selected - script exiting")
 		return
 
 	# extract the non-callpath events from the trial
-	print "extracting non-callpath..."
+	print("extracting non-callpath...")
 	extractor = ExtractNonCallpathEventOperation(trial)
 	extracted = extractor.processData().get(0)
 
 	# get basic statistics
-	print "computing mean..."
+	print("computing mean...")
 	statMaker = BasicStatisticsOperation(extracted, False)
 	stats = statMaker.processData()
 	means = stats.get(BasicStatisticsOperation.MEAN)
 
 	# get main event
 	mainEvent = means.getMainEvent()
-	print "Main Event: ", mainEvent
+	print("Main Event: ", mainEvent)
 
 	# calculate all derived metrics
-	print
-	print "Deriving power metric..."
+	print()
+	print("Deriving power metric...")
 	derived, PowerPerProc = getPowerModel(means)
 
 	# get the top 10 events
@@ -175,81 +175,81 @@
 	thread = 0
 
 	# iterate over events, output inefficiency derived metric
-	print
-	print "Top 10 Average", PowerPerProc, "values per thread for this trial:"
-	for event in top10er.getSortedEventNames():
-		print event, derived.getExclusive(thread, event, PowerPerProc)
-	print
-	print mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, PowerPerProc)
-	print
+	print()
+	print("Top 10 Average", PowerPerProc, "values per thread for this trial:")
+	for event in top10er.getSortedEventNames():
+		print(event, derived.getExclusive(thread, event, PowerPerProc))
+	print()
+	print(mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, PowerPerProc))
+	print()
 
 	# compute the energy consumed by each event
-	print "Computing joules consumed..."
+	print("Computing joules consumed...")
 	derived, EnergyPerProc = getEnergy(derived, PowerPerProc)
 
 	# iterate over events, output inefficiency derived metric
-	print
-	print "Top 10 Average", EnergyPerProc, "values per thread for this trial:"
-	for event in top10er.getSortedEventNames():
-		print event, derived.getExclusive(thread, event, EnergyPerProc)
-	print
-	print mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, EnergyPerProc)
-	print
+	print()
+	print("Top 10 Average", EnergyPerProc, "values per thread for this trial:")
+	for event in top10er.getSortedEventNames():
+		print(event, derived.getExclusive(thread, event, EnergyPerProc))
+	print()
+	print(mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, EnergyPerProc))
+	print()
 
 	# compute the floating point operations per joule per event
-	print "Computing FP_OPS/joule..."
+	print("Computing FP_OPS/joule...")
 	derived, FlopsPerJoule = getFlopsPerJoule(derived, EnergyPerProc)
 
 	# iterate over events, output inefficiency derived metric
-	print
-	print "Top 10 Average", FlopsPerJoule, "values per thread for this trial:"
-	for event in top10er.getSortedEventNames():
-		print event, derived.getExclusive(thread, event, FlopsPerJoule)
-	print
-	print mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, FlopsPerJoule)
-	print
+	print()
+	print("Top 10 Average", FlopsPerJoule, "values per thread for this trial:")
+	for event in top10er.getSortedEventNames():
+		print(event, derived.getExclusive(thread, event, FlopsPerJoule))
+	print()
+	print(mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, FlopsPerJoule))
+	print()
 
 	# compute the floating point operations per joule per event
-	print "Computing Instructions Per Cycle..."
+	print("Computing Instructions Per Cycle...")
 	derived, IPC = getIPC(derived)
 
 	# iterate over events, output inefficiency derived metric
-	print
-	print "Top 10 Average", IPC, "values per thread for this trial:"
-	for event in top10er.getSortedEventNames():
-		print event, derived.getExclusive(thread, event, IPC)
-	print
-	print mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, IPC)
-	print mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, "PAPI_TOT_INS")
-	print
+	print()
+	print("Top 10 Average", IPC, "values per thread for this trial:")
+	for event in top10er.getSortedEventNames():
+		print(event, derived.getExclusive(thread, event, IPC))
+	print()
+	print(mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, IPC))
+	print(mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, "PAPI_TOT_INS"))
+	print()
 
 	# compute the floating point operations per joule per event
-	print "Computing Issued Per Cycle..."
+	print("Computing Issued Per Cycle...")
 	derived, issuedPerCycle = getIssuedPerCycle(derived)
 
 	# iterate over events, output inefficiency derived metric
-	print
-	print "Top 10 Average", issuedPerCycle, "values per thread for this trial:"
-	for event in top10er.getSortedEventNames():
-		print event, derived.getExclusive(thread, event, issuedPerCycle)
-	print
-
-	print mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, issuedPerCycle)
-	print mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, "PAPI_TOT_IIS")
-	print
-
-	print "Time to completion..."
-	print
-	for event in top10er.getSortedEventNames():
-		print event, derived.getExclusive(thread, event, derived.getTimeMetric())/1000000
-	print
-
-	print mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, derived.getTimeMetric())/1000000
+	print()
+	print("Top 10 Average", issuedPerCycle, "values per thread for this trial:")
+	for event in top10er.getSortedEventNames():
+		print(event, derived.getExclusive(thread, event, issuedPerCycle))
+	print()
+
+	print(mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, issuedPerCycle))
+	print(mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, "PAPI_TOT_IIS"))
+	print()
+
+	print("Time to completion...")
+	print()
+	for event in top10er.getSortedEventNames():
+		print(event, derived.getExclusive(thread, event, derived.getTimeMetric())/1000000)
+	print()
+
+	print(mainEvent, "INCLUSIVE: ", derived.getInclusive(thread, mainEvent, derived.getTimeMetric())/1000000)
 
 	# process the rules
 	#RuleHarness.getInstance().processRules()
 
-	print "---------------- JPython test script end -------------"
+	print("---------------- JPython test script end -------------")
 
 if __name__ == "__main__":
 	main()
--- a/tools/src/perfexplorer/openuh/script.py	(original)
--- b/tools/src/perfexplorer/openuh/script.py	(refactored)
@@ -31,14 +31,14 @@
 
 def loadRules():
 	global ruleHarness
-	print "Loading Rules..."
+	print("Loading Rules...")
 	ruleHarness = RuleHarness.useGlobalRules("rules/GeneralRules.drl")
 	ruleHarness.addRules("rules/ApplicationRules.drl")
 	ruleHarness.addRules("rules/MachineRules.drl")
 	return 
 
 def loaddata():
-	print "loading the data..."
+	print("loading the data...")
 	Utilities.setSession("openuh")
 	#Utilities.setSession("perfdmf")
 	#trial = TrialMeanResult(Utilities.getTrial("fortran", "test", "O3-2048-real.8-bounds"))
@@ -246,8 +246,8 @@
 	return input, newMetrics
 
 
-print "--------------- JPython test script start ------------"
-print "doing single trial analysis for mm on gomez"
+print("--------------- JPython test script start ------------")
+print("doing single trial analysis for mm on gomez")
 
 # create a rulebase for processing
 #loadRules()
@@ -273,34 +273,34 @@
 derived, newMetrics = deriveMetrics(extracted)
 for thread in derived.getThreads():
 	for metric in newMetrics:
-		print event, metric, derived.getInclusive(thread, event, metric)
-
-print
+		print(event, metric, derived.getInclusive(thread, event, metric))
+
+print()
 
 # get the HP stall percentages
 percentages, newMetrics = stallHPPercentages(derived)
 for thread in percentages.getThreads():
 	for metric in newMetrics:
-		print event, metric, "%.2f%%" % (percentages.getInclusive(thread, event, metric)*100.0)
-
-print
+		print(event, metric, "%.2f%%" % (percentages.getInclusive(thread, event, metric)*100.0))
+
+print()
 
 # get the stall percentages
 percentages, newMetrics = stallPercentages(derived)
 for thread in percentages.getThreads():
 	for metric in newMetrics:
-		print event, metric, "%.2f%%" % (percentages.getInclusive(thread, event, metric)*100.0)
-
-print
+		print(event, metric, "%.2f%%" % (percentages.getInclusive(thread, event, metric)*100.0))
+
+print()
 
 # get the HP stall percentages, breakdown of fpstalls
 percentages, newMetrics = stallL1BreakdownPercentages(derived)
 for thread in percentages.getThreads():
 	for metric in newMetrics:
-		print event, metric, "%.2f%%" % (percentages.getInclusive(thread, event, metric)*100.0)
-
-print
+		print(event, metric, "%.2f%%" % (percentages.getInclusive(thread, event, metric)*100.0))
+
+print()
 
 #RuleHarness.getInstance().processRules()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/openuh/totalStalls.py	(original)
--- b/tools/src/perfexplorer/openuh/totalStalls.py	(refactored)
@@ -31,12 +31,12 @@
 
 def loadRules():
 	global ruleHarness
-	print "Loading Rules..."
+	print("Loading Rules...")
 	ruleHarness = RuleHarness.useGlobalRules("openuh/OpenUHRules.drl")
 	return 
 
 def loaddata():
-	print "loading the data..."
+	print("loading the data...")
 	Utilities.setSession("openuh")
 	#Utilities.setSession("perfdmf")
 	#trial = TrialMeanResult(Utilities.getTrial("fortran", "test", "O3-2048-real.8-bounds"))
@@ -252,8 +252,8 @@
 	return input, newMetrics
 
 
-print "--------------- JPython test script start ------------"
-print "doing single trial analysis for mm on gomez"
+print("--------------- JPython test script start ------------")
+print("doing single trial analysis for mm on gomez")
 
 # create a rulebase for processing
 loadRules()
@@ -262,14 +262,14 @@
 trial = loaddata()
 #event = "LOOP #2 [file:/mnt/netapp/home1/khuck/openuh/src/fpga/msap.c <65, 158>]"
 #event = "diff_coeff__"
-print "main event: ", trial.getMainEvent()
-print "time metric: ", trial.getTimeMetric()
+print("main event: ", trial.getMainEvent())
+print("time metric: ", trial.getTimeMetric())
 
 # extract the non-callpath events
 extracted = extractNonCallpath(trial)
 
 # get the stall percentages
-print "Breakdown of Total Stalls:"
+print("Breakdown of Total Stalls:")
 derived, newMetrics = deriveMetrics(extracted)
 percentages, newMetrics = stallPercentages(derived)
 for event in percentages.getEvents():
@@ -277,7 +277,7 @@
 		for metric in newMetrics:
 			#print event, metric, "%.2f%%" % (percentages.getInclusive(thread, event, metric)*100.0)
 			MeanEventFact.evaluateMetric(percentages, event, metric)
-print
+print()
 
 # get the HP stall percentages, breakdown of fpstalls
 # print "Breakdown of FP Stalls:"
@@ -301,4 +301,4 @@
 
 RuleHarness.getInstance().processRules()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/rules/cluster.py	(original)
--- b/tools/src/perfexplorer/rules/cluster.py	(refactored)
@@ -6,14 +6,14 @@
 
 def loadRules():
 	global ruleHarness
-	print "Loading Rules..."
+	print("Loading Rules...")
 	ruleHarness = RuleHarness.useGlobalRules("rules/GeneralRules.drl")
 	ruleHarness.addRules("rules/ApplicationRules.drl")
 	ruleHarness.addRules("rules/MachineRules.drl")
 	return 
 
 def loaddata():
-	print "loading the data..."
+	print("loading the data...")
 	#from home
 	Utilities.setSession("localhost:5432/perfdmf")
 	trial = TrialResult(Utilities.getTrial("sweep3d", "jaguar", "16"))
@@ -29,7 +29,7 @@
 	return extractor.processData().get(0)
 
 def getTop5(input):
-	print "Getting top 5 events (sorted by exclusive time)..."
+	print("Getting top 5 events (sorted by exclusive time)...")
 	getTop5 = TopXEvents(input, input.getTimeMetric(), AbstractResult.EXCLUSIVE, 5)
 	top5 = getTop5.processData().get(0)
 
@@ -43,9 +43,9 @@
 
 
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
-print "doing single trial analysis for gtc on jaguar"
+print("doing single trial analysis for gtc on jaguar")
 
 # create a rulebase for processing
 # loadRules()
@@ -63,4 +63,4 @@
 
 # RuleHarness.getInstance().processRules()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/rules/miranda.py	(original)
--- b/tools/src/perfexplorer/rules/miranda.py	(refactored)
@@ -5,14 +5,14 @@
 False = 0
 
 def loadRules():
-	print "Loading Rules..."
+	print("Loading Rules...")
 	ruleHarness = RuleHarness.useGlobalRules("rules/GeneralRules.drl")
 	ruleHarness.addRules("rules/ApplicationRules.drl")
 	ruleHarness.addRules("rules/MachineRules.drl")
 	return 
 
 def loaddata():
-	print "loading the data..."
+	print("loading the data...")
 	Utilities.setSession("spaceghost")
 	trial = Utilities.getTrial("Miranda", "BlueGeneL", "8K.old")
 
@@ -22,7 +22,7 @@
 	return trialResult, trialMetadata
 
 def getTop10(input):
-	print "Getting top 10 events (sorted by exclusive time)..."
+	print("Getting top 10 events (sorted by exclusive time)...")
 	getTop10 = TopXEvents(input, input.getTimeMetric(), AbstractResult.EXCLUSIVE, 10)
 	top10 = getTop10.processData().get(0)
 	return top10
@@ -33,8 +33,8 @@
 	RuleHarness.getInstance().assertObject(outputs.get(0));
 	return outputs
 
-print "--------------- JPython test script start ------------"
-print "doing single trial correlation analysis for Miranda on BGL"
+print("--------------- JPython test script start ------------")
+print("doing single trial correlation analysis for Miranda on BGL")
 # create a rulebase for processing
 loadRules()
 # load the trial
@@ -43,4 +43,4 @@
 top10 = getTop10(trialResult)
 correlateMetadata(top10, trialMetadata)
 RuleHarness.getInstance().processRules()
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/rules/rules.py	(original)
--- b/tools/src/perfexplorer/rules/rules.py	(refactored)
@@ -7,7 +7,7 @@
 False = 0
 
 def rules():
-	print "doing phase test for gtc on jaguar"
+	print("doing phase test for gtc on jaguar")
 	# load the trial
 	Utilities.setSession("perfdmf.test")
 	baseline = Utilities.getTrial("gtc_bench", "superscaling.jaguar", "64")
@@ -17,8 +17,8 @@
 	diff.addInput(comparison)
 	diff.processData()
 	metaDiff = DifferenceMetadataOperation(baseline, comparison)
-	print metaDiff.differencesAsString()
-	print "****** Processing Super Duper Rules! ******"
+	print(metaDiff.differencesAsString())
+	print("****** Processing Super Duper Rules! ******")
 	ruleHarness = RuleHarness("rules/GeneralRules.drl")
 	ruleHarness.addRules("rules/ApplicationRules.drl")
 	ruleHarness.addRules("rules/MachineRules.drl")
@@ -26,14 +26,14 @@
 	ruleHarness.assertObject(diff)
 	ruleHarness.processRules()
 
-	print "got the data"
+	print("got the data")
 
 	return
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
 rules()
 
 # pe.exit()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/rules/scdemo1.py	(original)
--- b/tools/src/perfexplorer/rules/scdemo1.py	(refactored)
@@ -8,14 +8,14 @@
 
 def loadRules():
 	global ruleHarness
-	print "Loading Rules..."
+	print("Loading Rules...")
 	ruleHarness = RuleHarness.useGlobalRules("rules/GeneralRules.drl")
 	ruleHarness.addRules("rules/ApplicationRules.drl")
 	ruleHarness.addRules("rules/MachineRules.drl")
 	return 
 
 def loaddata():
-	print "loading the data..."
+	print("loading the data...")
 	#from home
 	# Utilities.setSession("localhost:5432/perfdmf")
 	# trial = TrialMeanResult(Utilities.getTrial("gtc_bench", "jaguar", "64"))
@@ -31,7 +31,7 @@
 	return extractor.processData().get(0)
 
 def getTop10andMain(input):
-	print "Getting top 10 events (sorted by exclusive time)..."
+	print("Getting top 10 events (sorted by exclusive time)...")
 	getTop10 = TopXEvents(input, input.getTimeMetric(), AbstractResult.EXCLUSIVE, 10)
 	top10 = getTop10.processData().get(0)
 	sorted = top10.getEvents()
@@ -73,11 +73,11 @@
 	else:
 		metric8Value = 0.0;
 	
-	print event, value, metric1Value, metric2Value, metric4Value, metric5Value, metric7Value, metric8Value
+	print(event, value, metric1Value, metric2Value, metric4Value, metric5Value, metric7Value, metric8Value)
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
-print "doing single trial analysis for gtc on jaguar"
+print("doing single trial analysis for gtc on jaguar")
 
 # create a rulebase for processing
 loadRules()
@@ -107,4 +107,4 @@
 
 RuleHarness.getInstance().processRules()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/rules/scdemo2.py	(original)
--- b/tools/src/perfexplorer/rules/scdemo2.py	(refactored)
@@ -5,14 +5,14 @@
 False = 0
 
 def loadRules():
-	print "Loading Rules..."
+	print("Loading Rules...")
 	ruleHarness = RuleHarness.useGlobalRules("rules/GeneralRules.drl")
 	ruleHarness.addRules("rules/ApplicationRules.drl")
 	ruleHarness.addRules("rules/MachineRules.drl")
 	return 
 
 def loaddata():
-	print "loading the data..."
+	print("loading the data...")
 	#from home
 	Utilities.setSession("localhost:5432/perfdmf")
 	# from office
@@ -31,7 +31,7 @@
 	return extractor.processData().get(0)
 
 def getTop5(input):
-	print "Getting top 5 events (sorted by exclusive time)..."
+	print("Getting top 5 events (sorted by exclusive time)...")
 	getTop5 = TopXEvents(input, input.getTimeMetric(), AbstractResult.EXCLUSIVE, 5)
 	top5 = getTop5.processData().get(0)
 
@@ -46,9 +46,9 @@
 
 
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
-print "doing single trial analysis for Sweep3D on jaguar"
+print("doing single trial analysis for Sweep3D on jaguar")
 
 # create a rulebase for processing
 loadRules()
@@ -66,4 +66,4 @@
 
 RuleHarness.getInstance().processRules()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/perfexplorer/rules/scdemo3.py	(original)
--- b/tools/src/perfexplorer/rules/scdemo3.py	(refactored)
@@ -7,14 +7,14 @@
 
 def loadRules():
 	global ruleHarness
-	print "Loading Rules..."
+	print("Loading Rules...")
 	ruleHarness = RuleHarness.useGlobalRules("rules/GeneralRules.drl")
 	ruleHarness.addRules("rules/ApplicationRules.drl")
 	ruleHarness.addRules("rules/MachineRules.drl")
 	return 
 
 def loaddata():
-	print "loading the data..."
+	print("loading the data...")
 	#from home
 	Utilities.setSession("localhost:5432/perfdmf")
 	baseline = TrialMeanResult(Utilities.getTrial("gtc_bench", "jaguar", "64"))
@@ -32,7 +32,7 @@
 	return extractor.processData().get(0)
 
 def getTop5(baseline, comparison):
-	print "Getting top 5 events (sorted by exclusive time)..."
+	print("Getting top 5 events (sorted by exclusive time)...")
 	# get the top 5 events for the baseline
 	getTop5 = TopXEvents(baseline, baseline.getTimeMetric(), AbstractResult.EXCLUSIVE, 5)
 	baseEvents = getTop5.processData().get(0).getEvents()
@@ -69,9 +69,9 @@
 	diff.processData();
 	RuleHarness.getInstance().assertObject(diff);
 
-print "--------------- JPython test script start ------------"
+print("--------------- JPython test script start ------------")
 
-print "doing single trial analysis for gtc on jaguar"
+print("doing single trial analysis for gtc on jaguar")
 
 # create a rulebase for processing
 loadRules()
@@ -99,4 +99,4 @@
 
 RuleHarness.getInstance().processRules()
 
-print "---------------- JPython test script end -------------"
+print("---------------- JPython test script end -------------")
--- a/tools/src/pycoolr/src/pycoolrgui/pycoolr-plot/clr_utils.py	(original)
--- b/tools/src/pycoolr/src/pycoolrgui/pycoolr-plot/clr_utils.py	(refactored)
@@ -26,7 +26,7 @@
     for jt in jtext:
         try:
             j = json.loads(jt)
-        except ValueError, e:
+        except ValueError as e:
             continue
         ret.append(j)
 
--- a/tools/src/pycoolr/src/pycoolrgui/pycoolr-plot/coolr-back.py	(original)
--- b/tools/src/pycoolr/src/pycoolrgui/pycoolr-plot/coolr-back.py	(refactored)
@@ -1,7 +1,7 @@
 #!/usr/bin/env python
 
 #import sys, os, re, _thread, signal
-import sys, os, re, thread, signal
+import sys, os, re, _thread, signal
 #from cStringIO import StringIO
 from io import StringIO
 import subprocess
@@ -146,10 +146,10 @@
     with open(cfgfn) as f:
         cfgtmp = json.load(f)
         # override if cfg defines any
-        for k in cfgtmp.keys():
+        for k in list(cfgtmp.keys()):
             cfg[k] = cfgtmp[k]
         # override if specifed as cmd option
-        for k in ocfg.keys():
+        for k in list(ocfg.keys()):
             cfg[k] = ocfg[k]
 
 
@@ -157,21 +157,21 @@
     targetnode = os.environ['PYCOOLR_NODE']
     #targetnode = cfg['masternode']
 if len(enclaves) == 0:
-    if cfg.has_key('enclaves'):
+    if 'enclaves' in cfg:
         enclaves = cfg['enclaves']
 
 #print 'masternode:', cfg['masternode']
-print('targetnode:', targetnode)
-print('enclaves:', enclaves)
+print(('targetnode:', targetnode))
+print(('enclaves:', enclaves))
 
 if len(appcfgfn) > 0:
     with open(appcfgfn) as f:
         appcfg = json.load(f)
-    for k in appcfg.keys():
+    for k in list(appcfg.keys()):
         cfg[k] = appcfg[k]
 
-    if not (cfg.has_key('appname') and cfg.has_key('appsamples')):
-        print("Please double check %s: appname or appsamples tags" % appcfgfn)
+    if not ('appname' in cfg and 'appsamples' in cfg):
+        print(("Please double check %s: appname or appsamples tags" % appcfgfn))
         sys.exit(1)
 
 
@@ -187,7 +187,7 @@
 try:
     logf = open(cfg["outputfn"], 'w', 0) # unbuffered write
 except:
-    print('unable to open', cfg["outputfn"])
+    print(('unable to open', cfg["outputfn"]))
 
 
 #if not fakemode:
@@ -210,11 +210,11 @@
 params['enclaves'] = enclaves
 
 if sys.version_info[0] < 3:
-    import Tkinter
+    import tkinter
     #from Tkinter import *
-    import tkFileDialog
-    import tkFont
-    from tkFont import Font
+    import tkinter.filedialog
+    import tkinter.font
+    from tkinter.font import Font
     #from Tkinter.FileDialog import askopenfilename
 else:
     import tkinter
@@ -227,7 +227,7 @@
   def __init__(self, master, row=2, col=3):
 
         # Create a container
-        self.frame = Tkinter.Frame(master,width=200,height=100)
+        self.frame = tkinter.Frame(master,width=200,height=100)
         # Create 2 buttons
         #self.button_left = Tkinter.Button(frame,text="< Decrease Slope",
         #                               command=self.decrease)
@@ -243,7 +243,7 @@
         self.nbsamples = params['cfg']['nbsamples']
         #self.nbcvars = params['cfg']['nbcvars']
         self.listmetrics = params['cfg']['metrics']
-        print("self.listmetrics",self.listmetrics)
+        print(("self.listmetrics",self.listmetrics))
         #self.listsamples = params['cfg']['appsamples']
         self.nbGraphs = params['cfg']['nbgraphs']
       
@@ -268,7 +268,7 @@
           self.btncvarsupdate = None
 
         self.metrics = params['cfg']['metrics']
-        print("self.metrics", self.metrics)
+        print(("self.metrics", self.metrics))
         #self.ranks = params['cfg']['ranks']
         self.ranks = [None] * self.nbsamples
         self.procs = [None] * self.nbsamples
@@ -318,14 +318,14 @@
         self.listFontFamily = ['serif', 'sans-serif', 'cursive', 'fantasy', 'monospace']
         self.listFontWeight = ['ultralight','light','normal','regular','book','medium','roman','semibold','demibold','demi','bold','heavy','extra bold','black']
 
-        self.list_fonts = list( tkFont.families() )
+        self.list_fonts = list( tkinter.font.families() )
 
         self.selectedFontPolicy = None
         self.selectedFontSize = None
         self.selectedFontWeight = None
        
         # create a custom font
-        self.customFont = tkFont.Font(family="Helvetica", size=12)
+        self.customFont = tkinter.font.Font(family="Helvetica", size=12)
  
         for idx in range(params['cfg']['nbgraphs']):
          self.listUsedGraphs.append(-1)
@@ -414,7 +414,7 @@
         try:       
           root.config(menu=menubar)
         except AttributeError as attErr:
-          print('menu Exception: ', type(attErr), attErr)
+          print(('menu Exception: ', type(attErr), attErr))
 
         #self.winPvars()
         #self.winCvars()
@@ -422,27 +422,27 @@
         self.subSpawn()
 
   def try_execute(self, c, statement, parameters=None):
-    print ("statement: ", statement)
-    print ("parameters: ", parameters)
+    print(("statement: ", statement))
+    print(("parameters: ", parameters))
     try:
         if parameters:
             c.execute(statement,parameters);
         else:
             c.execute(statement);
     except sqlite3.Error as e:
-        print("database error...", e.args[0])
+        print(("database error...", e.args[0]))
 
   def open_connection(self):
     global conn
     # check for file to exist
     #print ("Checking for file: ", sqlite_file)
-    print("Checking for file: ", self.sosdbfile)
+    print(("Checking for file: ", self.sosdbfile))
     while not os.path.exists(self.sosdbfile):
-        print("Waiting on file: ", self.sosdbfile)
+        print(("Waiting on file: ", self.sosdbfile))
         time.sleep(1)
 
     #print("Connecting to: ", sqlite_file)
-    print("Connecting to: ", self.sosdbfile)
+    print(("Connecting to: ", self.sosdbfile))
     # Connecting to the database file
     #conn = sqlite3.connect(sqlite_file)
     #fd = os.open(sqlite_file, os.O_RDONLY)
@@ -481,14 +481,14 @@
       
   def browsefontpolicy(self):
         print('browsefontpolicy')
-        fontpolicydiag = tkFileDialog.askopenfilename(filetypes=[("Text files","*.fft")])
+        fontpolicydiag = tkinter.filedialog.askopenfilename(filetypes=[("Text files","*.fft")])
 
   def onselectFontPolicy(self,evt):
         w = evt.widget
         selection = w.curselection()
         value = w.get(selection[0])
         self.selectedFontPolicy = value
-        print('select font: ', value)
+        print(('select font: ', value))
 
   def onselectFontSize(self, evt):
        print('select font size')
@@ -496,7 +496,7 @@
        selection = w.curselection()
        value = w.get(selection[0])
        self.selectedFontSize = value
-       print('select font: ', value)
+       print(('select font: ', value))
 
   def onselectFontWeight(self, evt):
        print('select font weight')
@@ -504,7 +504,7 @@
        selection = w.curselection()
        value = w.get(selection[0])
        self.selectedFontWeight = value
-       print('select font: ', value)
+       print(('select font: ', value))
 
   def loadFontPolicy(self):
         fontpolicydiag = askopenfilename(filetypes=(("*.fft"))) 
@@ -597,9 +597,9 @@
         #f1 = Tk.Frame(pvarswin,width=150,height=100) 
         s1 = Tk.Scrollbar(self.f1) 
 	#l1 = Tk.Listbox(f1,selectmode='multiple',width=80,height=40)
-        print("self.listmetrics",self.listmetrics)
-        print("len(self.listmetrics)",len(self.listmetrics))
-        print("self.nbsamples",self.nbsamples)
+        print(("self.listmetrics",self.listmetrics))
+        print(("len(self.listmetrics)",len(self.listmetrics)))
+        print(("self.nbsamples",self.nbsamples))
         for i in range(self.nbsamples): self.l1.insert(i, self.listmetrics[i]) 
         s1.config(command = self.l1.yview) 
         self.l1.config(yscrollcommand = s1.set) 
@@ -661,7 +661,7 @@
 
   def clearplot(self,idxGraph):
 
-       print('clearplot: idxGraph=', idxGraph)
+       print(('clearplot: idxGraph=', idxGraph))
        ax = self.ax[idxGraph]
        ax.cla()    
        #ax.clf()
@@ -735,7 +735,7 @@
                         total_val=total_val+ref4
                         num_vals=num_vals+1
                         mean_val=total_val/num_vals
-                        print('display record ref4='+str(ref4))
+                        print(('display record ref4='+str(ref4)))
                         self.data_lr[i].add(t,ref4)
                         #self.data_lr[i].add(t,mean_val)
                         goodrecord=1
@@ -810,7 +810,7 @@
                 try:
                   ax.cla()
                 except Exception as errCla:
-                  print('update_gui: Error cla(): ', type(errCla), errCla)
+                  print(('update_gui: Error cla(): ', type(errCla), errCla))
 
                 ax.set_xlim([t-gxsec, t])
                 #print 'get x and y'
@@ -894,7 +894,7 @@
 
         #print 'parse graphs'
         metric_value = max(sample[1],0)
-        print("metric_value",metric_value)
+        print(("metric_value",metric_value))
         numeric = re.search(r'\d+', metric_value)
         metric_value_num = numeric.group()
         metric_value_float = float(metric_value_num)
@@ -920,7 +920,7 @@
         try:
            ax.cla()
         except Exception as errCla:
-          print('update_gui: Error cla(): ', type(errCla), errCla)
+          print(('update_gui: Error cla(): ', type(errCla), errCla))
 
         ax.set_xlim([pack_time-gxsec, pack_time])
         #print 'get x and y'
@@ -1030,7 +1030,7 @@
         try:
            ax.cla()
         except Exception as errCla:
-          print('update_gui: Error cla(): ', type(errCla), errCla)
+          print(('update_gui: Error cla(): ', type(errCla), errCla))
 
         ax.set_xlim([pack_time-gxsec, pack_time])
         #print 'get x and y'
@@ -1158,7 +1158,7 @@
            try:
              j = json.loads(payload)
            except ValueError as e:
-             print('Failed to load json data: %s' %e)
+             print(('Failed to load json data: %s' %e))
              continue
              #return False
 
@@ -1193,7 +1193,7 @@
          if 'node' not in e and\
             'sample' not in e and\
             'time' not in e:
-             print('Ignore this invalid sample:', json.dumps(e))
+             print(('Ignore this invalid sample:', json.dumps(e)))
              continue
 
          #print 'set timestamp'
@@ -1225,7 +1225,7 @@
        try:
          self.canvas.draw()
        except Exception as errDraw:
-         print('Error drawing canvas: ', type(errDraw), errDraw)
+         print(('Error drawing canvas: ', type(errDraw), errDraw))
        #plt.draw()
 
        profile_t7 = time.time()
@@ -1307,7 +1307,7 @@
     all_rows = c.fetchall()
     ts = np.array([x[0] for x in all_rows])
     min_timestamp = ts[0]
-    print("min timestamp: ", min_timestamp)
+    print(("min timestamp: ", min_timestamp))
 
 
   def get_min_timestamp(self):
@@ -1315,25 +1315,25 @@
     sql_statement = ("SELECT min(time_pack) FROM viewCombined;")
     print("get_min_timestamp Executing query")
  
-    print("sql statement: ", sql_statement)
+    print(("sql statement: ", sql_statement))
     #self.try_execute(c, sql_statement)
     os.environ['SOS_SQL'] = sql_statement
     sos_bin_path = os.environ.get('SOS_BIN_DIR')
-    print('SOS BIN path: ', sos_bin_path)
+    print(('SOS BIN path: ', sos_bin_path))
     os.system('cd '+ sos_bin_path)
-    print('current dir: ', os.getcwd())
+    print(('current dir: ', os.getcwd()))
     # Redirect stdout of passed command into a string
 
     soscmd = sos_bin_path + "/demo_app_silent --sql SOS_SQL"
-    print('soscmd: ', soscmd)
+    print(('soscmd: ', soscmd))
     tmp_res_min_ts_sql = subprocess.check_output(soscmd, shell=True)
 
     #self.res_min_ts_sql = tmp_res_min_ts_sql.splitlines()
-    print('get min ts: tmp res sql=', tmp_res_min_ts_sql)
+    print(('get min ts: tmp res sql=', tmp_res_min_ts_sql))
     res_min_ts_sql = tmp_res_min_ts_sql.splitlines()
-    print("List of result SQL MIN TS: ", res_min_ts_sql)
+    print(("List of result SQL MIN TS: ", res_min_ts_sql))
     min_ts_rows = res_min_ts_sql[1].split(",")
-    print("List of result SQL MIN TS values: ", min_ts_rows)
+    print(("List of result SQL MIN TS values: ", min_ts_rows))
     # Remove first element of SQL result 
     #ts = np.array([x[0] for x in min_ts_rows])
     str_min_timestamp = min_ts_rows[0].replace('\"', '')
@@ -1375,31 +1375,31 @@
     sql_statement = ("SELECT value_name, value, time_pack FROM viewCombined WHERE value_name LIKE '" + metric+ "'")
     #sql_statement = ("SELECT * FROM viewCombined WHERE value_name LIKE '" + metric+ "'")
    
-    print("sql statement: ", sql_statement )
+    print(("sql statement: ", sql_statement ))
     #self.try_execute(c, sql_statement)
     os.environ['SOS_SQL'] = sql_statement
     sos_bin_path = os.environ.get('SOS_BIN_DIR')
-    print('SOS BIN path: ', sos_bin_path)
+    print(('SOS BIN path: ', sos_bin_path))
     os.system('cd '+ sos_bin_path)  
-    print('current dir: ', os.getcwd()) 
+    print(('current dir: ', os.getcwd())) 
     # Redirect stdout of passed command into a string
    
     soscmd = sos_bin_path + "/demo_app_silent --sql SOS_SQL"
-    print('soscmd: ', soscmd)
+    print(('soscmd: ', soscmd))
     tmp_res_sql = subprocess.check_output(soscmd, shell=True)
 
     self.try_execute(c, sql_statement)
 
     #print 'stdout of SOS demo: ', sys.stdout
     #self.res_sql = resultstdout.getvalue()
-    print('tmp res_sql: ', tmp_res_sql)
+    print(('tmp res_sql: ', tmp_res_sql))
     
     self.res_sql = tmp_res_sql.splitlines()
     # REmove first element of SQL result 
     self.res_sql.pop(0)
 
     for item_sql in self.res_sql:
-      print('res sql: ', item_sql) 
+      print(('res sql: ', item_sql)) 
       
  
   # Call demo with SQL statement given as argument and store standard output
@@ -1429,14 +1429,14 @@
     while self.ranks.size == 0:
         time.sleep(1)
         self.ranks,self.procs = self.get_ranks(self.conn)
-    print ("ranks: ", self.ranks)
+    print(("ranks: ", self.ranks))
 
     # get the number of nodes
     self.nodes,self.noderanks = self.get_nodes(self.conn)
     while self.nodes.size == 0:
         time.sleep(1)
         nodes,self.noderanks = self.get_nodes(self.conn)
-    print ("nodes: ", self.nodes)
+    print(("nodes: ", self.nodes))
 
     self.get_min_timestamp_db(self.conn)
     #resize the figure
@@ -1463,7 +1463,7 @@
     print('SOS: Execute demo app')
     sos_path = os.environ.get('SOS_BUILD_DIR') 
     self.sos_bin_path = sos_path+"/bin"
-    print('SOS BIN PATH: ', self.sos_bin_path)
+    print(('SOS BIN PATH: ', self.sos_bin_path))
     os.system("cd "+ self.sos_bin_path) 
 
 
@@ -1475,7 +1475,7 @@
 
     self.opendb()
 
-    print("metrics: ", self.metrics)
+    print(("metrics: ", self.metrics))
     #self.get_min_timestamp()  
  
     while True:  
@@ -1511,7 +1511,7 @@
            countsamples = 0
            for sample in self.rows[j]:
              params['ts'] = 0
-             print 'PYCOOLR sample: ', sample
+             print('PYCOOLR sample: ', sample)
              #self.req_sql(self.conn, self.ranks, self.rows)
              profile_t2 = time.time()
              self.lock.acquire()
@@ -1541,7 +1541,7 @@
          if self.listRecordSample[i] != -1:
            j = self.listRecordSample[i]
      
-           print('readsosmetrics: i=%d, j=%d' %(i,j))
+           print(('readsosmetrics: i=%d, j=%d' %(i,j)))
            
            #rank = self.ranks[j]
            #rank2 = self.ranks2[j]
@@ -1559,7 +1559,7 @@
            self.rows[j] = self.conn.fetchall()
            #print 'rows: ', self.rows[j]
            if len(self.rows[j]) <= 0:
-             print("Error: query returned no rows.",)
+             print(("Error: query returned no rows.",))
            else:
              goodrecord = 1
          
@@ -1646,11 +1646,11 @@
 
 
            payload.strip()
-           print('payload =',payload)
+           print(('payload =',payload))
            try:
              j = json.loads(payload)
            except ValueError as e:
-             print('Failed to load json data: %s' %e)
+             print(('Failed to load json data: %s' %e))
              continue
              #return False
 
@@ -1685,7 +1685,7 @@
          if 'node' not in e and\
             'sample' not in e and\
             'time' not in e:
-             print('Ignore this invalid sample:', json.dumps(e))
+             print(('Ignore this invalid sample:', json.dumps(e)))
              continue
 
          #print 'set timestamp'
@@ -1755,20 +1755,20 @@
          print('subSpawn: load beacon subscriber library')
          envlibpath = os.environ['PYCOOLR_LIBPATH']
          libarbjsonbeep = cdll.LoadLibrary(envlibpath+'/libarbitraryjsonbeepmulsub.so')
-         thread.start_new_thread(self.subscribe,(libarbjsonbeep,))
-         thread.start_new_thread(self.readEvents,(libarbjsonbeep,))
+         _thread.start_new_thread(self.subscribe,(libarbjsonbeep,))
+         _thread.start_new_thread(self.readEvents,(libarbjsonbeep,))
          #thread.start_new_thread(self.readEvents,(libarbjsonbeep,))
        except Exception as errThread:
-         print("Error: unable to start thread: ", errThread)
+         print(("Error: unable to start thread: ", errThread))
 
      elif self.tool == "sos":
        try:
          #thread.start_new_thread(self.subscribe,(libarbjsonbeep,))
-         thread.start_new_thread(self.readsosmetrics,())
+         _thread.start_new_thread(self.readsosmetrics,())
          #thread.start_new_thread(self.readsosmetrics_db,())
       
        except Exception as errThread:
-         print('Error: unable to start thread: ', errThread)
+         print(('Error: unable to start thread: ', errThread))
 
 
      self.refresh_plot()
@@ -1801,7 +1801,7 @@
 
             self.selectedcvarsvalues[i] =  self.listcvarsentry[i].get()
             strcvarsvalues += self.selectedcvarsvalues[i]
-            print('numselectedcvars=%d, index=%d' % (self.numselectedcvars, i))
+            print(('numselectedcvars=%d, index=%d' % (self.numselectedcvars, i)))
             if i+1 < self.numselectedcvars:
               strcvarsmetrics += ","
               strcvarsvalues += ","
@@ -1814,7 +1814,7 @@
             #self.strcvars += "=" 
             #self.strcvars += self.selectedcvarsvalues[i]
             #strcvars += ","
-            print('numselectedcvars=%d, index=%d' % (self.numselectedcvars, i))
+            print(('numselectedcvars=%d, index=%d' % (self.numselectedcvars, i)))
             if i+1 < self.numselectedcvars:
               strcvarsmetrics += ","
               strcvarsvalues += ","
@@ -1825,9 +1825,9 @@
         #self.strcvars += ":"
         self.strcvars += strcvarsvalues
 
-        print("strcvarsmetrics: ", strcvarsmetrics)
-        print("strcvarsvalues: ", strcvarsvalues)
-        print("strcvars: ", self.strcvars)
+        print(("strcvarsmetrics: ", strcvarsmetrics))
+        print(("strcvarsvalues: ", strcvarsvalues))
+        print(("strcvars: ", self.strcvars))
 
         # Test if we have to communicate MPI_T CVARS in a Publish/Subscribe mode       
         if cvars_comm_mode == "pub":
@@ -1863,7 +1863,7 @@
 
         for i in range(len(selection)):
           value = w.get(selection[i])
-          print("selection:", selection, ": '%s'" % value)
+          print(("selection:", selection, ": '%s'" % value))
           self.selectedcvarsmetrics[i] = value
 
         if self.listlabelcvarsmetric:
@@ -1885,19 +1885,19 @@
         self.listcvarsarrayindexentry = [None] * len(selection)
         self.listcvarsarrayindex = [None] * len(selection)
 
-        print('selection: ', selection)
-        print('range selection: ', range(len(selection)))
-
-        for cvaritem, cvarindex in zip(selection, range(len(selection))):
+        print(('selection: ', selection))
+        print(('range selection: ', list(range(len(selection)))))
+
+        for cvaritem, cvarindex in zip(selection, list(range(len(selection)))):
 
           value = w.get(selection[cvarindex])
-          print('len selection: ', len(selection))
-          print('value of item %d: %s ' % (cvarindex, value))
-          print('cvaritem: ', cvaritem)
-          print('cvarindex= ', cvarindex)
-          print('cvarsindexrow= ', self.cvarsindexrow)
-
-          print('cfg cvars array:', self.listcfgcvarsarray[0])
+          print(('len selection: ', len(selection)))
+          print(('value of item %d: %s ' % (cvarindex, value)))
+          print(('cvaritem: ', cvaritem))
+          print(('cvarindex= ', cvarindex))
+          print(('cvarsindexrow= ', self.cvarsindexrow))
+
+          print(('cfg cvars array:', self.listcfgcvarsarray[0]))
           if value == self.listcfgcvarsarray[0]:
 
             self.listlabelcvarsmetric[cvarindex]=Tk.Label(self.stepCvarsUpdate,  text=value)
@@ -1945,7 +1945,7 @@
           #print "selection:", selection, ": '%s'" % value
          
         listintselection = [int (i) for i in selection]
-        print('listintselection: ', listintselection)
+        print(('listintselection: ', listintselection))
 
         for i in range(self.nbsamples):
           if (self.listSamplesAllocated[i] > -1) and (i not in listintselection):
@@ -1960,7 +1960,7 @@
               if self.listSamplesAllocated[j] == -1:    
                 #index = int(j)
                 self.listUsedGraphs[i] = j
-                print('graph %d allocated to sample %d' % (i, j))
+                print(('graph %d allocated to sample %d' % (i, j)))
                 self.listRecordSample[i] = j
                 self.listSamplesAllocated[j] = i
                 break
@@ -1986,7 +1986,7 @@
                 # Mark current graph as used
                 self.listUsedGraphs[j] = 1           
                 # Record the current graph as plotting the current sample
-                print('Record Sample %d for graph %d' %(index,j))
+                print(('Record Sample %d for graph %d' %(index,j)))
                 self.listRecordSample[j] = index
 
                 # Mark current sample as allocated to the current graph
@@ -2087,7 +2087,7 @@
          self.canvas.draw()
          #self.frame.update()
        except Exception as errDraw:
-         print('refresh_plot: Error drawing canvas: ', type(errDraw), errDraw)
+         print(('refresh_plot: Error drawing canvas: ', type(errDraw), errDraw))
        self.lock.release()
 
        self.root.after(1000,self.refresh_plot)      
@@ -2097,11 +2097,11 @@
        try:
          self.canvas.draw()
        except Exception as errDraw:
-         print('Error drawing canvas: ', type(errDraw), errDraw)
+         print(('Error drawing canvas: ', type(errDraw), errDraw))
 
   def checkfn(self, idx, text): 
        print('checkfn')
-       print('Check index=%d text=%s' % (idx,text))
+       print(('Check index=%d text=%s' % (idx,text)))
        #print 'Size of listbtnchecked[]= ', len(self.listbtnchecked)
        #self.listbtnchecked[idx] = 1
 
@@ -2110,7 +2110,7 @@
 #     print 'nothing'
       
 
-root = Tkinter.Tk()
+root = tkinter.Tk()
 
 app = Coolrsub(root,2,3)
 root.mainloop()
--- a/tools/src/pycoolr/src/pycoolrgui/pycoolr-plot/coolr-launch.py	(original)
--- b/tools/src/pycoolr/src/pycoolrgui/pycoolr-plot/coolr-launch.py	(refactored)
@@ -39,8 +39,8 @@
 try:
     opts, args = getopt.getopt(sys.argv[1:],
                                shortopt, longopt)
-except getopt.GetoptError, err:
-    print err
+except getopt.GetoptError as err:
+    print(err)
     usage()
     sys.exit(1)
 
@@ -66,21 +66,21 @@
     elif o in ("--ncols"):
         ocfg["ncols"]=int(a)
     elif o in ("--list"):
-        print ''
-        print '[available graph modules]'
-        print ''
+        print('')
+        print('[available graph modules]')
+        print('')
         for i in cfg["modnames"]:
-            print i
-        print ''
-        print ''
+            print(i)
+        print('')
+        print('')
         sys.exit(0)
     elif o in ("--mods"):
         ocfg["modnames"] = a.split(",")
 
 if len(args) < 1:
-    print ''
-    print 'No config file is specified.  Enabled the fake mode.'
-    print ''
+    print('')
+    print('No config file is specified.  Enabled the fake mode.')
+    print('')
     cfg["masternode"] = "frontend"
     cfg["drawexternal"] = "no"
     cfg["drawacpipwr"] = "no"
@@ -102,30 +102,30 @@
     with open(cfgfn) as f:
         cfgtmp = json.load(f)
         # override if cfg defines any
-        for k in cfgtmp.keys():
+        for k in list(cfgtmp.keys()):
             cfg[k] = cfgtmp[k]
         # override if specifed as cmd option
-        for k in ocfg.keys():
+        for k in list(ocfg.keys()):
             cfg[k] = ocfg[k]
 
 if len(targetnode) == 0 :
     targetnode = cfg['masternode']
 if len(enclaves) == 0:
-    if cfg.has_key('enclaves'):
+    if 'enclaves' in cfg:
         enclaves = cfg['enclaves']
 
-print 'masternode:', cfg['masternode']
-print 'targetnode:', targetnode
-print 'enclaves:', enclaves
+print('masternode:', cfg['masternode'])
+print('targetnode:', targetnode)
+print('enclaves:', enclaves)
 
 if len(appcfgfn) > 0:
     with open(appcfgfn) as f:
         appcfg = json.load(f)
-    for k in appcfg.keys():
+    for k in list(appcfg.keys()):
         cfg[k] = appcfg[k]
 
-    if not (cfg.has_key('appname') and cfg.has_key('appsamples')):
-        print "Please double check %s: appname or appsamples tags" % appcfgfn
+    if not ('appname' in cfg and 'appsamples' in cfg):
+        print("Please double check %s: appname or appsamples tags" % appcfgfn)
         sys.exit(1)
 
 
@@ -143,9 +143,9 @@
 try:
     logf = open(cfg["outputfn"], 'w', 0) # unbuffered write
 except:
-    print 'unable to open', cfg["outputfn"]
-
-print >>logf, json.dumps(info)
+    print('unable to open', cfg["outputfn"])
+
+print(json.dumps(info), file=logf)
 
 #if not fakemode:
 #    querycmds = cfg['querycmds']
@@ -180,7 +180,7 @@
 
 
 if sys.version_info[0] < 3:
-    import Tkinter as Tk
+    import tkinter as Tk
 else:
     import tkinter as Tk
 
@@ -221,7 +221,7 @@
   #root.after(2000,mainLoop)
 
 ngraphs = len(params['cfg']['appsamples'])
-print 'samples ', params['cfg']['appsamples']
+print('samples ', params['cfg']['appsamples'])
 data_lr = [listrotate2D(length=params['lrlen']) for i in range(ngraphs)]
 
 #fig = plt.figure( figsize=(cfg["figwidth"],cfg["figheight"]) )
--- a/tools/src/pycoolr/src/pycoolrgui/pycoolr-plot/coolr-sos-db.py	(original)
--- b/tools/src/pycoolr/src/pycoolrgui/pycoolr-plot/coolr-sos-db.py	(refactored)
@@ -1,6 +1,6 @@
 #!/usr/bin/env python
 
-import sys, os, re, thread, signal
+import sys, os, re, _thread, signal
 import multiprocessing
 import json
 import sqlite3
@@ -74,8 +74,8 @@
 try:
     opts, args = getopt.getopt(sys.argv[1:],
                                shortopt, longopt)
-except getopt.GetoptError, err:
-    print err
+except getopt.GetoptError as err:
+    print(err)
     usage()
     sys.exit(1)
 
@@ -101,22 +101,22 @@
     elif o in ("--ncols"):
         ocfg["ncols"]=int(a)
     elif o in ("--list"):
-        print ''
-        print '[available graph modules]'
-        print ''
+        print('')
+        print('[available graph modules]')
+        print('')
         for i in cfg["modnames"]:
-            print i
-        print ''
-        print ''
+            print(i)
+        print('')
+        print('')
         sys.exit(0)
     elif o in ("--mods"):
         ocfg["modnames"] = a.split(",")
 
 
 if len(args) < 1:
-    print ''
-    print 'No config file is specified.  Enabled the fake mode.'
-    print ''
+    print('')
+    print('No config file is specified.  Enabled the fake mode.')
+    print('')
     cfg["masternode"] = "frontend"
     cfg["drawexternal"] = "no"
     cfg["drawacpipwr"] = "no"
@@ -140,10 +140,10 @@
     with open(cfgfn) as f:
         cfgtmp = json.load(f)
         # override if cfg defines any
-        for k in cfgtmp.keys():
+        for k in list(cfgtmp.keys()):
             cfg[k] = cfgtmp[k]
         # override if specifed as cmd option
-        for k in ocfg.keys():
+        for k in list(ocfg.keys()):
             cfg[k] = ocfg[k]
 
 
@@ -151,21 +151,21 @@
     targetnode = os.environ['PYCOOLR_NODE']
     #targetnode = cfg['masternode']
 if len(enclaves) == 0:
-    if cfg.has_key('enclaves'):
+    if 'enclaves' in cfg:
         enclaves = cfg['enclaves']
 
 #print 'masternode:', cfg['masternode']
-print 'targetnode:', targetnode
-print 'enclaves:', enclaves
+print('targetnode:', targetnode)
+print('enclaves:', enclaves)
 
 if len(appcfgfn) > 0:
     with open(appcfgfn) as f:
         appcfg = json.load(f)
-    for k in appcfg.keys():
+    for k in list(appcfg.keys()):
         cfg[k] = appcfg[k]
 
-    if not (cfg.has_key('appname') and cfg.has_key('appsamples')):
-        print "Please double check %s: appname or appsamples tags" % appcfgfn
+    if not ('appname' in cfg and 'appsamples' in cfg):
+        print("Please double check %s: appname or appsamples tags" % appcfgfn)
         sys.exit(1)
 
 
@@ -181,7 +181,7 @@
 try:
     logf = open(cfg["outputfn"], 'w', 0) # unbuffered write
 except:
-    print 'unable to open', cfg["outputfn"]
+    print('unable to open', cfg["outputfn"])
 
 
 #if not fakemode:
@@ -204,11 +204,11 @@
 params['enclaves'] = enclaves
 
 if sys.version_info[0] < 3:
-    import Tkinter
+    import tkinter
     #from Tkinter import *
-    import tkFileDialog
-    import tkFont
-    from tkFont import Font
+    import tkinter.filedialog
+    import tkinter.font
+    from tkinter.font import Font
     #from Tkinter.FileDialog import askopenfilename
 else:
     import tkinter
@@ -221,7 +221,7 @@
   def __init__(self, master, row=2, col=3):
 
         # Create a container
-        self.frame = Tkinter.Frame(master,width=200,height=100)
+        self.frame = tkinter.Frame(master,width=200,height=100)
         # Create 2 buttons
         #self.button_left = Tkinter.Button(frame,text="< Decrease Slope",
         #                               command=self.decrease)
@@ -290,14 +290,14 @@
         self.listFontFamily = ['serif', 'sans-serif', 'cursive', 'fantasy', 'monospace']
         self.listFontWeight = ['ultralight','light','normal','regular','book','medium','roman','semibold','demibold','demi','bold','heavy','extra bold','black']
 
-        self.list_fonts = list( tkFont.families() )
+        self.list_fonts = list( tkinter.font.families() )
 
         self.selectedFontPolicy = None
         self.selectedFontSize = None
         self.selectedFontWeight = None
        
         # create a custom font
-        self.customFont = tkFont.Font(family="Helvetica", size=12)
+        self.customFont = tkinter.font.Font(family="Helvetica", size=12)
  
         for idx in range(params['cfg']['nbgraphs']):
          self.listUsedGraphs.append(-1)
@@ -381,7 +381,7 @@
         try:       
           root.config(menu=menubar)
         except AttributeError as attErr:
-          print 'menu Exception: ', type(attErr), attErr 
+          print('menu Exception: ', type(attErr), attErr) 
 
         #self.winPvars()
         #self.winCvars()
@@ -393,27 +393,27 @@
         self.subSpawn(sos_db_file)
 
   def try_execute(self, c, statement, parameters=None):
-    print ("statement: ", statement)
-    print ("parameters: ", parameters)
+    print(("statement: ", statement))
+    print(("parameters: ", parameters))
     try:
         if parameters:
             c.execute(statement,parameters);
         else:
             c.execute(statement);
     except sqlite3.Error as e:
-        print("database error.....", e.args[0])
+        print(("database error.....", e.args[0]))
 
   def open_connection(self,sqlite_file):
     global conn
     # check for file to exist
     #print ("Checking for file: ", sqlite_file)
-    print ("Checking for file: ", "sosd.00000.db")
+    print(("Checking for file: ", "sosd.00000.db"))
     while not os.path.exists("sosd.00000.db"):
-        print ("Waiting on file: ", sqlite_file)
+        print(("Waiting on file: ", sqlite_file))
         time.sleep(1)
 
     #print("Connecting to: ", sqlite_file)
-    print("Connecting to: ", "sosd.00000.db")
+    print(("Connecting to: ", "sosd.00000.db"))
     # Connecting to the database file
     #conn = sqlite3.connect(sqlite_file)
     #fd = os.open(sqlite_file, os.O_RDONLY)
@@ -433,7 +433,7 @@
     return c
 
   def btnfontsupdate(self):
-       print 'Update font'
+       print('Update font')
        if self.selectedFontPolicy or self.selectedFontSize or self.selectedFontWeight:
          matplotlib.rcParams.update({'font.size': self.selectedFontSize, 'font.family': self.selectedFontPolicy})
          #self.customFont.configure(family=self.selectedFontPolicy)
@@ -442,40 +442,40 @@
          matplotlib.rc('font', **font)
 
   def ckbtnFontBold(self):
-        print 'Bold selected'
+        print('Bold selected')
 
   def ckbtnFontItalic(self):
-        print 'Italic selected'
+        print('Italic selected')
 
   def ckbtnFontUnderline(self):
-        print 'Underline selected'
+        print('Underline selected')
       
   def browsefontpolicy(self):
-        print 'browsefontpolicy'
-        fontpolicydiag = tkFileDialog.askopenfilename(filetypes=[("Text files","*.fft")])
+        print('browsefontpolicy')
+        fontpolicydiag = tkinter.filedialog.askopenfilename(filetypes=[("Text files","*.fft")])
 
   def onselectFontPolicy(self,evt):
         w = evt.widget
         selection = w.curselection()
         value = w.get(selection[0])
         self.selectedFontPolicy = value
-        print 'select font: ', value
+        print('select font: ', value)
 
   def onselectFontSize(self, evt):
-       print 'select font size'  
+       print('select font size')  
        w = evt.widget
        selection = w.curselection()
        value = w.get(selection[0])
        self.selectedFontSize = value
-       print 'select font: ', value
+       print('select font: ', value)
 
   def onselectFontWeight(self, evt):
-       print 'select font weight'  
+       print('select font weight')  
        w = evt.widget
        selection = w.curselection()
        value = w.get(selection[0])
        self.selectedFontWeight = value
-       print 'select font: ', value
+       print('select font: ', value)
 
   def loadFontPolicy(self):
         fontpolicydiag = askopenfilename(filetypes=(("*.fft"))) 
@@ -485,7 +485,7 @@
   #def cvarsmenu(self):
 
   def fontmenu(self):
-        print 'nothing'
+        print('nothing')
 
         self.paramswin = Tk.Tk()
         self.paramswin.title("Fonts: family, size and weight")
@@ -593,7 +593,7 @@
 
   def clearplot(self,idxGraph):
 
-       print 'clearplot: idxGraph=', idxGraph
+       print('clearplot: idxGraph=', idxGraph)
        ax = self.ax[idxGraph]
        ax.cla()    
        #ax.clf()
@@ -667,13 +667,13 @@
                         total_val=total_val+ref4
                         num_vals=num_vals+1
                         mean_val=total_val/num_vals
-                        print 'display record ref4='+str(ref4)
+                        print('display record ref4='+str(ref4))
                         self.data_lr[i].add(t,ref4)
                         #self.data_lr[i].add(t,mean_val)
                         goodrecord=1
 
         if goodrecord==0:
-                print 'bad record'
+                print('bad record')
                 return        
 
   def updategui3(self, params, rows):
@@ -684,7 +684,7 @@
         total_val=0
         num_vals=0
 
-	print '[PYCOOLR] Starting update gui'
+	print('[PYCOOLR] Starting update gui')
         #if sample['node'] == params['targetnode'] and sample['sample'] == 'tau':
             #
             # data handling
@@ -705,9 +705,9 @@
 
                   #print("Fetching rows.")
                   rows[j] = self.conn.fetchall()
-                  print 'row: ', rows[j]
+                  print('row: ', rows[j])
                   if len(rows[j]) <= 0:
-                    print("Error: query returned no rows.",)
+                    print(("Error: query returned no rows.",))
                   else:
                    goodrecord = 1
 
@@ -738,7 +738,7 @@
                 try:
                   ax.cla()
                 except Exception as errCla:
-                  print 'update_gui: Error cla(): ', type(errCla), errCla
+                  print('update_gui: Error cla(): ', type(errCla), errCla)
 
                 #ax.set_xlim([t-gxsec, t])
                 #print 'get x and y'
@@ -852,7 +852,7 @@
         try:
            ax.cla()
         except Exception as errCla:
-          print 'update_gui: Error cla(): ', type(errCla), errCla
+          print('update_gui: Error cla(): ', type(errCla), errCla)
 
         ax.set_xlim([pack_time-gxsec, pack_time])
         #print 'get x and y'
@@ -910,7 +910,7 @@
         graphs = [None, None, None, None, None, None]
         axises = [None, None, None, None, None, None]
 
-	print '[PYCOOLR] Starting update gui'
+	print('[PYCOOLR] Starting update gui')
         #if sample['node'] == params['targetnode'] and sample['sample'] == 'tau':
             #
             # data handling
@@ -931,9 +931,9 @@
 
                   #print("Fetching rows.")
                   rows[j] = self.conn.fetchall()
-                  print 'rows: ', rows[j]
+                  print('rows: ', rows[j])
                   if len(rows[j]) <= 0:
-                    print("Error: query returned no rows.",)
+                    print(("Error: query returned no rows.",))
                   else:
                    goodrecord = 1
 
@@ -967,7 +967,7 @@
                   graph = {}  
 
                 if newplot:
-                  print 'newplot True'
+                  print('newplot True')
                   axis = pl.subplot(1)
                   axis.set_title("Time per iteration");
                   graph[r] = (pl.plot(pack_time, metric_values, marker='*', linestyle='-', label=str(r))[0])
@@ -977,7 +977,7 @@
                   pl.ylabel("Seconds")
                   pl.xlabel("Timestamp")
                 else:
-                  print 'newplot False'
+                  print('newplot False')
                   #axis = pl.subplot(321)
                   graph[r].set_data(pack_time, metric_values)
                   axis.relim()        # Recalculate limits
@@ -1076,7 +1076,7 @@
                 try:
                   ax.cla()
                 except Exception as errCla:
-                  print 'update_gui: Error cla(): ', type(errCla), errCla
+                  print('update_gui: Error cla(): ', type(errCla), errCla)
 
                 ax.set_xlim([t-gxsec, t])
                 #print 'get x and y'
@@ -1136,7 +1136,7 @@
 
   def subscribe(self,libarbjsonbeep):
 
-     print 'start thread with Subscribe'
+     print('start thread with Subscribe')
 
      listargs = ['MEMORY','NODE_POWER_WATTS','MPI_T_PVAR']
 
@@ -1145,7 +1145,7 @@
 
   def publish(self,libarbpubcvars):
 
-     print 'start thread with Publish'
+     print('start thread with Publish')
 
      #listargs = ['MEMORY','NODE_POWER_WATTS','MPI_T_PVAR']
 
@@ -1211,11 +1211,11 @@
              payload += resultPayload[j]
 
            payload.strip()
-           print 'payload =',payload
+           print('payload =',payload)
            try:
              j = json.loads(payload)
            except ValueError as e:
-             print 'Failed to load json data: %s' %e
+             print('Failed to load json data: %s' %e)
              continue
              #return False
 
@@ -1250,7 +1250,7 @@
          if 'node' not in e and\
             'sample' not in e and\
             'time' not in e:
-             print 'Ignore this invalid sample:', json.dumps(e)
+             print('Ignore this invalid sample:', json.dumps(e))
              continue
 
          #print 'set timestamp'
@@ -1278,11 +1278,11 @@
        #print 'finished parsing listEvents'
        #draw to refresh plotting
        #layout.canvas.draw()
-       print 'draw canvas'
+       print('draw canvas')
        try:
          self.canvas.draw()
        except Exception as errDraw:
-         print 'Error drawing canvas: ', type(errDraw), errDraw
+         print('Error drawing canvas: ', type(errDraw), errDraw)
        #plt.draw()
 
        profile_t7 = time.time()
@@ -1364,10 +1364,10 @@
     all_rows = c.fetchall()
     ts = np.array([x[0] for x in all_rows])
     min_timestamp = ts[0]
-    print("min timestamp: ", min_timestamp)
+    print(("min timestamp: ", min_timestamp))
 
   def req_sql(self, c, ranks, ranks2, group_column, metric):
-    print 'req_sql entering'
+    print('req_sql entering')
     for r in ranks:
         sql_statement = ("SELECT distinct tbldata.name, tblvals.val, tblvals.time_pack, tblpubs.comm_rank FROM tblvals INNER JOIN tbldata ON tblvals.guid = tbldata.guid INNER JOIN tblpubs ON tblpubs.guid = tbldata.pub_guid WHERE tblvals.guid IN (SELECT guid FROM tbldata WHERE tbldata.name LIKE '" + metric + "') AND tblpubs." + group_column)
         """
@@ -1414,15 +1414,15 @@
             sql_statement = (sql_statement + " like '" + r + "' and tblvals.val > 0 order by tblvals.time_pack;")
 
         #params = [metric,r]
-        print "Executing query: ", sql_statement,
+        print("Executing query: ", sql_statement, end=' ')
         self.try_execute(c, sql_statement)
-        print "Done. "
+        print("Done. ")
 
         #print("Fetching rows.")
         all_rows = c.fetchall()
         if len(all_rows) <= 0:
-            print("Error: query returned no rows.",)
-            print(sql_statement, params)
+            print(("Error: query returned no rows.",))
+            print((sql_statement, params))
 
         #print("Making numpy array of: metric_values")
         metric_values = np.array([max(x[1],0) for x in all_rows])
@@ -1464,14 +1464,14 @@
     while self.ranks.size == 0:
         time.sleep(1)
         self.ranks,self.procs = self.get_ranks(self.conn)
-    print ("ranks: ", self.ranks)
+    print(("ranks: ", self.ranks))
 
     # get the number of nodes
     self.nodes,self.noderanks = self.get_nodes(self.conn)
     while self.nodes.size == 0:
         time.sleep(1)
         nodes,self.noderanks = self.get_nodes(self.conn)
-    print ("nodes: ", self.nodes)
+    print(("nodes: ", self.nodes))
 
     self.get_min_timestamp(self.conn)
     #resize the figure
@@ -1496,11 +1496,11 @@
 
   def readsosmetrics(self,arguments):
 
-     print 'readsosmetrics'
+     print('readsosmetrics')
      profile_t1 = time.time()
      self.opendb(arguments)
     
-     print 'after opening db, read db and plot ....'
+     print('after opening db, read db and plot ....')
  
      while True:
 
@@ -1510,7 +1510,7 @@
          if self.listRecordSample[i] != -1:
            j = self.listRecordSample[i]
      
-           print 'readsosmetrics: i=%d, j=%d' %(i,j)
+           print('readsosmetrics: i=%d, j=%d' %(i,j))
            
            #rank = self.ranks[j]
            #rank2 = self.ranks2[j]
@@ -1528,7 +1528,7 @@
            self.rows[j] = self.conn.fetchall()
            #print 'rows: ', self.rows[j]
            if len(self.rows[j]) <= 0:
-             print("Error: query returned no rows.",)
+             print(("Error: query returned no rows.",))
            else:
              goodrecord = 1
          
@@ -1546,7 +1546,7 @@
 
   def readEvents(self,libarbjsonbeep):
 
-    print '[PYCOOLR] readEvents begin'
+    print('[PYCOOLR] readEvents begin')
 
     low_index = 0
     high_index = 0
@@ -1622,7 +1622,7 @@
            try:
              j = json.loads(payload)
            except ValueError as e:
-             print 'Failed to load json data: %s' %e
+             print('Failed to load json data: %s' %e)
              continue
              #return False
 
@@ -1657,7 +1657,7 @@
          if 'node' not in e and\
             'sample' not in e and\
             'time' not in e:
-             print 'Ignore this invalid sample:', json.dumps(e)
+             print('Ignore this invalid sample:', json.dumps(e))
              continue
 
          #print 'set timestamp'
@@ -1714,7 +1714,7 @@
 
   def subSpawn(self,arguments):
 
-     print 'subSpawn: load beacon subscriber library'
+     print('subSpawn: load beacon subscriber library')
      envlibpath = os.environ['PYCOOLR_LIBPATH']
      libarbjsonbeep = cdll.LoadLibrary(envlibpath+'/libarbitraryjsonbeepmulsub.so')
 
@@ -1727,10 +1727,10 @@
 
      try:
        #thread.start_new_thread(self.subscribe,(libarbjsonbeep,))
-       thread.start_new_thread(self.readsosmetrics,(arguments,))
+       _thread.start_new_thread(self.readsosmetrics,(arguments,))
       
      except Exception as errThread:
-       print 'Error: unable to start thread: ', errThread
+       print('Error: unable to start thread: ', errThread)
 
      self.refresh_plot()
      #self.readEvents(libarbjsonbeep)
@@ -1751,7 +1751,7 @@
           #print "selection:", selection, ": '%s'" % value
          
         listintselection = [int (i) for i in selection]
-        print 'listintselection: ', listintselection
+        print('listintselection: ', listintselection)
 
         for i in range(self.nbsamples):
           if (self.listSamplesAllocated[i] > -1) and (i not in listintselection):
@@ -1766,7 +1766,7 @@
               if self.listSamplesAllocated[j] == -1:    
                 #index = int(j)
                 self.listUsedGraphs[i] = j
-                print 'graph %d allocated to sample %d' % (i, j)
+                print('graph %d allocated to sample %d' % (i, j))
                 self.listRecordSample[i] = j
                 self.listSamplesAllocated[j] = i
                 break
@@ -1792,7 +1792,7 @@
                 # Mark current graph as used
                 self.listUsedGraphs[j] = 1           
                 # Record the current graph as plotting the current sample
-                print 'Record Sample %d for graph %d' %(index,j)
+                print('Record Sample %d for graph %d' %(index,j))
                 self.listRecordSample[j] = index
 
                 # Mark current sample as allocated to the current graph
@@ -1893,21 +1893,21 @@
          self.canvas.draw()
          #self.frame.update()
        except Exception as errDraw:
-         print 'refresh_plot: Error drawing canvas: ', type(errDraw), errDraw
+         print('refresh_plot: Error drawing canvas: ', type(errDraw), errDraw)
        self.lock.release()
 
        self.root.after(1000,self.refresh_plot)      
 
   def updatebtn(self):
-       print 'update buttonupdate button'
+       print('update buttonupdate button')
        try:
          self.canvas.draw()
        except Exception as errDraw:
-         print 'Error drawing canvas: ', type(errDraw), errDraw
+         print('Error drawing canvas: ', type(errDraw), errDraw)
 
   def checkfn(self, idx, text): 
-       print 'checkfn'
-       print 'Check index=%d text=%s' % (idx,text)
+       print('checkfn')
+       print('Check index=%d text=%s' % (idx,text))
        #print 'Size of listbtnchecked[]= ', len(self.listbtnchecked)
        #self.listbtnchecked[idx] = 1
 
@@ -1916,7 +1916,7 @@
 #     print 'nothing'
       
 
-root = Tkinter.Tk()
+root = tkinter.Tk()
 
 app = Coolrsub(root,2,3)
 root.mainloop()
--- a/tools/src/pycoolr/src/pycoolrgui/pycoolr-plot/coolr.py	(original)
--- b/tools/src/pycoolr/src/pycoolrgui/pycoolr-plot/coolr.py	(refactored)
@@ -1,7 +1,7 @@
 #!/usr/bin/env python
 
 #import sys, os, re, _thread, signal
-import sys, os, re, thread, signal
+import sys, os, re, _thread, signal
 #from cStringIO import StringIO
 from io import StringIO
 import subprocess
@@ -148,10 +148,10 @@
     with open(cfgfn) as f:
         cfgtmp = json.load(f)
         # override if cfg defines any
-        for k in cfgtmp.keys():
+        for k in list(cfgtmp.keys()):
             cfg[k] = cfgtmp[k]
         # override if specifed as cmd option
-        for k in ocfg.keys():
+        for k in list(ocfg.keys()):
             cfg[k] = ocfg[k]
 
 
@@ -159,21 +159,21 @@
     targetnode = os.environ['PYCOOLR_NODE']
     #targetnode = cfg['masternode']
 if len(enclaves) == 0:
-    if cfg.has_key('enclaves'):
+    if 'enclaves' in cfg:
         enclaves = cfg['enclaves']
 
 #print 'masternode:', cfg['masternode']
-print('targetnode:', targetnode)
-print('enclaves:', enclaves)
+print(('targetnode:', targetnode))
+print(('enclaves:', enclaves))
 
 if len(appcfgfn) > 0:
     with open(appcfgfn) as f:
         appcfg = json.load(f)
-    for k in appcfg.keys():
+    for k in list(appcfg.keys()):
         cfg[k] = appcfg[k]
 
-    if not (cfg.has_key('appname') and cfg.has_key('appsamples')):
-        print("Please double check %s: appname or appsamples tags" % appcfgfn)
+    if not ('appname' in cfg and 'appsamples' in cfg):
+        print(("Please double check %s: appname or appsamples tags" % appcfgfn))
         sys.exit(1)
 
 
@@ -189,7 +189,7 @@
 try:
     logf = open(cfg["outputfn"], 'w', 0) # unbuffered write
 except:
-    print('unable to open', cfg["outputfn"])
+    print(('unable to open', cfg["outputfn"]))
 
 
 #if not fakemode:
@@ -212,11 +212,11 @@
 params['enclaves'] = enclaves
 
 if sys.version_info[0] < 3:
-    import Tkinter
+    import tkinter
     #from Tkinter import *
-    import tkFileDialog
-    import tkFont
-    from tkFont import Font
+    import tkinter.filedialog
+    import tkinter.font
+    from tkinter.font import Font
     #from Tkinter.FileDialog import askopenfilename
 else:
     import tkinter
@@ -229,7 +229,7 @@
   def __init__(self, master, row=2, col=3):
 
         # Create a container
-        self.frame = Tkinter.Frame(master,width=200,height=100)
+        self.frame = tkinter.Frame(master,width=200,height=100)
         # Create 2 buttons
         #self.button_left = Tkinter.Button(frame,text="< Decrease Slope",
         #                               command=self.decrease)
@@ -265,10 +265,10 @@
 	        sql_statement = ("SELECT MAX(frame) FROM tblVals;")
 	        self.try_execute(self.conn, sql_statement)
 	        query_result = self.conn.fetchall()
-	        print("query_result", query_result[0][0])
+	        print(("query_result", query_result[0][0]))
 	        if type(query_result[0][0]) == int:
 	        	frame = int(query_result[0][0])
-	        print("frame", frame)
+	        print(("frame", frame))
           self.metricsDB = ""
           #Get the metric's names
           #sql_statement = ("SELECT distinct(value_name), comm_rank FROM viewCombined where frame > 0 ORDER BY value_name, comm_rank;")
@@ -284,7 +284,7 @@
           params['cfg']['units'] = ["KB" if (metric[0].find("KB") > -1) else "counts"  for metric in self.metrics]
           params['cfg']['units'] = ["#Events" if (metric[0].find("NumEvents") > -1)  else units for metric,units in zip(self.metrics,params['cfg']['units'])]
           print("---------------------------------------------------------------------------------------------------------")
-          print("self.nbsamples",self.nbsamples)
+          print(("self.nbsamples",self.nbsamples))
 
         if self.tool == "beacon":
           self.nbcvars = params['cfg']['nbcvars']
@@ -349,14 +349,14 @@
         self.listFontFamily = ['serif', 'sans-serif', 'cursive', 'fantasy', 'monospace']
         self.listFontWeight = ['ultralight','light','normal','regular','book','medium','roman','semibold','demibold','demi','bold','heavy','extra bold','black']
 
-        self.list_fonts = list( tkFont.families() )
+        self.list_fonts = list( tkinter.font.families() )
 
         self.selectedFontPolicy = None
         self.selectedFontSize = None
         self.selectedFontWeight = None
        
         # create a custom font
-        self.customFont = tkFont.Font(family="Helvetica", size=12)
+        self.customFont = tkinter.font.Font(family="Helvetica", size=12)
  
         for idx in range(params['cfg']['nbgraphs']):
          self.listUsedGraphs.append(-1)
@@ -452,7 +452,7 @@
         #  selected_list.append(i)
         #print selected_list
         self.selected_list= [-1] * self.nbGraphs
-        print self.selected_list
+        print(self.selected_list)
 
 
 
@@ -471,7 +471,7 @@
         try:       
           root.config(menu=menubar)
         except AttributeError as attErr:
-          print('menu Exception: ', type(attErr), attErr)
+          print(('menu Exception: ', type(attErr), attErr))
          
         #self.winPvars()
         #self.winCvars()
@@ -488,19 +488,19 @@
         else:
             c.execute(statement);
     except sqlite3.Error as e:
-        print("database error...", e.args[0])
+        print(("database error...", e.args[0]))
 
   def open_connection(self):
     global conn
     # check for file to exist
     #print ("Checking for file: ", sqlite_file)
-    print("Checking for file: ", self.sosdbfile)
+    print(("Checking for file: ", self.sosdbfile))
     while not os.path.exists(self.sosdbfile):
-        print("Waiting on file: ", self.sosdbfile)
+        print(("Waiting on file: ", self.sosdbfile))
         time.sleep(1)
 
     #print("Connecting to: ", sqlite_file)
-    print("Connecting to: ", self.sosdbfile)
+    print(("Connecting to: ", self.sosdbfile))
     # Connecting to the database file
     #conn = sqlite3.connect(sqlite_file)
     #fd = os.open(sqlite_file, os.O_RDONLY)
@@ -539,14 +539,14 @@
       
   def browsefontpolicy(self):
         print('browsefontpolicy')
-        fontpolicydiag = tkFileDialog.askopenfilename(filetypes=[("Text files","*.fft")])
+        fontpolicydiag = tkinter.filedialog.askopenfilename(filetypes=[("Text files","*.fft")])
 
   def onselectFontPolicy(self,evt):
         w = evt.widget
         selection = w.curselection()
         value = w.get(selection[0])
         self.selectedFontPolicy = value
-        print('select font: ', value)
+        print(('select font: ', value))
 
   def onselectFontSize(self, evt):
        print('select font size')
@@ -554,7 +554,7 @@
        selection = w.curselection()
        value = w.get(selection[0])
        self.selectedFontSize = value
-       print('select font: ', value)
+       print(('select font: ', value))
 
   def onselectFontWeight(self, evt):
        print('select font weight')
@@ -562,7 +562,7 @@
        selection = w.curselection()
        value = w.get(selection[0])
        self.selectedFontWeight = value
-       print('select font: ', value)
+       print(('select font: ', value))
 
   def loadFontPolicy(self):
         fontpolicydiag = askopenfilename(filetypes=(("*.fft"))) 
@@ -632,7 +632,7 @@
  
   #def winPvars(self):
   def select_metric(self, fig_num):
-        print "Selected metric for figure: " + str(fig_num)
+        print("Selected metric for figure: " + str(fig_num))
     	# this is the child window
         self.pvarswin = Tk.Tk()
         str_metric_title = "Select Metric: "+ str(fig_num)
@@ -761,7 +761,7 @@
 
   def clearplot(self,idxGraph):
 
-       print('clearplot: idxGraph=', idxGraph)
+       print(('clearplot: idxGraph=', idxGraph))
        ax = self.ax[idxGraph]
        ax.cla()    
        #ax.clf()
@@ -835,7 +835,7 @@
                         total_val=total_val+ref4
                         num_vals=num_vals+1
                         mean_val=total_val/num_vals
-                        print('display record ref4='+str(ref4))
+                        print(('display record ref4='+str(ref4)))
                         self.data_lr[i].add(t,ref4)
                         #self.data_lr[i].add(t,mean_val)
                         goodrecord=1
@@ -910,7 +910,7 @@
                 try:
                   ax.cla()
                 except Exception as errCla:
-                  print('update_gui: Error cla(): ', type(errCla), errCla)
+                  print(('update_gui: Error cla(): ', type(errCla), errCla))
 
                 ax.set_xlim([t-gxsec, t])
                 #print 'get x and y'
@@ -1020,7 +1020,7 @@
         try:
            ax.cla()
         except Exception as errCla:
-          print('update_gui: Error cla(): ', type(errCla), errCla)
+          print(('update_gui: Error cla(): ', type(errCla), errCla))
 
         ax.set_xlim([pack_time-gxsec, pack_time])
         #print 'get x and y'
@@ -1130,7 +1130,7 @@
         try:
            ax.cla()
         except Exception as errCla:
-          print('update_gui: Error cla(): ', type(errCla), errCla)
+          print(('update_gui: Error cla(): ', type(errCla), errCla))
 
         ax.set_xlim([pack_time-gxsec, pack_time])
         #print 'get x and y'
@@ -1258,7 +1258,7 @@
            try:
              j = json.loads(payload)
            except ValueError as e:
-             print('Failed to load json data: %s' %e)
+             print(('Failed to load json data: %s' %e))
              continue
              #return False
 
@@ -1293,7 +1293,7 @@
          if 'node' not in e and\
             'sample' not in e and\
             'time' not in e:
-             print('Ignore this invalid sample:', json.dumps(e))
+             print(('Ignore this invalid sample:', json.dumps(e)))
              continue
 
          #print 'set timestamp'
@@ -1325,7 +1325,7 @@
        try:
          self.canvas.draw()
        except Exception as errDraw:
-         print('Error drawing canvas: ', type(errDraw), errDraw)
+         print(('Error drawing canvas: ', type(errDraw), errDraw))
        #plt.draw()
 
        profile_t7 = time.time()
@@ -1407,7 +1407,7 @@
     all_rows = c.fetchall()
     ts = np.array([x[0] for x in all_rows])
     min_timestamp = ts[0]
-    print("min timestamp: ", min_timestamp)
+    print(("min timestamp: ", min_timestamp))
 
 
   def get_min_timestamp(self):
@@ -1415,25 +1415,25 @@
     sql_statement = ("SELECT min(time_pack) FROM viewCombined;")
     print("get_min_timestamp Executing query")
  
-    print("sql statement: ", sql_statement)
+    print(("sql statement: ", sql_statement))
     #self.try_execute(c, sql_statement)
     os.environ['SOS_SQL'] = sql_statement
     sos_bin_path = os.environ.get('SOS_BIN_DIR')
-    print('SOS BIN path: ', sos_bin_path)
+    print(('SOS BIN path: ', sos_bin_path))
     os.system('cd '+ sos_bin_path)
-    print('current dir: ', os.getcwd())
+    print(('current dir: ', os.getcwd()))
     # Redirect stdout of passed command into a string
 
     soscmd = sos_bin_path + "/demo_app_silent --sql SOS_SQL"
-    print('soscmd: ', soscmd)
+    print(('soscmd: ', soscmd))
     tmp_res_min_ts_sql = subprocess.check_output(soscmd, shell=True)
 
     #self.res_min_ts_sql = tmp_res_min_ts_sql.splitlines()
-    print('get min ts: tmp res sql=', tmp_res_min_ts_sql)
+    print(('get min ts: tmp res sql=', tmp_res_min_ts_sql))
     res_min_ts_sql = tmp_res_min_ts_sql.splitlines()
-    print("List of result SQL MIN TS: ", res_min_ts_sql)
+    print(("List of result SQL MIN TS: ", res_min_ts_sql))
     min_ts_rows = res_min_ts_sql[1].split(",")
-    print("List of result SQL MIN TS values: ", min_ts_rows)
+    print(("List of result SQL MIN TS values: ", min_ts_rows))
     # Remove first element of SQL result 
     #ts = np.array([x[0] for x in min_ts_rows])
     str_min_timestamp = min_ts_rows[0].replace('\"', '')
@@ -1475,31 +1475,31 @@
     sql_statement = ("SELECT value_name, value, time_pack FROM viewCombined WHERE value_name LIKE '" + metric+ "'")
     #sql_statement = ("SELECT * FROM viewCombined WHERE value_name LIKE '" + metric+ "'")
    
-    print("sql statement: ", sql_statement )
+    print(("sql statement: ", sql_statement ))
     #self.try_execute(c, sql_statement)
     os.environ['SOS_SQL'] = sql_statement
     sos_bin_path = os.environ.get('SOS_BIN_DIR')
-    print('SOS BIN path: ', sos_bin_path)
+    print(('SOS BIN path: ', sos_bin_path))
     os.system('cd '+ sos_bin_path)  
-    print('current dir: ', os.getcwd()) 
+    print(('current dir: ', os.getcwd())) 
     # Redirect stdout of passed command into a string
    
     soscmd = sos_bin_path + "/demo_app_silent --sql SOS_SQL"
-    print('soscmd: ', soscmd)
+    print(('soscmd: ', soscmd))
     tmp_res_sql = subprocess.check_output(soscmd, shell=True)
 
     self.try_execute(c, sql_statement)
 
     #print 'stdout of SOS demo: ', sys.stdout
     #self.res_sql = resultstdout.getvalue()
-    print('tmp res_sql: ', tmp_res_sql)
+    print(('tmp res_sql: ', tmp_res_sql))
     
     self.res_sql = tmp_res_sql.splitlines()
     # REmove first element of SQL result 
     self.res_sql.pop(0)
 
     for item_sql in self.res_sql:
-      print('res sql: ', item_sql) 
+      print(('res sql: ', item_sql)) 
       
  
   # Call demo with SQL statement given as argument and store standard output
@@ -1566,7 +1566,7 @@
     print('SOS: Execute demo app')
     sos_path = os.environ.get('SOS_BUILD_DIR') 
     self.sos_bin_path = sos_path+"/bin"
-    print('SOS BIN PATH: ', self.sos_bin_path)
+    print(('SOS BIN PATH: ', self.sos_bin_path))
     os.system("cd "+ self.sos_bin_path) 
 
 
@@ -1644,7 +1644,7 @@
          if self.listRecordSample[i] != -1:
            j = self.listRecordSample[i]
      
-           print('readsosmetrics: i=%d, j=%d' %(i,j))
+           print(('readsosmetrics: i=%d, j=%d' %(i,j)))
            
            #rank = self.ranks[j]
            #rank2 = self.ranks2[j]
@@ -1662,7 +1662,7 @@
            self.rows[j] = self.conn.fetchall()
            #print 'rows: ', self.rows[j]
            if len(self.rows[j]) <= 0:
-             print("Error: query returned no rows.",)
+             print(("Error: query returned no rows.",))
            else:
              goodrecord = 1
          
@@ -1749,11 +1749,11 @@
 
 
            payload.strip()
-           print('payload =',payload)
+           print(('payload =',payload))
            try:
              j = json.loads(payload)
            except ValueError as e:
-             print('Failed to load json data: %s' %e)
+             print(('Failed to load json data: %s' %e))
              continue
              #return False
 
@@ -1788,7 +1788,7 @@
          if 'node' not in e and\
             'sample' not in e and\
             'time' not in e:
-             print('Ignore this invalid sample:', json.dumps(e))
+             print(('Ignore this invalid sample:', json.dumps(e)))
              continue
 
          #print 'set timestamp'
@@ -1858,20 +1858,20 @@
          print('subSpawn: load beacon subscriber library')
          envlibpath = os.environ['PYCOOLR_LIBPATH']
          libarbjsonbeep = cdll.LoadLibrary(envlibpath+'/libarbitraryjsonbeepmulsub.so')
-         thread.start_new_thread(self.subscribe,(libarbjsonbeep,))
-         thread.start_new_thread(self.readEvents,(libarbjsonbeep,))
+         _thread.start_new_thread(self.subscribe,(libarbjsonbeep,))
+         _thread.start_new_thread(self.readEvents,(libarbjsonbeep,))
          #thread.start_new_thread(self.readEvents,(libarbjsonbeep,))
        except Exception as errThread:
-         print("Error: unable to start thread: ", errThread)
+         print(("Error: unable to start thread: ", errThread))
 
      elif self.tool == "sos":
        try:
          #thread.start_new_thread(self.subscribe,(libarbjsonbeep,))
-         thread.start_new_thread(self.readsosmetrics,())
+         _thread.start_new_thread(self.readsosmetrics,())
          #thread.start_new_thread(self.readsosmetrics_db,())
       
        except Exception as errThread:
-         print('Error: unable to start thread: ', errThread)
+         print(('Error: unable to start thread: ', errThread))
 
 
      self.refresh_plot()
@@ -1904,7 +1904,7 @@
 
             self.selectedcvarsvalues[i] =  self.listcvarsentry[i].get()
             strcvarsvalues += self.selectedcvarsvalues[i]
-            print('numselectedcvars=%d, index=%d' % (self.numselectedcvars, i))
+            print(('numselectedcvars=%d, index=%d' % (self.numselectedcvars, i)))
             if i+1 < self.numselectedcvars:
               strcvarsmetrics += ","
               strcvarsvalues += ","
@@ -1917,7 +1917,7 @@
             #self.strcvars += "=" 
             #self.strcvars += self.selectedcvarsvalues[i]
             #strcvars += ","
-            print('numselectedcvars=%d, index=%d' % (self.numselectedcvars, i))
+            print(('numselectedcvars=%d, index=%d' % (self.numselectedcvars, i)))
             if i+1 < self.numselectedcvars:
               strcvarsmetrics += ","
               strcvarsvalues += ","
@@ -1928,9 +1928,9 @@
         #self.strcvars += ":"
         self.strcvars += strcvarsvalues
 
-        print("strcvarsmetrics: ", strcvarsmetrics)
-        print("strcvarsvalues: ", strcvarsvalues)
-        print("strcvars: ", self.strcvars)
+        print(("strcvarsmetrics: ", strcvarsmetrics))
+        print(("strcvarsvalues: ", strcvarsvalues))
+        print(("strcvars: ", self.strcvars))
 
         # Test if we have to communicate MPI_T CVARS in a Publish/Subscribe mode       
         if cvars_comm_mode == "pub":
@@ -1966,7 +1966,7 @@
 
         for i in range(len(selection)):
           value = w.get(selection[i])
-          print("selection:", selection, ": '%s'" % value)
+          print(("selection:", selection, ": '%s'" % value))
           self.selectedcvarsmetrics[i] = value
 
         if self.listlabelcvarsmetric:
@@ -1988,19 +1988,19 @@
         self.listcvarsarrayindexentry = [None] * len(selection)
         self.listcvarsarrayindex = [None] * len(selection)
 
-        print('selection: ', selection)
-        print('range selection: ', range(len(selection)))
-
-        for cvaritem, cvarindex in zip(selection, range(len(selection))):
+        print(('selection: ', selection))
+        print(('range selection: ', list(range(len(selection)))))
+
+        for cvaritem, cvarindex in zip(selection, list(range(len(selection)))):
 
           value = w.get(selection[cvarindex])
-          print('len selection: ', len(selection))
-          print('value of item %d: %s ' % (cvarindex, value))
-          print('cvaritem: ', cvaritem)
-          print('cvarindex= ', cvarindex)
-          print('cvarsindexrow= ', self.cvarsindexrow)
-
-          print('cfg cvars array:', self.listcfgcvarsarray[0])
+          print(('len selection: ', len(selection)))
+          print(('value of item %d: %s ' % (cvarindex, value)))
+          print(('cvaritem: ', cvaritem))
+          print(('cvarindex= ', cvarindex))
+          print(('cvarsindexrow= ', self.cvarsindexrow))
+
+          print(('cfg cvars array:', self.listcfgcvarsarray[0]))
           if value == self.listcfgcvarsarray[0]:
 
             self.listlabelcvarsmetric[cvarindex]=Tk.Label(self.stepCvarsUpdate,  text=value)
@@ -2056,7 +2056,7 @@
           #print "selection:", selection, ": '%s'" % value
          
         listintselection = [int (i) for i in selection]
-        print('listintselection: ', listintselection)
+        print(('listintselection: ', listintselection))
         #print('listSamplesAllocated: ', self.listSamplesAllocated)
         #print('nbsamples', self.nbsamples)
         #print('len(self.listSamplesAllocated)', len(self.listSamplesAllocated))
@@ -2074,7 +2074,7 @@
             if self.listSamplesAllocated[fig_num] == -1:    
                 #index = int(j)
                 self.listUsedGraphs[fig_num] = listintselection[fig_num]
-                print('graph %d allocated to sample %d' % (fig_num, listintselection[fig_num]))
+                print(('graph %d allocated to sample %d' % (fig_num, listintselection[fig_num])))
                 self.listRecordSample[fig_num] = listintselection[fig_num]
                 self.listSamplesAllocated[listintselection[fig_num]] = fig_num
 
@@ -2099,7 +2099,7 @@
                 # Mark current graph as used
                 self.listUsedGraphs[j] = 1           
                 # Record the current graph as plotting the current sample
-                print('Record Sample %d for graph %d' %(index,j))
+                print(('Record Sample %d for graph %d' %(index,j)))
                 self.listRecordSample[j] = index
 
                 # Mark current sample as allocated to the current graph
@@ -2200,7 +2200,7 @@
          self.canvas.draw()
          #self.frame.update()
        except Exception as errDraw:
-         print('refresh_plot: Error drawing canvas: ', type(errDraw), errDraw)
+         print(('refresh_plot: Error drawing canvas: ', type(errDraw), errDraw))
        self.lock.release()
 
        self.root.after(1000,self.refresh_plot)      
@@ -2210,11 +2210,11 @@
        try:
          self.canvas.draw()
        except Exception as errDraw:
-         print('Error drawing canvas: ', type(errDraw), errDraw)
+         print(('Error drawing canvas: ', type(errDraw), errDraw))
 
   def checkfn(self, idx, text): 
        print('checkfn')
-       print('Check index=%d text=%s' % (idx,text))
+       print(('Check index=%d text=%s' % (idx,text)))
        #print 'Size of listbtnchecked[]= ', len(self.listbtnchecked)
        #self.listbtnchecked[idx] = 1
 
@@ -2223,7 +2223,7 @@
 #     print 'nothing'
       
 
-root = Tkinter.Tk()
+root = tkinter.Tk()
 
 app = Coolrsub(root,2,3)
 root.mainloop()
--- a/tools/src/pycoolr/src/pycoolrgui/pycoolr-plot/init_coolr.py	(original)
--- b/tools/src/pycoolr/src/pycoolrgui/pycoolr-plot/init_coolr.py	(refactored)
@@ -38,8 +38,8 @@
 try:
     opts, args = getopt.getopt(sys.argv[1:],
                                shortopt, longopt)
-except getopt.GetoptError, err:
-    print err
+except getopt.GetoptError as err:
+    print(err)
     usage()
     sys.exit(1)
 
@@ -65,21 +65,21 @@
     elif o in ("--ncols"):
         ocfg["ncols"]=int(a)
     elif o in ("--list"):
-        print ''
-        print '[available graph modules]'
-        print ''
+        print('')
+        print('[available graph modules]')
+        print('')
         for i in cfg["modnames"]:
-            print i
-        print ''
-        print ''
+            print(i)
+        print('')
+        print('')
         sys.exit(0)
     elif o in ("--mods"):
         ocfg["modnames"] = a.split(",")
 
 if len(args) < 1:
-    print ''
-    print 'No config file is specified.  Enabled the fake mode.'
-    print ''
+    print('')
+    print('No config file is specified.  Enabled the fake mode.')
+    print('')
     cfg["masternode"] = "frontend"
     cfg["drawexternal"] = "no"
     cfg["drawacpipwr"] = "no"
@@ -101,30 +101,30 @@
     with open(cfgfn) as f:
         cfgtmp = json.load(f)
         # override if cfg defines any
-        for k in cfgtmp.keys():
+        for k in list(cfgtmp.keys()):
             cfg[k] = cfgtmp[k]
         # override if specifed as cmd option
-        for k in ocfg.keys():
+        for k in list(ocfg.keys()):
             cfg[k] = ocfg[k]
 
 if len(targetnode) == 0 :
     targetnode = cfg['masternode']
 if len(enclaves) == 0:
-    if cfg.has_key('enclaves'):
+    if 'enclaves' in cfg:
         enclaves = cfg['enclaves']
 
-print 'masternode:', cfg['masternode']
-print 'targetnode:', targetnode
-print 'enclaves:', enclaves
+print('masternode:', cfg['masternode'])
+print('targetnode:', targetnode)
+print('enclaves:', enclaves)
 
 if len(appcfgfn) > 0:
     with open(appcfgfn) as f:
         appcfg = json.load(f)
-    for k in appcfg.keys():
+    for k in list(appcfg.keys()):
         cfg[k] = appcfg[k]
 
-    if not (cfg.has_key('appname') and cfg.has_key('appsamples')):
-        print "Please double check %s: appname or appsamples tags" % appcfgfn
+    if not ('appname' in cfg and 'appsamples' in cfg):
+        print("Please double check %s: appname or appsamples tags" % appcfgfn)
         sys.exit(1)
 
 
@@ -142,9 +142,9 @@
 try:
     logf = open(cfg["outputfn"], 'w', 0) # unbuffered write
 except:
-    print 'unable to open', cfg["outputfn"]
+    print('unable to open', cfg["outputfn"])
 
-print >>logf, json.dumps(info)
+print(json.dumps(info), file=logf)
 
 #if not fakemode:
 #    querycmds = cfg['querycmds']
--- a/tools/src/pycoolr/src/pycoolrgui/pycoolr-plot/layout.py	(original)
--- b/tools/src/pycoolr/src/pycoolrgui/pycoolr-plot/layout.py	(refactored)
@@ -7,7 +7,7 @@
 from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
 
 if sys.version_info[0] < 3:
-    import Tkinter as Tk
+    import tkinter as Tk
 else:
     import tkinter as Tk
 
--- a/tools/src/pycoolr/src/pycoolrgui/pycoolr-plot/listrotate.py	(original)
--- b/tools/src/pycoolr/src/pycoolrgui/pycoolr-plot/listrotate.py	(refactored)
@@ -115,15 +115,15 @@
     lr = listrotate2D(5)
     for i in range(8):
         lr.add(i,i)
-        print lr.getlistx()
-        print lr.getlisty()
-        print lr.getlistr()
-        print 
+        print(lr.getlistx())
+        print(lr.getlisty())
+        print(lr.getlistr())
+        print() 
 
-    print '------------'
+    print('------------')
     lr = listrotate1D(5)
     for i in range(8):
         lr.add(i)
-        print lr.getlist()
-        print lr.getlistr()
-        print 
+        print(lr.getlist())
+        print(lr.getlistr())
+        print() 
--- a/tools/src/tau_portal/bin/tau_portal.py	(original)
--- b/tools/src/tau_portal/bin/tau_portal.py	(refactored)
@@ -1,5 +1,5 @@
 #!/usr/bin/env python
-import httplib, urllib, fileinput, sys, getpass, platform
+import http.client, urllib.request, urllib.parse, urllib.error, fileinput, sys, getpass, platform
 from optparse import OptionParser
 #import perfdmf and portal modules
 import portal
@@ -39,7 +39,7 @@
 #    sys.exit(2)
 
   if len(sys.argv[1:]) < 1:
-    print usage()
+    print(usage())
     sys.exit(-1)
   
 
@@ -66,12 +66,12 @@
     parser.parse_args(sys.argv[1:])
 
   if (options.username == ""):
-    print "TAU Portal Username: ",
+    print("TAU Portal Username: ", end=' ')
     options.username = sys.stdin.readline().strip()
   if (options.password == ""):
     options.password = getpass.getpass("TAU Portal Password: ")
   if (options.workspace == "" and not sys.argv[1] in ["list_workspaces", "work"]):
-    print "TAU Portal Workspace: ",
+    print("TAU Portal Workspace: ", end=' ')
     options.workspace = sys.stdin.readline().strip()
   
   #print options, args
@@ -80,16 +80,16 @@
     trial_list = []
     for trial in args:
       trial_list.append(open(trial, 'r'))
-    print portal.upload(options.username, options.password, options.workspace,
-    options.experiment, trial_list, options.host, options.summary)
+    print(portal.upload(options.username, options.password, options.workspace,
+    options.experiment, trial_list, options.host, options.summary))
     #print "upload"
   elif (sys.argv[1] in ["download", "down"]):
     file = portal.download(options.username, options.password,
     options.workspace, options.experiment, args[0], options.host)
     if (file.startswith("TAU Portal")):
-      print file
+      print(file)
     else:  
-      print "TAU PORTAL download is a success.\n"
+      print("TAU PORTAL download is a success.\n")
       name = args[0] + ".ppk"
       filewriter = open(name, 'w')
       filewriter.write(file)
@@ -104,15 +104,15 @@
     #print "sync"
   elif (sys.argv[1] in ["list_workspaces", "work"]):
     for workspace in portal.get_workspaces(options.username, options.password):
-      print workspace + ",",
+      print(workspace + ",", end=' ')
   elif (sys.argv[1] in ["list_trials", "trial"]):
     trials = portal.get_trials(options.username, options.password,
     options.workspace, options.experiment, options.host)
     if (not trials is None):
-      print ", ".join(trials)
+      print(", ".join(trials))
     #print portal.get_trials(options.username, options.password,
     #options.workspace, options.host) 
   else:
-    print "Command : " + sys.argv[1] + " unknown."
+    print("Command : " + sys.argv[1] + " unknown.")
 
 main()
